{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from copy import deepcopy\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "import lovely_tensors as lt\n",
    "from nnfabrik.builder import get_data\n",
    "from lurz2020.datasets.mouse_loaders import static_loaders\n",
    "from lurz2020.models.models import se2d_fullgaussian2d\n",
    "from lurz2020.training.trainers import standard_trainer as trainer\n",
    "from lurz2020.utility.measures import get_correlations, get_fraction_oracles\n",
    "\n",
    "import csng\n",
    "from csng.CNN_Decoder import CNN_Decoder\n",
    "from csng.utils import RunningStats, plot_comparison, standardize, normalize, get_mean_and_std, count_parameters\n",
    "from csng.losses import SSIMLoss, MSELossWithCrop\n",
    "from csng.data import MixedBatchLoader\n",
    "\n",
    "from models import MultiReadInCNN\n",
    "from data_utils import get_mouse_v1_data, PerSampleStoredDataset\n",
    "\n",
    "lt.monkey_patch()\n",
    "\n",
    "DATA_PATH = os.path.join(os.environ[\"DATA_PATH\"], \"mouse_v1_sensorium22\")\n",
    "print(f\"{DATA_PATH=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"data\": {\n",
    "        \"mixing_strategy\": \"sequential\", # needed only with multiple base dataloaders\n",
    "    },\n",
    "    \"device\": \"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    "    \"seed\": 0,\n",
    "}\n",
    "\n",
    "print(f\"... Running on {config['device']} ...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(config[\"seed\"])\n",
    "torch.manual_seed(config[\"seed\"])\n",
    "random.seed(config[\"seed\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloaders = dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mouse V1 dataset (Sensorium 2022)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### prep data config\n",
    "filenames = [ # from https://gin.g-node.org/cajal/Sensorium2022/src/master\n",
    "    # \"static26872-17-20-GrayImageNet-94c6ff995dac583098847cfecd43e7b6.zip\", # mouse 1\n",
    "    # \"static27204-5-13-GrayImageNet-94c6ff995dac583098847cfecd43e7b6.zip\", # sensorium+ (mouse 2)\n",
    "    # \"static21067-10-18-GrayImageNet-94c6ff995dac583098847cfecd43e7b6.zip\", # pretraining (mouse 3)\n",
    "    # \"static22846-10-16-GrayImageNet-94c6ff995dac583098847cfecd43e7b6.zip\", # pretraining (mouse 4)\n",
    "    # \"static23343-5-17-GrayImageNet-94c6ff995dac583098847cfecd43e7b6.zip\", # pretraining (mouse 5)\n",
    "    # \"static23656-14-22-GrayImageNet-94c6ff995dac583098847cfecd43e7b6.zip\", # pretraining (mouse 6)\n",
    "    \"static23964-4-22-GrayImageNet-94c6ff995dac583098847cfecd43e7b6.zip\", # pretraining (mouse 7)\n",
    "]\n",
    "for f_idx, f_name in enumerate(filenames):\n",
    "    filenames[f_idx] = os.path.join(DATA_PATH, f_name)\n",
    "\n",
    "config[\"data\"].update({\n",
    "    \"paths\": filenames,\n",
    "    \"dataset_fn\": \"sensorium.datasets.static_loaders\",\n",
    "    \"dataset_config\": {\n",
    "        \"paths\": filenames,\n",
    "        \"normalize\": True,\n",
    "        \"scale\": 0.25, # 256x144 -> 64x36\n",
    "        \"include_behavior\": False,\n",
    "        \"add_behavior_as_channels\": False,\n",
    "        \"include_eye_position\": True,\n",
    "        \"exclude\": None,\n",
    "        \"file_tree\": True,\n",
    "        \"cuda\": False,\n",
    "        \"batch_size\": 128,\n",
    "        \"seed\": config[\"seed\"],\n",
    "        \"use_cache\": False,\n",
    "    },\n",
    "    \"normalize_neuron_coords\": True,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## get dataloaders and cell coordinates\n",
    "dataloaders, neuron_coords = get_mouse_v1_data(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### show data\n",
    "sample_data_key = dataloaders[\"mouse_v1\"][\"val\"].data_keys[0]\n",
    "datapoint = next(iter(dataloaders[\"mouse_v1\"][\"val\"].dataloaders[0]))\n",
    "stim, resp = datapoint.images, datapoint.responses\n",
    "pupil_center = datapoint.pupil_center\n",
    "print(\n",
    "    f\"Training dataset:\\t {sum(len(dl) * config['data']['dataset_config']['batch_size'] for dl in dataloaders['mouse_v1']['train'].dataloaders)} samples\"\n",
    "    f\"\\nValidation dataset:\\t {sum(len(dl) * config['data']['dataset_config']['batch_size'] for dl in dataloaders['mouse_v1']['val'].dataloaders)} samples\"\n",
    "    f\"\\nTest dataset:\\t\\t {sum(len(dl) * config['data']['dataset_config']['batch_size'] for dl in dataloaders['mouse_v1']['test'].dataloaders)} samples\"\n",
    "    f\"\\nTest (no resp) dataset:\\t {sum(len(dl) * config['data']['dataset_config']['batch_size'] for dl in dataloaders['mouse_v1']['test_no_resp'].dataloaders)} samples\"\n",
    "\n",
    "    \"\\n\\nstimuli:\"\n",
    "    f\"\\n  {stim.shape}\"\n",
    "    f\"\\n  min={stim.min().item():.3f}  max={stim.max().item():.3f}\"\n",
    "    f\"\\n  mean={stim.mean().item():.3f}  std={stim.std().item():.3f}\"\n",
    "    \"\\nresponses:\"\n",
    "    f\"\\n  {resp.shape}\"\n",
    "    f\"\\n  min={resp.min().item():.3f}  max={resp.max().item():.3f}\"\n",
    "    f\"\\n  mean={resp.mean().item():.3f}  std={resp.std().item():.3f}\"\n",
    "    \"\\nneuronal coordinates:\"\n",
    "    f\"\\n  {neuron_coords[sample_data_key].shape}\"\n",
    "    f\"\\n  min={neuron_coords[sample_data_key].min():.3f}  max={neuron_coords[sample_data_key].max():.3f}\"\n",
    "    f\"\\n  mean={neuron_coords[sample_data_key].mean():.3f}  std={neuron_coords[sample_data_key].std():.3f}\"\n",
    ")\n",
    "\n",
    "fig = plt.figure(figsize=(16, 6))\n",
    "ax = fig.add_subplot(121)\n",
    "ax.imshow(stim[0].squeeze().unsqueeze(-1).cpu(), cmap=\"gray\")\n",
    "\n",
    "ax = fig.add_subplot(122)\n",
    "reshape_to = None\n",
    "for i in range(30, 150):\n",
    "    if resp.shape[-1] % i == 0:\n",
    "        reshape_to = (i, resp.shape[-1] // i)\n",
    "        break\n",
    "if reshape_to != None:\n",
    "    ax.imshow(resp[0].view(reshape_to).squeeze(0).unsqueeze(-1).cpu(), cmap=\"gray\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### load encoder\n",
    "print(\"Loading encoder...\")\n",
    "\n",
    "### load pretrained encoder ckpt\n",
    "encoder_ckpt = torch.load(\n",
    "    os.path.join(DATA_PATH, \"models\", \"encoder.pt\"),\n",
    "    map_location=config[\"device\"],\n",
    ")\n",
    "\n",
    "### get temporary dataloaders for the encoder\n",
    "_dataloaders = get_data(\n",
    "    encoder_ckpt[\"config\"][\"data\"][\"dataset_fn\"],\n",
    "    encoder_ckpt[\"config\"][\"data\"][\"dataset_config\"]\n",
    ")\n",
    "\n",
    "### init encoder\n",
    "encoder = se2d_fullgaussian2d(\n",
    "    **encoder_ckpt[\"config\"][\"encoder\"][\"model_config\"],\n",
    "    dataloaders=_dataloaders,\n",
    "    seed=encoder_ckpt[\"config\"][\"seed\"],\n",
    ").float()\n",
    "encoder.load_state_dict(encoder_ckpt[\"encoder_state\"], strict=True)\n",
    "encoder.to(config[\"device\"])\n",
    "encoder.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### validate encoder is working (corr on val set should be ~ 0.32)\n",
    "train_correlation = get_correlations(encoder, _dataloaders[\"train\"], device=config[\"device\"], as_dict=False, per_neuron=False)\n",
    "validation_correlation = get_correlations(encoder, _dataloaders[\"validation\"], device=config[\"device\"], as_dict=False, per_neuron=False)\n",
    "test_correlation = get_correlations(encoder, _dataloaders[\"test\"], device=config[\"device\"], as_dict=False, per_neuron=False)\n",
    "\n",
    "print(\n",
    "    f\"Correlation (train set):      {train_correlation:.3f}\"\n",
    "    f\"\\nCorrelation (validation set): {validation_correlation:.3f}\"\n",
    "    f\"\\nCorrelation (test set):       {test_correlation:.3f}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create synthetic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_part = \"test\"\n",
    "assert len(dataloaders[\"mouse_v1\"][data_part].data_keys) == 1,\\\n",
    "    \"Create synthetic datasets one by one.\"\n",
    "data_key = dataloaders[\"mouse_v1\"][data_part].data_keys[0]\n",
    "save_stats = False\n",
    "\n",
    "print(f\"{data_part=}  {data_key=}  {save_stats=}\")\n",
    "\n",
    "trans_to_apply = [\n",
    "    {\n",
    "        \"name\": \"original\",\n",
    "        \"stim\": lambda x: x,\n",
    "        \"resp\": lambda x: x,\n",
    "        \"save_dir\": os.path.join(DATA_PATH, \"synthetic_data_mouse_v1_encoder\", data_key, data_part),\n",
    "        \"sample_idx\": 0,\n",
    "        \"stats\": RunningStats(num_components=encoder.readout[data_key].outdims, lib=\"torch\", device=config[\"device\"]),\n",
    "    },\n",
    "    # { ### noise to resp\n",
    "    #     \"name\": \"01noise_resp\n",
    "    #     \"stim\": lambda x: x,\n",
    "    #     \"resp\": lambda x: x + torch.randn(x.shape) * 0.1,\n",
    "    #     \"save_dir\": os.path.join(DATA_PATH, \"synthetic_data_mouse_v1_encoder\", data_part + \"_01noise_resp\"),\n",
    "    #     \"sample_idx\": 0,\n",
    "    #     \"stats\": RunningStats(num_components=10000, lib=\"torch\", device=config[\"device\"]),\n",
    "    # },\n",
    "    # { ### flip stim\n",
    "    #     \"name\": \"flip_stim\",\n",
    "    #     \"stim\": lambda x: x.flip(2),\n",
    "    #     \"resp\": lambda x: x,\n",
    "    #     \"save_dir\": os.path.join(DATA_PATH, \"synthetic_data_mouse_v1_encoder\", data_part + \"_flip_stim\"),\n",
    "    #     \"sample_idx\": 0,\n",
    "    #     \"stats\": RunningStats(num_components=10000, lib=\"torch\", device=config[\"device\"]),\n",
    "    # },\n",
    "    # { ### rotate stim\n",
    "    #     \"name\": \"01rotate_stim\",\n",
    "    #     \"stim\": lambda x: torch.rot90(x, 1, (1, 2)),\n",
    "    #     \"resp\": lambda x: x,\n",
    "    #     \"save_dir\": os.path.join(DATA_PATH, \"synthetic_data_mouse_v1_encoder\", data_part + \"_01rotate_stim\"),\n",
    "    #     \"sample_idx\": 0,\n",
    "    #     \"stats\": RunningStats(num_components=10000, lib=\"torch\", device=config[\"device\"]),\n",
    "    # },\n",
    "    # { ### rotate stim\n",
    "    #     \"name\": \"02rotate_stim\",\n",
    "    #     \"stim\": lambda x: torch.rot90(x, 2, (1, 2)),\n",
    "    #     \"resp\": lambda x: x,\n",
    "    #     \"save_dir\": os.path.join(DATA_PATH, \"synthetic_data_mouse_v1_encoder\", data_part + \"_02rotate_stim\"),\n",
    "    #     \"sample_idx\": 0,\n",
    "    #     \"stats\": RunningStats(num_components=10000, lib=\"torch\", device=config[\"device\"]),\n",
    "    # },\n",
    "    # { ### rotate stim\n",
    "    #     \"name\": \"03rotate_stim\",\n",
    "    #     \"stim\": lambda x: torch.rot90(x, 3, (1, 2)),\n",
    "    #     \"resp\": lambda x: x,\n",
    "    #     \"save_dir\": os.path.join(DATA_PATH, \"synthetic_data_mouse_v1_encoder\", data_part + \"_03rotate_stim\"),\n",
    "    #     \"sample_idx\": 0,\n",
    "    #     \"stats\": RunningStats(num_components=10000, lib=\"torch\", device=config[\"device\"]),\n",
    "    # },\n",
    "]\n",
    "\n",
    "### create dirs\n",
    "for tran_to_apply in trans_to_apply:\n",
    "    if os.path.exists(tran_to_apply[\"save_dir\"]) and len(os.listdir(tran_to_apply[\"save_dir\"])) > 0:\n",
    "        print(f\"[WARNING]: {tran_to_apply['save_dir']} already exists and is not empty.\")\n",
    "    os.makedirs(tran_to_apply[\"save_dir\"], exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_batches = len(dataloaders[\"mouse_v1\"][data_part])\n",
    "\n",
    "with torch.no_grad():\n",
    "    ### run\n",
    "    for batch_idx, b in enumerate(dataloaders[\"mouse_v1\"][data_part]):\n",
    "        for _data_key, (stim, _, neuron_coords, pupil_center) in b.items():\n",
    "            assert _data_key == data_key, f\"Data key mismatch: {data_key} vs. {_data_key}\"\n",
    "            for tran_to_apply in trans_to_apply:\n",
    "                stim = tran_to_apply[\"stim\"](stim.to(config[\"device\"]))\n",
    "\n",
    "                ### forward\n",
    "                resp = encoder(stim, data_key=data_key)\n",
    "                resp = tran_to_apply[\"resp\"](resp)\n",
    "                if save_stats:\n",
    "                    tran_to_apply[\"stats\"].update(resp)\n",
    "\n",
    "                ### save\n",
    "                for i in range(stim.shape[0]):\n",
    "                    sample_path = os.path.join(tran_to_apply[\"save_dir\"], f\"{tran_to_apply['sample_idx']}.pickle\")\n",
    "                    with open(sample_path, \"wb\") as f:\n",
    "                        pickle.dump({\n",
    "                            \"stim\": stim[i].cpu(),\n",
    "                            \"resp\": resp[i].cpu(),\n",
    "                            \"pupil_center\": pupil_center[i].cpu(),\n",
    "                        }, f)\n",
    "                    tran_to_apply[\"sample_idx\"] += 1\n",
    "\n",
    "        ### log\n",
    "        if batch_idx % 50 == 0:\n",
    "            print(f\"Batch {batch_idx}/{n_batches}\")\n",
    "\n",
    "## save stats of responses\n",
    "if save_stats:\n",
    "    for tran_to_apply in trans_to_apply:\n",
    "        np.save(\n",
    "            os.path.join(DATA_PATH, \"synthetic_data_mouse_v1_encoder\", data_key, f\"responses_mean_{tran_to_apply['name']}.npy\"),\n",
    "            tran_to_apply[\"stats\"].get_mean().cpu().numpy(),\n",
    "        )\n",
    "        np.save(\n",
    "            os.path.join(DATA_PATH, \"synthetic_data_mouse_v1_encoder\", data_key, f\"responses_std_{tran_to_apply['name']}.npy\"),\n",
    "            tran_to_apply[\"stats\"].get_std().cpu().numpy(),\n",
    "        )\n",
    "\n",
    "## save neuron_coords\n",
    "p = os.path.join(DATA_PATH, \"synthetic_data_mouse_v1_encoder\", data_key, f\"neuron_coords.npy\")\n",
    "np.save(p, neuron_coords.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### load\n",
    "# resp_mean = torch.from_numpy(np.load(os.path.join(DATA_PATH, \"synthetic_data_mouse_v1_encoder\", target_data_key, f\"responses_mean_original.npy\"))).float()\n",
    "resp_std = torch.from_numpy(np.load(os.path.join(DATA_PATH, \"synthetic_data_mouse_v1_encoder\", data_key, f\"responses_std_original.npy\"))).float()\n",
    "\n",
    "div_by = resp_std.clone()\n",
    "thres = 0.01 * resp_std.mean()\n",
    "idx = resp_std <= thres\n",
    "div_by[idx] = thres\n",
    "\n",
    "dataset = PerSampleStoredDataset(\n",
    "    dataset_dir=os.path.join(DATA_PATH, \"synthetic_data_mouse_v1_encoder\", data_key, data_part),\n",
    "    stim_transform=lambda x: x, # stim is already normalized\n",
    "    resp_transform=csng.utils.Normalize(\n",
    "        # mean=resp_mean,\n",
    "        mean=0,\n",
    "        std=div_by,\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = RunningStats(num_components=resp.shape[-1], lib=\"torch\", device=\"cpu\")\n",
    "for b, (s, r, pc) in enumerate(dataloader):\n",
    "    # stats.update(s.view(s.shape[0], -1))\n",
    "    stats.update(r)\n",
    "    if b % 50 == 0:\n",
    "        print(f\"Batch {b} processed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.get_mean(), stats.get_std()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
