{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from copy import deepcopy\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import GaussianBlur\n",
    "import lovely_tensors as lt\n",
    "from nnfabrik.builder import get_data\n",
    "from lurz2020.datasets.mouse_loaders import static_loaders\n",
    "from lurz2020.models.models import se2d_fullgaussian2d\n",
    "from lurz2020.training.trainers import standard_trainer as trainer\n",
    "from lurz2020.utility.measures import get_correlations, get_fraction_oracles\n",
    "\n",
    "import csng\n",
    "from csng.CNN_Decoder import CNN_Decoder\n",
    "from csng.utils import crop, plot_comparison, standardize, normalize, get_mean_and_std, count_parameters\n",
    "from csng.losses import SSIMLoss, MSELossWithCrop\n",
    "from csng.data import MixedBatchLoader\n",
    "\n",
    "from data_utils import get_mouse_v1_data, PerSampleStoredDataset\n",
    "\n",
    "lt.monkey_patch()\n",
    "\n",
    "DATA_PATH = os.path.join(os.environ[\"DATA_PATH\"], \"mouse_v1_sensorium22\")\n",
    "print(f\"{DATA_PATH=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"data\": {\n",
    "        \"mixing_strategy\": \"parallel_min\", # needed only with multiple base dataloaders\n",
    "    },\n",
    "    \"device\": \"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    "    \"seed\": 0,\n",
    "    \"crop_win\": (22, 36),\n",
    "}\n",
    "\n",
    "print(f\"... Running on {config['device']} ...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(config[\"seed\"])\n",
    "torch.manual_seed(config[\"seed\"])\n",
    "random.seed(config[\"seed\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = [ # from https://gin.g-node.org/cajal/Sensorium2022/src/master\n",
    "    \"static26872-17-20-GrayImageNet-94c6ff995dac583098847cfecd43e7b6.zip\", # mouse 1\n",
    "    \"static27204-5-13-GrayImageNet-94c6ff995dac583098847cfecd43e7b6.zip\", # sensorium+ (mouse 2)\n",
    "    \"static21067-10-18-GrayImageNet-94c6ff995dac583098847cfecd43e7b6.zip\", # pretraining (mouse 3)\n",
    "    \"static22846-10-16-GrayImageNet-94c6ff995dac583098847cfecd43e7b6.zip\", # pretraining (mouse 4)\n",
    "    \"static23343-5-17-GrayImageNet-94c6ff995dac583098847cfecd43e7b6.zip\", # pretraining (mouse 5)\n",
    "    \"static23656-14-22-GrayImageNet-94c6ff995dac583098847cfecd43e7b6.zip\", # pretraining (mouse 6)\n",
    "    \"static23964-4-22-GrayImageNet-94c6ff995dac583098847cfecd43e7b6.zip\", # pretraining (mouse 7)\n",
    "]\n",
    "for f_idx, f_name in enumerate(filenames):\n",
    "    filenames[f_idx] = os.path.join(DATA_PATH, f_name)\n",
    "\n",
    "config[\"data\"].update({\n",
    "    \"paths\": filenames,\n",
    "    \"dataset_fn\": \"sensorium.datasets.static_loaders\",\n",
    "    \"dataset_config\": {\n",
    "        \"paths\": filenames,\n",
    "        \"normalize\": True,\n",
    "        \"scale\": 0.25, # 256x144 -> 64x36\n",
    "        \"include_behavior\": False,\n",
    "        \"add_behavior_as_channels\": False,\n",
    "        \"include_eye_position\": False,\n",
    "        \"exclude\": None,\n",
    "        \"file_tree\": True,\n",
    "        \"cuda\": False,\n",
    "        \"batch_size\": 64,\n",
    "        \"seed\": config[\"seed\"],\n",
    "        \"use_cache\": False,\n",
    "    },\n",
    "})\n",
    "\n",
    "dataloaders = get_data(config[\"data\"][\"dataset_fn\"], config[\"data\"][\"dataset_config\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config[\"encoder\"] = {\n",
    "    \"model_config\": {\n",
    "        \"init_mu_range\": 0.55,\n",
    "        \"init_sigma\": 0.4,\n",
    "        \"input_kern\": 15,\n",
    "        \"hidden_kern\": 13,\n",
    "        \"gamma_input\": 1.0,\n",
    "        \"grid_mean_predictor\": {\n",
    "            \"type\": \"cortex\",\n",
    "            \"input_dimensions\": 2,\n",
    "            \"hidden_layers\": 0,\n",
    "            \"hidden_features\": 0,\n",
    "            \"final_tanh\": False\n",
    "        },\n",
    "        \"gamma_readout\": 2.439,\n",
    "    },\n",
    "    # \"load_ckpt\": \"../Lurz_2020_code/notebooks/models/transfer_model.pth.tar\",\n",
    "    \"load_ckpt\": None,\n",
    "    \"trainer_config\": {\n",
    "        \"track_training\": True,\n",
    "        \"detach_core\": False, # detach core of encoder (not fine-tune)\n",
    "        \"max_iter\": 300,\n",
    "        \"patience\": 10,\n",
    "        \"device\": config[\"device\"],\n",
    "    }\n",
    "}\n",
    "model = se2d_fullgaussian2d(**config[\"encoder\"][\"model_config\"], dataloaders=dataloaders, seed=config[\"seed\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### load pretrained model (from Lurz et al. 2020)\n",
    "if config[\"encoder\"][\"load_ckpt\"] is not None:\n",
    "    ckpt_transfer = torch.load(config[\"encoder\"][\"load_ckpt\"])\n",
    "    model.load_state_dict(ckpt_transfer, strict=False)\n",
    "    print(f\"Loaded pretrained model from {config['encoder']['load_ckpt']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### train\n",
    "score, output, model_state = trainer(\n",
    "    model=model,\n",
    "    dataloaders=dataloaders,\n",
    "    seed=config[\"seed\"],\n",
    "    **config[\"encoder\"][\"trainer_config\"]\n",
    ")\n",
    "\n",
    "### save the model state\n",
    "torch.save({\n",
    "    \"encoder_state\": model_state,\n",
    "    \"config\": config,\n",
    "    \"history\": output,\n",
    "    \"score\": score,\n",
    "}, \"model_state.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### eval - train encoder from scratch (no pretrained weights)\n",
    "train_correlation = get_correlations(model, dataloaders[\"train\"], device=config[\"device\"], as_dict=False, per_neuron=False)\n",
    "validation_correlation = get_correlations(model, dataloaders[\"validation\"], device=config[\"device\"], as_dict=False, per_neuron=False)\n",
    "test_correlation = get_correlations(model, dataloaders[\"test\"], device=config[\"device\"], as_dict=False, per_neuron=False)\n",
    "\n",
    "print(f\"Correlation (train set):      {train_correlation:.3f}\")\n",
    "print(f\"Correlation (validation set): {validation_correlation:.3f}\")\n",
    "print(f\"Correlation (test set):       {test_correlation:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### eval - train encoder with the core frozen\n",
    "train_correlation = get_correlations(model, dataloaders[\"train\"], device=config[\"device\"], as_dict=False, per_neuron=False)\n",
    "validation_correlation = get_correlations(model, dataloaders[\"validation\"], device=config[\"device\"], as_dict=False, per_neuron=False)\n",
    "test_correlation = get_correlations(model, dataloaders[\"test\"], device=config[\"device\"], as_dict=False, per_neuron=False)\n",
    "\n",
    "print(f\"Correlation (train set):      {train_correlation:.3f}\")\n",
    "print(f\"Correlation (validation set): {validation_correlation:.3f}\")\n",
    "print(f\"Correlation (test set):       {test_correlation:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### eval - train encoder with the core unfrozen\n",
    "train_correlation = get_correlations(model, dataloaders[\"train\"], device=config[\"device\"], as_dict=False, per_neuron=False)\n",
    "validation_correlation = get_correlations(model, dataloaders[\"validation\"], device=config[\"device\"], as_dict=False, per_neuron=False)\n",
    "test_correlation = get_correlations(model, dataloaders[\"test\"], device=config[\"device\"], as_dict=False, per_neuron=False)\n",
    "\n",
    "print(f\"Correlation (train set):      {train_correlation:.3f}\")\n",
    "print(f\"Correlation (validation set): {validation_correlation:.3f}\")\n",
    "print(f\"Correlation (test set):       {test_correlation:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoder Inversion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### prep data config\n",
    "filenames = [ # from https://gin.g-node.org/cajal/Sensorium2022/src/master\n",
    "    # \"static26872-17-20-GrayImageNet-94c6ff995dac583098847cfecd43e7b6.zip\", # mouse 1\n",
    "    # \"static27204-5-13-GrayImageNet-94c6ff995dac583098847cfecd43e7b6.zip\", # sensorium+ (mouse 2)\n",
    "    \"static21067-10-18-GrayImageNet-94c6ff995dac583098847cfecd43e7b6.zip\", # pretraining (mouse 3)\n",
    "    # \"static22846-10-16-GrayImageNet-94c6ff995dac583098847cfecd43e7b6.zip\", # pretraining (mouse 4)\n",
    "    # \"static23343-5-17-GrayImageNet-94c6ff995dac583098847cfecd43e7b6.zip\", # pretraining (mouse 5)\n",
    "    # \"static23656-14-22-GrayImageNet-94c6ff995dac583098847cfecd43e7b6.zip\", # pretraining (mouse 6)\n",
    "    # \"static23964-4-22-GrayImageNet-94c6ff995dac583098847cfecd43e7b6.zip\", # pretraining (mouse 7)\n",
    "]\n",
    "for f_idx, f_name in enumerate(filenames):\n",
    "    filenames[f_idx] = os.path.join(DATA_PATH, f_name)\n",
    "\n",
    "config[\"data\"].update({\n",
    "    \"paths\": filenames,\n",
    "    \"dataset_fn\": \"sensorium.datasets.static_loaders\",\n",
    "    \"dataset_config\": {\n",
    "        \"paths\": filenames,\n",
    "        \"normalize\": True,\n",
    "        \"scale\": 0.25, # 256x144 -> 64x36\n",
    "        \"include_behavior\": False,\n",
    "        \"add_behavior_as_channels\": False,\n",
    "        \"include_eye_position\": True,\n",
    "        \"exclude\": None,\n",
    "        \"file_tree\": True,\n",
    "        \"cuda\": False,\n",
    "        # \"batch_size\": 32,\n",
    "        \"batch_size\": 7,\n",
    "        \"seed\": config[\"seed\"],\n",
    "        \"use_cache\": False,\n",
    "    },\n",
    "    \"normalize_neuron_coords\": True,\n",
    "})\n",
    "\n",
    "### get dataloaders and cell coordinates\n",
    "dataloaders, neuron_coords = get_mouse_v1_data(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### show data\n",
    "sample_data_key = dataloaders[\"mouse_v1\"][\"val\"].data_keys[0]\n",
    "datapoint = next(iter(dataloaders[\"mouse_v1\"][\"val\"].dataloaders[0]))\n",
    "stim, resp = datapoint.images, datapoint.responses\n",
    "pupil_center = datapoint.pupil_center\n",
    "print(\n",
    "    f\"Training dataset:\\t {sum(len(dl) * config['data']['dataset_config']['batch_size'] for dl in dataloaders['mouse_v1']['train'].dataloaders)} samples\"\n",
    "    f\"\\nValidation dataset:\\t {sum(len(dl) * config['data']['dataset_config']['batch_size'] for dl in dataloaders['mouse_v1']['val'].dataloaders)} samples\"\n",
    "    f\"\\nTest dataset:\\t\\t {sum(len(dl) * config['data']['dataset_config']['batch_size'] for dl in dataloaders['mouse_v1']['test'].dataloaders)} samples\"\n",
    "    f\"\\nTest (no resp) dataset:\\t {sum(len(dl) * config['data']['dataset_config']['batch_size'] for dl in dataloaders['mouse_v1']['test_no_resp'].dataloaders)} samples\"\n",
    "\n",
    "    \"\\n\\nstimuli:\"\n",
    "    f\"\\n  {stim.shape}\"\n",
    "    f\"\\n  min={stim.min().item():.3f}  max={stim.max().item():.3f}\"\n",
    "    f\"\\n  mean={stim.mean().item():.3f}  std={stim.std().item():.3f}\"\n",
    "    \"\\nresponses:\"\n",
    "    f\"\\n  {resp.shape}\"\n",
    "    f\"\\n  min={resp.min().item():.3f}  max={resp.max().item():.3f}\"\n",
    "    f\"\\n  mean={resp.mean().item():.3f}  std={resp.std().item():.3f}\"\n",
    "    \"\\nneuronal coordinates:\"\n",
    "    f\"\\n  {neuron_coords[sample_data_key].shape}\"\n",
    "    f\"\\n  min={neuron_coords[sample_data_key].min():.3f}  max={neuron_coords[sample_data_key].max():.3f}\"\n",
    "    f\"\\n  mean={neuron_coords[sample_data_key].mean():.3f}  std={neuron_coords[sample_data_key].std():.3f}\"\n",
    ")\n",
    "\n",
    "### plot sample data\n",
    "sample_idx = 0\n",
    "\n",
    "fig = plt.figure(figsize=(16, 6))\n",
    "ax = fig.add_subplot(121)\n",
    "ax.imshow(stim[sample_idx].squeeze().unsqueeze(-1).cpu(), cmap=\"gray\")\n",
    "\n",
    "# ax = fig.add_subplot(122)\n",
    "# reshape_to = None\n",
    "# for i in range(30, 150):\n",
    "#     if resp.shape[-1] % i == 0:\n",
    "#         reshape_to = (i, resp.shape[-1] // i)\n",
    "#         break\n",
    "# if reshape_to != None:\n",
    "#     ax.imshow(resp[0].view(reshape_to).squeeze(0).unsqueeze(-1).cpu(), cmap=\"gray\")\n",
    "\n",
    "### bin the neuronal responses based on their neuron coordinates and sum within each bin -> 2D grid of vals\n",
    "coords = neuron_coords[sample_data_key]\n",
    "H, W = stim.shape[-2:] # the size of the grid\n",
    "n_x_bins, n_y_bins = 32, 18 # number of bins in each dimension\n",
    "min_x, max_x, min_y, max_y = coords[:,0].min().item(), coords[:,0].max().item(), coords[:,1].min().item(), coords[:,1].max().item()\n",
    "x_bins = torch.linspace(min_x, max_x, n_x_bins + 1)\n",
    "y_bins = torch.linspace(min_y, max_y, n_y_bins + 1)\n",
    "binned_resp = torch.zeros(n_y_bins, n_x_bins)\n",
    "for i in range(n_x_bins):\n",
    "    for j in range(n_y_bins):\n",
    "        ### mask of the neurons in the bin\n",
    "        mask = (x_bins[i] <= coords[:,0]) &\\\n",
    "               (coords[:,0] < x_bins[i + 1]) &\\\n",
    "               (y_bins[j] <= coords[:,1]) &\\\n",
    "               (coords[:,1] < y_bins[j + 1])\n",
    "        binned_resp[j,i] = resp[sample_idx, mask.cpu()].sum(0)\n",
    "ax = fig.add_subplot(122)\n",
    "ax.imshow(binned_resp.squeeze().cpu(), cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### load encoder\n",
    "print(\"Loading encoder...\")\n",
    "\n",
    "from lurz2020.models.models import se2d_fullgaussian2d\n",
    "\n",
    "### load pretrained encoder ckpt\n",
    "encoder_ckpt = torch.load(\n",
    "    os.path.join(DATA_PATH, \"models\", \"encoder.pt\"),\n",
    "    map_location=config[\"device\"],\n",
    ")\n",
    "\n",
    "### get temporary dataloaders for the encoder\n",
    "_dataloaders = get_data(\n",
    "    encoder_ckpt[\"config\"][\"data\"][\"dataset_fn\"],\n",
    "    encoder_ckpt[\"config\"][\"data\"][\"dataset_config\"]\n",
    ")\n",
    "\n",
    "### init encoder\n",
    "encoder = se2d_fullgaussian2d(\n",
    "    **encoder_ckpt[\"config\"][\"encoder\"][\"model_config\"],\n",
    "    dataloaders=_dataloaders,\n",
    "    seed=encoder_ckpt[\"config\"][\"seed\"],\n",
    ").float()\n",
    "encoder.load_state_dict(encoder_ckpt[\"encoder_state\"], strict=True)\n",
    "encoder.to(config[\"device\"])\n",
    "encoder.eval()\n",
    "del _dataloaders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run Inversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config[\"enc_inv\"] = {\n",
    "    \"init\": \"zeros\",\n",
    "    \"n_inits\": 1,\n",
    "    \"n_steps\": 200,\n",
    "    \"opter_cls\": torch.optim.SGD,\n",
    "    # \"opter_cls\": torch.optim.Adam,\n",
    "    \"opter_kwargs\": {\"lr\": 1.},\n",
    "    \"resp_loss_fn\": nn.MSELoss(),\n",
    "    \"stim_loss_fn\": SSIMLoss(\n",
    "        window=config[\"crop_win\"],\n",
    "        log_loss=True,\n",
    "        inp_normalized=True,\n",
    "        inp_standardized=False,\n",
    "    ),\n",
    "    # \"blur\": None,\n",
    "    \"blur\": GaussianBlur(\n",
    "        kernel_size=5,\n",
    "        sigma=1,\n",
    "    ),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_stim = stim.float().to(config[\"device\"])\n",
    "target_resp = resp.float().to(config[\"device\"])\n",
    "data_key = sample_data_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_enc_inversion(config, stim_shape):\n",
    "    if config[\"enc_inv\"][\"init\"] == \"rand\":\n",
    "        # stim_pred = torch.rand_like(target_stim, device=config[\"device\"])\n",
    "        stim_pred = torch.rand(stim_shape, device=config[\"device\"])\n",
    "    elif config[\"enc_inv\"][\"init\"] == \"randn\":\n",
    "        # stim_pred = torch.randn_like(target_stim, device=config[\"device\"])\n",
    "        stim_pred = torch.randn(stim_shape, device=config[\"device\"])\n",
    "    elif config[\"enc_inv\"][\"init\"] == \"zeros\":\n",
    "        # stim_pred = torch.zeros_like(target_stim, device=config[\"device\"])\n",
    "        stim_pred = torch.zeros(stim_shape, device=config[\"device\"])\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown init method: {config['enc_inv']['init']}\")\n",
    "    stim_pred = stim_pred.requires_grad_(True)\n",
    "    opter = config[\"enc_inv\"][\"opter_cls\"](\n",
    "        [stim_pred], **config[\"enc_inv\"][\"opter_kwargs\"],\n",
    "    )\n",
    "    return stim_pred, opter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss_history(history):\n",
    "    fig = plt.figure(figsize=(16, 6))\n",
    "    ax = fig.add_subplot(121)\n",
    "    ax.plot(history[\"resp_loss\"])\n",
    "    ax.set_title(\"resp_loss\")\n",
    "\n",
    "    ax = fig.add_subplot(122)\n",
    "    ax.plot(history[\"stim_loss\"])\n",
    "    ax.set_title(\"stim_loss\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_inversion(target_resp, data_key, encoder, config, target_stim, log_freq=100, plot_loss=True):\n",
    "    stim_preds = []\n",
    "    histories = []\n",
    "\n",
    "    for init_i in range(config[\"enc_inv\"][\"n_inits\"]):\n",
    "        # print(f\"Init {init_i}\")\n",
    "\n",
    "        ### init decoded img and optimizer\n",
    "        stim_pred, opter = init_enc_inversion(config=config, stim_shape=target_stim.shape)\n",
    "        # plot_comparison(target=target_stim[:8].cpu(), pred=stim_pred[:8].detach().cpu())\n",
    "\n",
    "        ### inversion\n",
    "        history = {\"resp_loss\": [], \"stim_loss\": [], \"best\": {\"stim_loss\": np.inf, \"stim_pred\": None}}\n",
    "        for step_i in range(config[\"enc_inv\"][\"n_steps\"]):\n",
    "            opter.zero_grad()\n",
    "\n",
    "            resp_pred = encoder(stim_pred, data_key=data_key).float()\n",
    "            resp_loss = config[\"enc_inv\"][\"resp_loss_fn\"](resp_pred, target_resp)\n",
    "            resp_loss.backward()\n",
    "            \n",
    "            ### blur the gradient image\n",
    "            if config[\"enc_inv\"][\"blur\"] is not None:\n",
    "                stim_pred.grad = config[\"enc_inv\"][\"blur\"](stim_pred.grad)\n",
    "            \n",
    "            ### update\n",
    "            opter.step()\n",
    "            stim_loss = config[\"enc_inv\"][\"stim_loss_fn\"](stim_pred, target_stim)\n",
    "\n",
    "            ### save best\n",
    "            if stim_loss.item() < history[\"best\"][\"stim_loss\"]:\n",
    "                history[\"best\"][\"stim_loss\"] = stim_loss.item()\n",
    "                history[\"best\"][\"stim_pred\"] = stim_pred.detach().clone().cpu()\n",
    "\n",
    "            ### log\n",
    "            history[\"resp_loss\"].append(resp_loss.item())\n",
    "            history[\"stim_loss\"].append(stim_loss.item())\n",
    "            if log_freq is not None and (step_i + 1) % log_freq == 0:\n",
    "                print(f\"[{init_i}: {step_i + 1}/{config['enc_inv']['n_steps']}]:  resp_loss={resp_loss.item():.3f}  stim_loss={stim_loss.item():.3f}\")\n",
    "                plot_comparison(target=crop(target_stim[:8], config[\"crop_win\"]).cpu(),\n",
    "                                pred=crop(stim_pred[:8], config[\"crop_win\"]).detach().cpu())\n",
    "\n",
    "        ### plot loss history\n",
    "        if plot_loss:\n",
    "            plot_loss_history(history=history)\n",
    "\n",
    "        stim_preds.append(stim_pred.detach().cpu())\n",
    "        histories.append(history)\n",
    "    \n",
    "    return stim_preds, histories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stim_preds, histories = run_inversion(\n",
    "    target_resp=target_resp,\n",
    "    data_key=data_key,\n",
    "    encoder=encoder,\n",
    "    config=config,\n",
    "    target_stim=target_stim,\n",
    "    log_freq=500,\n",
    "    plot_loss=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stim_pred = histories[0][\"best\"][\"stim_pred\"]\n",
    "plot_comparison(target=crop(target_stim[:8], config[\"crop_win\"]).cpu(), pred=crop(stim_pred[:8], config[\"crop_win\"]).detach().cpu())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparam search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### hyperparam configs\n",
    "config_updates = [\n",
    "    {\"opter_kwargs\": {\"lr\": 1000}, \"blur\": GaussianBlur(kernel_size=3, sigma=2.5)},\n",
    "    {\"opter_kwargs\": {\"lr\": 1000}, \"blur\": GaussianBlur(kernel_size=5, sigma=2.5)},\n",
    "    {\"opter_kwargs\": {\"lr\": 1000}, \"blur\": GaussianBlur(kernel_size=7, sigma=2.5)},\n",
    "    {\"opter_kwargs\": {\"lr\": 1000}, \"blur\": GaussianBlur(kernel_size=9, sigma=2.5)},\n",
    "    {\"opter_kwargs\": {\"lr\": 1000}, \"blur\": GaussianBlur(kernel_size=11, sigma=2.5)},\n",
    "    {\"opter_kwargs\": {\"lr\": 1000}, \"blur\": GaussianBlur(kernel_size=15, sigma=2.5)},\n",
    "    {\"opter_kwargs\": {\"lr\": 1000}, \"blur\": GaussianBlur(kernel_size=17, sigma=2.5)},\n",
    "    {\"opter_kwargs\": {\"lr\": 1000}, \"blur\": GaussianBlur(kernel_size=21, sigma=2.5)},\n",
    "    {\"opter_kwargs\": {\"lr\": 1000}, \"blur\": GaussianBlur(kernel_size=25, sigma=2.5)},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ker_sz = 3\n",
    "print(0.3 * ((ker_sz - 1) * 0.5 - 1) + 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### run\n",
    "results = []\n",
    "for i, config_update in enumerate(config_updates):\n",
    "    print(f\"[{i+1}/{len(config_updates)}]\")\n",
    "    run_config = deepcopy(config)\n",
    "    run_config[\"enc_inv\"].update(config_update)\n",
    "    stim_preds, histories = run_inversion(\n",
    "        target_resp=target_resp,\n",
    "        data_key=data_key,\n",
    "        encoder=encoder,\n",
    "        config=run_config,\n",
    "        target_stim=target_stim,\n",
    "        log_freq=None,\n",
    "        plot_loss=False,\n",
    "    )\n",
    "    results.append({\"run_config\": run_config, \"stim_preds\": stim_preds, \"histories\": histories})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for r in results:\n",
    "    print(\n",
    "        f\"lr={r['run_config']['enc_inv']['opter_kwargs']['lr']}\"\n",
    "        f\", sigma={r['run_config']['enc_inv']['blur'].sigma[0]}\"\n",
    "        f\", ker_sz={r['run_config']['enc_inv']['blur'].kernel_size[0]}\"\n",
    "        f\"   {r['histories'][0]['best']['stim_loss']:.5f}\"\n",
    "    )\n",
    "\n",
    "    ### plot loss history\n",
    "    plot_loss_history(history=r[\"histories\"][0])\n",
    "\n",
    "    ### plot best results\n",
    "    plot_comparison(target=crop(target_stim[:8], config[\"crop_win\"]).cpu(),\n",
    "                    pred=crop(r['histories'][0]['best']['stim_pred'][:8], config[\"crop_win\"]).cpu())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
