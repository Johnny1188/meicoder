{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"DATA_PATH\"] = \"/home/sobotj11/decoding-brain-activity/data\"\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from copy import deepcopy\n",
    "import dill\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "import lovely_tensors as lt\n",
    "from nnfabrik.builder import get_data\n",
    "from focal_frequency_loss import FocalFrequencyLoss as FFL\n",
    "\n",
    "import csng\n",
    "from csng.InvertedEncoder import InvertedEncoder\n",
    "from csng.CNN_Decoder import CNN_Decoder\n",
    "from csng.utils import crop, plot_comparison, standardize, normalize, get_mean_and_std, count_parameters, plot_losses\n",
    "from csng.losses import (\n",
    "    MultiSSIMLoss,\n",
    "    SSIMLoss,\n",
    "    CroppedLoss,\n",
    "    Loss,\n",
    "    MS_SSIMLoss,\n",
    "    PerceptualLoss,\n",
    "    EncoderPerceptualLoss,\n",
    "    VGGPerceptualLoss,\n",
    ")\n",
    "from csng.data import MixedBatchLoader\n",
    "from csng.readins import (\n",
    "    MultiReadIn,\n",
    "    HypernetReadIn,\n",
    "    ConvReadIn,\n",
    "    AttentionReadIn,\n",
    "    FCReadIn,\n",
    "    AutoEncoderReadIn,\n",
    "    Conv1dReadIn,\n",
    ")\n",
    "\n",
    "# from BoostedInvertedEncoder import BoostedInvertedEncoder\n",
    "from encoder import get_encoder\n",
    "from data_utils import get_mouse_v1_data, PerSampleStoredDataset, append_syn_dataloaders, append_data_aug_dataloaders\n",
    "from comparison_utils import (\n",
    "    eval_decoder,\n",
    "    get_all_data,\n",
    "    plot_reconstructions,\n",
    "    plot_metrics,\n",
    "    plot_over_training,\n",
    "    plot_reconstructions_publication,\n",
    "    plot_metrics_publication,\n",
    ")\n",
    "\n",
    "lt.monkey_patch()\n",
    "\n",
    "DATA_PATH = os.path.join(os.environ[\"DATA_PATH\"], \"mouse_v1_sensorium22\")\n",
    "print(f\"{DATA_PATH=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"data\": {\n",
    "        \"mixing_strategy\": \"sequential\", # needed only with multiple base dataloaders\n",
    "    },\n",
    "    \"device\": \"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    "    \"seed\": 0,\n",
    "    \"crop_win\": (22, 36),\n",
    "}\n",
    "print(f\"... Running on {config['device']} ...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(config[\"seed\"])\n",
    "torch.manual_seed(config[\"seed\"])\n",
    "random.seed(config[\"seed\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloaders = dict()\n",
    "config[\"data\"][\"mouse_v1\"] = None\n",
    "config[\"data\"][\"syn_dataset_config\"] = None\n",
    "config[\"data\"][\"data_augmentation\"] = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mouse V1 dataset (Sensorium 2022)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### prep data config\n",
    "config[\"data\"][\"mouse_v1\"] = {\n",
    "    \"dataset_fn\": \"sensorium.datasets.static_loaders\",\n",
    "    \"dataset_config\": {\n",
    "        \"paths\": [ # from https://gin.g-node.org/cajal/Sensorium2022/src/master\n",
    "            # os.path.join(DATA_PATH, \"static26872-17-20-GrayImageNet-94c6ff995dac583098847cfecd43e7b6.zip\"), # mouse 1\n",
    "            # os.path.join(DATA_PATH, \"static27204-5-13-GrayImageNet-94c6ff995dac583098847cfecd43e7b6.zip\"), # sensorium+ (mouse 2)\n",
    "            os.path.join(DATA_PATH, \"static21067-10-18-GrayImageNet-94c6ff995dac583098847cfecd43e7b6.zip\"), # pretraining (mouse 3)\n",
    "            # os.path.join(DATA_PATH, \"static22846-10-16-GrayImageNet-94c6ff995dac583098847cfecd43e7b6.zip\"), # pretraining (mouse 4)\n",
    "            # os.path.join(DATA_PATH, \"static23343-5-17-GrayImageNet-94c6ff995dac583098847cfecd43e7b6.zip\"), # pretraining (mouse 5)\n",
    "            # os.path.join(DATA_PATH, \"static23656-14-22-GrayImageNet-94c6ff995dac583098847cfecd43e7b6.zip\"), # pretraining (mouse 6)\n",
    "            # os.path.join(DATA_PATH, \"static23964-4-22-GrayImageNet-94c6ff995dac583098847cfecd43e7b6.zip\"), # pretraining (mouse 7)\n",
    "        ],\n",
    "        \"normalize\": True,\n",
    "        \"scale\": 0.25, # 256x144 -> 64x36\n",
    "        \"include_behavior\": False,\n",
    "        \"add_behavior_as_channels\": False,\n",
    "        \"include_eye_position\": True,\n",
    "        \"exclude\": None,\n",
    "        \"file_tree\": True,\n",
    "        \"cuda\": \"cuda\" in config[\"device\"],\n",
    "        \"batch_size\": 16,\n",
    "        \"seed\": config[\"seed\"],\n",
    "        \"use_cache\": False,\n",
    "    },\n",
    "    \"skip_train\": False,\n",
    "    \"skip_val\": False,\n",
    "    \"skip_test\": False,\n",
    "    \"normalize_neuron_coords\": True,\n",
    "    \"average_test_multitrial\": True,\n",
    "    \"save_test_multitrial\": True,\n",
    "    \"test_batch_size\": 7,\n",
    "    \"device\": config[\"device\"],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### get dataloaders and cell coordinates\n",
    "dataloaders, neuron_coords = get_mouse_v1_data(config[\"data\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### show data\n",
    "sample_data_key = dataloaders[\"mouse_v1\"][\"test\"].data_keys[0]\n",
    "datapoint = next(iter(dataloaders[\"mouse_v1\"][\"test\"].dataloaders[0]))\n",
    "stim, resp = datapoint.images, datapoint.responses\n",
    "pupil_center = datapoint.pupil_center\n",
    "print(\n",
    "    f\"Training dataset:\\t {sum(len(dl) * config['data']['mouse_v1']['dataset_config']['batch_size'] for dl in dataloaders['mouse_v1']['train'].dataloaders)} samples\"\n",
    "    f\"\\nValidation dataset:\\t {sum(len(dl) * config['data']['mouse_v1']['dataset_config']['batch_size'] for dl in dataloaders['mouse_v1']['val'].dataloaders)} samples\"\n",
    "    f\"\\nTest dataset:\\t\\t {sum(len(dl) * config['data']['mouse_v1']['dataset_config']['batch_size'] for dl in dataloaders['mouse_v1']['test'].dataloaders)} samples\"\n",
    "    f\"\\nTest (no resp) dataset:\\t {sum(len(dl) * config['data']['mouse_v1']['dataset_config']['batch_size'] for dl in dataloaders['mouse_v1']['test_no_resp'].dataloaders)} samples\"\n",
    "\n",
    "    \"\\n\\nstimuli:\"\n",
    "    f\"\\n  {stim.shape}\"\n",
    "    f\"\\n  min={stim.min().item():.3f}  max={stim.max().item():.3f}\"\n",
    "    f\"\\n  mean={stim.mean().item():.3f}  std={stim.std().item():.3f}\"\n",
    "    \"\\nresponses:\"\n",
    "    f\"\\n  {resp.shape}\"\n",
    "    f\"\\n  min={resp.min().item():.3f}  max={resp.max().item():.3f}\"\n",
    "    f\"\\n  mean={resp.mean().item():.3f}  std={resp.std().item():.3f}\"\n",
    "    \"\\nneuronal coordinates:\"\n",
    "    f\"\\n  {neuron_coords[sample_data_key].shape}\"\n",
    "    f\"\\n  min={neuron_coords[sample_data_key].min():.3f}  max={neuron_coords[sample_data_key].max():.3f}\"\n",
    "    f\"\\n  mean={neuron_coords[sample_data_key].mean():.3f}  std={neuron_coords[sample_data_key].std():.3f}\"\n",
    ")\n",
    "\n",
    "### plot sample data\n",
    "sample_idx = 0\n",
    "\n",
    "fig = plt.figure(figsize=(16, 6))\n",
    "ax = fig.add_subplot(131)\n",
    "ax.imshow(stim[sample_idx].squeeze().unsqueeze(-1).cpu(), cmap=\"gray\")\n",
    "\n",
    "ax = fig.add_subplot(132)\n",
    "ax.imshow(crop(stim[sample_idx].cpu(), config[\"crop_win\"]).squeeze().unsqueeze(-1), cmap=\"gray\")\n",
    "\n",
    "### bin the neuronal responses based on their neuron coordinates and sum within each bin -> 2D grid of vals\n",
    "coords = neuron_coords[sample_data_key]\n",
    "H, W = stim.shape[-2:] # the size of the grid\n",
    "n_x_bins, n_y_bins = 32, 18 # number of bins in each dimension\n",
    "min_x, max_x, min_y, max_y = coords[:,0].min().item(), coords[:,0].max().item(), coords[:,1].min().item(), coords[:,1].max().item()\n",
    "x_bins = torch.linspace(min_x, max_x, n_x_bins + 1)\n",
    "y_bins = torch.linspace(min_y, max_y, n_y_bins + 1)\n",
    "binned_resp = torch.zeros(n_y_bins, n_x_bins)\n",
    "for i in range(n_y_bins):\n",
    "    for j in range(n_x_bins):\n",
    "        ### mask of the neurons in the bin\n",
    "        mask = (x_bins[j] <= coords[:,0]) &\\\n",
    "               (coords[:,0] < x_bins[j + 1]) &\\\n",
    "               (y_bins[i] <= coords[:,1]) &\\\n",
    "               (coords[:,1] < y_bins[i + 1])\n",
    "        binned_resp[i,j] = resp[sample_idx, mask.cpu()].sum(0)\n",
    "ax = fig.add_subplot(133)\n",
    "ax.imshow(binned_resp.squeeze().cpu(), cmap=\"gray\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### show data\n",
    "sample_data_key = dataloaders[\"mouse_v1\"][\"test\"].data_keys[0]\n",
    "datapoint = next(iter(dataloaders[\"mouse_v1\"][\"test\"].dataloaders[0]))\n",
    "stim, resp = datapoint.images, datapoint.responses\n",
    "pupil_center = datapoint.pupil_center\n",
    "print(\n",
    "    f\"Training dataset:\\t {sum(len(dl) * config['data']['mouse_v1']['dataset_config']['batch_size'] for dl in dataloaders['mouse_v1']['train'].dataloaders)} samples\"\n",
    "    f\"\\nValidation dataset:\\t {sum(len(dl) * config['data']['mouse_v1']['dataset_config']['batch_size'] for dl in dataloaders['mouse_v1']['val'].dataloaders)} samples\"\n",
    "    f\"\\nTest dataset:\\t\\t {sum(len(dl) * config['data']['mouse_v1']['dataset_config']['batch_size'] for dl in dataloaders['mouse_v1']['test'].dataloaders)} samples\"\n",
    "    f\"\\nTest (no resp) dataset:\\t {sum(len(dl) * config['data']['mouse_v1']['dataset_config']['batch_size'] for dl in dataloaders['mouse_v1']['test_no_resp'].dataloaders)} samples\"\n",
    "\n",
    "    \"\\n\\nstimuli:\"\n",
    "    f\"\\n  {stim.shape}\"\n",
    "    f\"\\n  min={stim.min().item():.3f}  max={stim.max().item():.3f}\"\n",
    "    f\"\\n  mean={stim.mean().item():.3f}  std={stim.std().item():.3f}\"\n",
    "    \"\\nresponses:\"\n",
    "    f\"\\n  {resp.shape}\"\n",
    "    f\"\\n  min={resp.min().item():.3f}  max={resp.max().item():.3f}\"\n",
    "    f\"\\n  mean={resp.mean().item():.3f}  std={resp.std().item():.3f}\"\n",
    "    \"\\nneuronal coordinates:\"\n",
    "    f\"\\n  {neuron_coords[sample_data_key].shape}\"\n",
    "    f\"\\n  min={neuron_coords[sample_data_key].min():.3f}  max={neuron_coords[sample_data_key].max():.3f}\"\n",
    "    f\"\\n  mean={neuron_coords[sample_data_key].mean():.3f}  std={neuron_coords[sample_data_key].std():.3f}\"\n",
    ")\n",
    "\n",
    "### plot sample data\n",
    "sample_idx = 0\n",
    "\n",
    "fig = plt.figure(figsize=(16, 6))\n",
    "ax = fig.add_subplot(131)\n",
    "ax.imshow(stim[sample_idx].squeeze().unsqueeze(-1).cpu(), cmap=\"gray\")\n",
    "\n",
    "ax = fig.add_subplot(132)\n",
    "ax.imshow(crop(stim[sample_idx].cpu(), config[\"crop_win\"]).squeeze().unsqueeze(-1), cmap=\"gray\")\n",
    "\n",
    "### bin the neuronal responses based on their neuron coordinates and sum within each bin -> 2D grid of vals\n",
    "coords = neuron_coords[sample_data_key]\n",
    "H, W = stim.shape[-2:] # the size of the grid\n",
    "n_x_bins, n_y_bins = 32, 18 # number of bins in each dimension\n",
    "min_x, max_x, min_y, max_y = coords[:,0].min().item(), coords[:,0].max().item(), coords[:,1].min().item(), coords[:,1].max().item()\n",
    "x_bins = torch.linspace(min_x, max_x, n_x_bins + 1)\n",
    "y_bins = torch.linspace(min_y, max_y, n_y_bins + 1)\n",
    "binned_resp = torch.zeros(n_y_bins, n_x_bins)\n",
    "for i in range(n_y_bins):\n",
    "    for j in range(n_x_bins):\n",
    "        ### mask of the neurons in the bin\n",
    "        mask = (x_bins[j] <= coords[:,0]) &\\\n",
    "               (coords[:,0] < x_bins[j + 1]) &\\\n",
    "               (y_bins[i] <= coords[:,1]) &\\\n",
    "               (coords[:,1] < y_bins[i + 1])\n",
    "        binned_resp[i,j] = resp[sample_idx, mask.cpu()].sum(0)\n",
    "ax = fig.add_subplot(133)\n",
    "ax.imshow(binned_resp.squeeze().cpu(), cmap=\"gray\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = get_encoder(device=config[\"device\"], eval_mode=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare decoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config[\"comparison\"] = {\n",
    "    \"load_best\": False,\n",
    "    # \"load_best\": True,\n",
    "    \"eval_all_ckpts\": True,\n",
    "    # \"eval_all_ckpts\": False,\n",
    "    \"find_best_ckpt_according_to\": None,\n",
    "    \"find_best_ckpt_according_to\": \"Perceptual Loss (VGG16)\",\n",
    "    # \"find_best_ckpt_according_to\": \"SSIML + PSL\",\n",
    "    \"save_dir\": None,\n",
    "    \"save_dir\": os.path.join(\n",
    "        \"results\",\n",
    "        \"table_02\",\n",
    "    ),\n",
    "    \"load_ckpt\": None,\n",
    "    # \"load_ckpt\": {\n",
    "    #     \"path\": os.path.join(\n",
    "    #         \"results\",\n",
    "    #         \"fig1\",\n",
    "    #         \"2024-04-08_15-23-37.pt\",\n",
    "    #     ),\n",
    "    # },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runs_to_compare = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if config[\"comparison\"][\"load_ckpt\"] is not None:\n",
    "    print(f\"Loading checkpoint from {config['comparison']['load_ckpt']['path']}...\")\n",
    "    runs_to_compare.update(\n",
    "        torch.load(config[\"comparison\"][\"load_ckpt\"][\"path\"], map_location=config[\"device\"])\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Encoder Inversion \"\"\"\n",
    "# runs_to_compare[\"Inverted Encoder\"] = torch.load(\"encoder_inversion_eval_all_mice.pt\", pickle_module=dill)[\"Inverted Encoder\"]\n",
    "runs_to_compare[\"Inverted Encoder\"] = {\n",
    "    \"decoder\": InvertedEncoder(\n",
    "        encoder=encoder,\n",
    "        img_dims=stim.shape[1:],\n",
    "        stim_pred_init=\"zeros\",\n",
    "        opter_cls=torch.optim.SGD,\n",
    "        opter_config={\"lr\": 1500, \"momentum\": 0},\n",
    "        n_steps=400,\n",
    "        resp_loss_fn=F.mse_loss,\n",
    "        stim_loss_fn=SSIMLoss(\n",
    "            window=config[\"crop_win\"],\n",
    "            log_loss=True,\n",
    "            inp_normalized=True,\n",
    "            inp_standardized=False,\n",
    "        ),\n",
    "        img_gauss_blur_config=None,\n",
    "        img_grad_gauss_blur_config={\"kernel_size\": 17, \"sigma\": 2},\n",
    "        device=config[\"device\"],\n",
    "    ).to(config[\"device\"]),\n",
    "    \"run_name\": None,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### config for collecting results (2)\n",
    "# ### FCReadIn\n",
    "# \"FCReadIn\": {\n",
    "#     \"run_name\": \"2024-02-25_17-09-59\",\n",
    "#     \"ckpt_path\": os.path.join(DATA_PATH, \"models\", \"cnn\", \"2024-02-25_17-09-59\", \"decoder.pt\"),\n",
    "# },\n",
    "# \"FCReadIn - Autoencoding\": {\n",
    "#     \"run_name\": \"2024-02-27_00-27-17\",\n",
    "#     \"ckpt_path\": os.path.join(DATA_PATH, \"models\", \"cnn\", \"2024-02-27_00-27-17\", \"decoder.pt\"),\n",
    "# },\n",
    "# \"FCReadIn - Contrastive reg.\": {\n",
    "#     \"run_name\": \"2024-02-28_21-27-46\",\n",
    "#     \"ckpt_path\": os.path.join(DATA_PATH, \"models\", \"cnn\", \"2024-02-28_21-27-46\", \"decoder.pt\"),\n",
    "# },\n",
    "\n",
    "# ### ConvReadIn\n",
    "# \"ConvReadIn\": {\n",
    "#     \"run_name\": \"2024-02-25_21-16-59\",\n",
    "#     \"ckpt_path\": os.path.join(DATA_PATH, \"models\", \"cnn\", \"2024-02-25_21-16-59\", \"decoder.pt\"),\n",
    "# },\n",
    "# # \"ConvReadIn - no shift\": {\n",
    "# \"ConvReadIn - no pupil center training\": {\n",
    "#     \"run_name\": \"2024-03-06_12-46-53\",\n",
    "#     \"ckpt_path\": os.path.join(DATA_PATH, \"models\", \"cnn\", \"2024-03-06_12-46-53\", \"decoder.pt\"),\n",
    "# },\n",
    "# \"ConvReadIn - Autoencoding\": {\n",
    "#     \"run_name\": \"2024-02-27_13-01-15\",\n",
    "#     \"ckpt_path\": os.path.join(DATA_PATH, \"models\", \"cnn\", \"2024-02-27_13-01-15\", \"decoder.pt\"),\n",
    "# },\n",
    "# \"ConvReadIn - Contrastive reg.\": {\n",
    "#     \"run_name\": \"2024-02-27_00-04-30\",\n",
    "#     \"ckpt_path\": os.path.join(DATA_PATH, \"models\", \"cnn\", \"2024-02-27_00-04-30\", \"decoder.pt\"),\n",
    "# },\n",
    "# \"ConvReadIn - Fine-tuned\": {\n",
    "#     \"run_name\": \"2024-02-28_00-55-12\",\n",
    "#     \"ckpt_path\": os.path.join(DATA_PATH, \"models\", \"cnn\", \"2024-02-28_00-55-12\", \"decoder.pt\"),\n",
    "# },\n",
    "# \"ConvReadIn - From scratch\": { # comparison to the above\n",
    "#     \"run_name\": \"2024-02-28_00-59-51\",\n",
    "#     \"ckpt_path\": os.path.join(DATA_PATH, \"models\", \"cnn\", \"2024-02-28_00-59-51\", \"decoder.pt\"),\n",
    "# },\n",
    "# runs_to_compare[\"ConvReadIn - Con. reg.\"] = {\n",
    "#     \"run_name\": \"2024-03-02_12-28-42\",\n",
    "#     \"ckpt_path\": os.path.join(DATA_PATH, \"models\", \"cnn\", \"2024-03-02_12-28-42\", \"decoder.pt\"),\n",
    "# }\n",
    "# runs_to_compare[\"ConvReadIn - Con. reg., no shifter\"] = {\n",
    "#     \"run_name\": \"2024-03-18_01-12-49\",\n",
    "#     \"ckpt_path\": os.path.join(DATA_PATH, \"models\", \"cnn\", \"2024-03-18_01-12-49\", \"decoder.pt\"),\n",
    "# }\n",
    "# runs_to_compare[\"ConvReadIn - Con. reg. + Fine-tuned\"] = {\n",
    "#         \"run_name\": \"2024-02-28_13-08-22\",\n",
    "#         \"ckpt_path\": os.path.join(DATA_PATH, \"models\", \"cnn\", \"2024-02-28_13-08-22\", \"decoder.pt\"),\n",
    "#     }\n",
    "# runs_to_compare[\"ConvReadIn - Con. reg. (large) with neuron embeddings\"] = {\n",
    "#     \"run_name\": \"2024-03-03_00-59-02\",\n",
    "#     \"ckpt_path\": os.path.join(DATA_PATH, \"models\", \"cnn\", \"2024-03-03_00-59-02\", \"decoder.pt\"),\n",
    "# }\n",
    "# runs_to_compare[\"ConvReadIn - Con. reg. + Data aug.\"] = {\n",
    "#     \"run_name\": \"2024-03-08_13-08-36\",\n",
    "#     \"ckpt_path\": os.path.join(DATA_PATH, \"models\", \"cnn\", \"2024-03-08_13-08-36\", \"decoder.pt\"),\n",
    "# }\n",
    "# runs_to_compare[\"ConvReadIn - Synth. data 43%\"] = {\n",
    "#     \"run_name\": \"2024-03-11_01-05-34\",\n",
    "#     \"ckpt_path\": os.path.join(DATA_PATH, \"models\", \"cnn\", \"2024-03-11_01-05-34\", \"decoder.pt\"),\n",
    "# }\n",
    "# runs_to_compare[\"ConvReadIn - Synth. data 30% + Data aug.\"] = {\n",
    "#     \"run_name\": \"2024-03-11_20-03-03\",\n",
    "#     \"ckpt_path\": os.path.join(DATA_PATH, \"models\", \"cnn\", \"2024-03-11_20-03-03\", \"decoder.pt\"),\n",
    "# }\n",
    "# runs_to_compare[\"Con. reg.\"] = {\n",
    "#     \"run_name\": \"2024-03-18_01-12-49\",\n",
    "#     \"ckpt_path\": os.path.join(DATA_PATH, \"models\", \"cnn\", \"2024-03-18_01-12-49\", \"decoder.pt\"),\n",
    "# }\n",
    "\n",
    "\n",
    "\n",
    "### Single datasets\n",
    "# runs_to_compare[\"ConvReadIn (mouse #1) - Fine-tuned\"] = {\n",
    "#     \"run_name\": \"2024-02-28_13-09-19\",\n",
    "#     \"ckpt_path\": os.path.join(DATA_PATH, \"models\", \"cnn\", \"2024-02-28_13-09-19\", \"decoder.pt\"),\n",
    "# }\n",
    "# runs_to_compare[\"ConvReadIn (mouse #1) - From scratch\"] = {\n",
    "#     \"run_name\": \"2024-02-28_15-10-47\",\n",
    "#     \"ckpt_path\": os.path.join(DATA_PATH, \"models\", \"cnn\", \"2024-02-28_15-10-47\", \"decoder.pt\"),\n",
    "# }\n",
    "# \"ConvReadIn (mouse #1) - With neuron embeddings\": {\n",
    "#     \"run_name\": \"2024-03-03_19-47-31\",\n",
    "#     \"ckpt_path\": os.path.join(DATA_PATH, \"models\", \"cnn\", \"2024-03-03_19-47-31\", \"decoder.pt\"),\n",
    "# },\n",
    "# runs_to_compare[\"ConvReadIn (mouse #1) - From scratch + Synth. data 50%\"] = {\n",
    "#     \"run_name\": \"2024-03-10_21-32-52\",\n",
    "#     \"ckpt_path\": os.path.join(DATA_PATH, \"models\", \"cnn\", \"2024-03-10_21-32-52\", \"decoder.pt\"),\n",
    "# }\n",
    "# runs_to_compare[\"ConvReadIn (mouse #1) - From scratch + Synth. data 40% + Data aug.\"] = {\n",
    "#     \"run_name\": \"2024-03-12_18-52-18\",\n",
    "#     \"ckpt_path\": os.path.join(DATA_PATH, \"models\", \"cnn\", \"2024-03-12_18-52-18\", \"decoder.pt\"),\n",
    "# }\n",
    "# runs_to_compare[\"ConvReadIn (mouse #1) - From scratch, SSIM\"] = {\n",
    "#     \"run_name\": \"2024-03-16_17-13-54\",\n",
    "#     \"ckpt_path\": os.path.join(DATA_PATH, \"models\", \"cnn\", \"2024-03-16_17-13-54\", \"decoder.pt\"),\n",
    "# }\n",
    "# runs_to_compare[\"ConvReadIn (mouse #1) - From scratch, SSIM, no z-coord\"] = {\n",
    "#     \"run_name\": \"2024-03-17_11-16-25\",\n",
    "#     \"ckpt_path\": os.path.join(DATA_PATH, \"models\", \"cnn\", \"2024-03-17_11-16-25\", \"decoder.pt\"),\n",
    "# }\n",
    "# runs_to_compare[\"ConvReadIn (mouse #1) - From scratch, MultiSSIM\"] = {\n",
    "#     \"run_name\": \"2024-03-16_21-01-52\",\n",
    "#     \"ckpt_path\": os.path.join(DATA_PATH, \"models\", \"cnn\", \"2024-03-16_21-01-52\", \"decoder.pt\"),\n",
    "# }\n",
    "# \"Boosted Inverted Encoder (mouse #1)\": {\n",
    "#     \"run_name\": \"2024-03-06_01-15-13\",\n",
    "#     \"ckpt_path\": os.path.join(DATA_PATH, \"models\", \"boosted_inverted_encoder\", \"2024-03-06_01-15-13\", \"decoder.pt\"),\n",
    "# },\n",
    "# \"Boosted Inverted Encoder (mouse #1)\": {\n",
    "#     \"run_name\": \"2024-03-07_01-01-23\",\n",
    "#     \"ckpt_path\": os.path.join(DATA_PATH, \"models\", \"boosted_inverted_encoder\", \"2024-03-07_01-01-23\", \"decoder.pt\"),\n",
    "# },"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" MEIReadIn \"\"\"\n",
    "# runs_to_compare[\"ConvReadIn (all datasets)\"] = {\n",
    "#     \"run_name\": \"2024-03-26_10-36-00\",\n",
    "#     \"ckpt_path\": os.path.join(DATA_PATH, \"models\", \"cnn\", \"2024-03-26_10-36-00\", \"decoder.pt\"),\n",
    "# }\n",
    "# runs_to_compare[\"MEIReadIn (all datasets)\"] = {\n",
    "#     \"run_name\": \"2024-03-24_14-24-59\",\n",
    "#     \"ckpt_path\": os.path.join(DATA_PATH, \"models\", \"cnn\", \"2024-03-24_14-24-59\", \"decoder.pt\"),\n",
    "# }\n",
    "\n",
    "# runs_to_compare[\"ConvReadIn (mouse #1)\"] = {\n",
    "#     \"run_name\": \"2024-03-24_11-07-15\",\n",
    "#     \"ckpt_path\": os.path.join(DATA_PATH, \"models\", \"cnn\", \"2024-03-24_11-07-15\", \"decoder.pt\"),\n",
    "# }\n",
    "# runs_to_compare[\"MEIReadIn (mouse #1)\"] = {\n",
    "#     \"run_name\": \"2024-03-25_16-22-15\",\n",
    "#     \"ckpt_path\": os.path.join(DATA_PATH, \"models\", \"cnn\", \"2024-03-25_16-22-15\", \"decoder.pt\"),\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Training w/ different loss functions \"\"\"\n",
    "runs_to_compare[\"Log SSIM\"] = {\n",
    "    \"run_name\": \"2024-03-16_17-13-54\",\n",
    "    \"ckpt_path\": os.path.join(DATA_PATH, \"models\", \"cnn\", \"2024-03-16_17-13-54\", \"decoder.pt\"),\n",
    "}\n",
    "runs_to_compare[\"Log MultiSSIM\"] = {\n",
    "    \"run_name\": \"2024-03-16_21-01-52\",\n",
    "    \"ckpt_path\": os.path.join(DATA_PATH, \"models\", \"cnn\", \"2024-03-16_21-01-52\", \"decoder.pt\"),\n",
    "}\n",
    "runs_to_compare[\"MSE\"] = {\n",
    "    \"run_name\": \"2024-03-13_16-43-29\",\n",
    "    \"ckpt_path\": os.path.join(DATA_PATH, \"models\", \"cnn\", \"2024-03-13_16-43-29\", \"decoder.pt\"),\n",
    "}\n",
    "runs_to_compare[\"0.5 * MSE + 0.5 * Log SSIM\"] = {\n",
    "    \"run_name\": \"2024-03-14_00-46-57\",\n",
    "    \"ckpt_path\": os.path.join(DATA_PATH, \"models\", \"cnn\", \"2024-03-14_00-46-57\", \"decoder.pt\"),\n",
    "}\n",
    "runs_to_compare[\"0.9 * MSE + 0.1 * Log SSIM\"] = {\n",
    "    \"run_name\": \"2024-03-14_13-23-58\",\n",
    "    \"ckpt_path\": os.path.join(DATA_PATH, \"models\", \"cnn\", \"2024-03-14_13-23-58\", \"decoder.pt\"),\n",
    "}\n",
    "runs_to_compare[\"0.1 * MSE + 0.9 * Log SSIM\"] = {\n",
    "    \"run_name\": \"2024-03-14_19-40-02\",\n",
    "    \"ckpt_path\": os.path.join(DATA_PATH, \"models\", \"cnn\", \"2024-03-14_19-40-02\", \"decoder.pt\"),\n",
    "}\n",
    "runs_to_compare[\"MAE\"] = {\n",
    "    \"run_name\": \"2024-03-16_13-40-03\",\n",
    "    \"ckpt_path\": os.path.join(DATA_PATH, \"models\", \"cnn\", \"2024-03-16_13-40-03\", \"decoder.pt\"),\n",
    "}\n",
    "runs_to_compare[\"FFL\"] = {\n",
    "    \"run_name\": \"2024-03-17_00-36-23\",\n",
    "    \"ckpt_path\": os.path.join(DATA_PATH, \"models\", \"cnn\", \"2024-03-17_00-36-23\", \"decoder.pt\"),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Synthetic data comparison (new stimuli) \"\"\"\n",
    "### all datasets\n",
    "# runs_to_compare[\"Synth. data 0%\"] = {\n",
    "#     \"run_name\": \"2024-03-26_10-36-00\",\n",
    "#     \"ckpt_path\": os.path.join(DATA_PATH, \"models\", \"cnn\", \"2024-03-26_10-36-00\", \"decoder.pt\"),\n",
    "# }\n",
    "# runs_to_compare[\"Synth. data 25%\"] = {\n",
    "#     \"run_name\": \"2024-03-24_11-43-39\",\n",
    "#     \"ckpt_path\": os.path.join(DATA_PATH, \"models\", \"cnn\", \"2024-03-24_11-43-39\", \"decoder.pt\"),\n",
    "# }\n",
    "# runs_to_compare[\"Synth. data 50%\"] = {\n",
    "#     \"run_name\": \"2024-03-24_00-22-38\",\n",
    "#     \"ckpt_path\": os.path.join(DATA_PATH, \"models\", \"cnn\", \"2024-03-24_00-22-38\", \"decoder.pt\"),\n",
    "# }\n",
    "# runs_to_compare[\"Synth. data 75%\"] = {\n",
    "#     \"run_name\": \"2024-03-24_20-58-11\",\n",
    "#     \"ckpt_path\": os.path.join(DATA_PATH, \"models\", \"cnn\", \"2024-03-24_20-58-11\", \"decoder.pt\"),\n",
    "# }\n",
    "runs_to_compare[\"Synth. data 87.5%\"] = {\n",
    "    \"run_name\": \"2024-04-01_11-16-55\",\n",
    "    \"ckpt_path\": os.path.join(DATA_PATH, \"models\", \"cnn\", \"2024-04-01_11-16-55\", \"decoder.pt\"),\n",
    "}\n",
    "# runs_to_compare[\"Synth. data 100%\"] = {\n",
    "#     \"run_name\": \"2024-03-25_21-37-04\",\n",
    "#     \"ckpt_path\": os.path.join(DATA_PATH, \"models\", \"cnn\", \"2024-03-25_21-37-04\", \"decoder.pt\"),\n",
    "# }\n",
    "\n",
    "### single datasets\n",
    "# runs_to_compare[\"Synth. data 0% (all datasets)\"] = {\n",
    "#     \"run_name\": \"2024-03-26_10-36-00\",\n",
    "#     \"ckpt_path\": os.path.join(DATA_PATH, \"models\", \"cnn\", \"2024-03-26_10-36-00\", \"decoder.pt\"),\n",
    "# }\n",
    "# runs_to_compare[\"Synth. data 0%\"] = {\n",
    "#     \"run_name\": \"2024-03-24_11-07-15\",\n",
    "#     \"ckpt_path\": os.path.join(DATA_PATH, \"models\", \"cnn\", \"2024-03-24_11-07-15\", \"decoder.pt\"),\n",
    "# }\n",
    "# runs_to_compare[\"Synth. data 25%\"] = {\n",
    "#     \"run_name\": \"2024-03-24_11-10-27\",\n",
    "#     \"ckpt_path\": os.path.join(DATA_PATH, \"models\", \"cnn\", \"2024-03-24_11-10-27\", \"decoder.pt\"),\n",
    "# }\n",
    "# runs_to_compare[\"Synth. data 25%, noise\"] = {\n",
    "#     \"run_name\": \"2024-03-26_14-06-06\",\n",
    "#     \"ckpt_path\": os.path.join(DATA_PATH, \"models\", \"cnn\", \"2024-03-26_14-06-06\", \"decoder.pt\"),\n",
    "# }\n",
    "# runs_to_compare[\"Synth. data 50%\"] = {\n",
    "#     \"run_name\": \"2024-03-24_11-00-40\",\n",
    "#     \"ckpt_path\": os.path.join(DATA_PATH, \"models\", \"cnn\", \"2024-03-24_11-00-40\", \"decoder.pt\"),\n",
    "# }\n",
    "# runs_to_compare[\"Synth. data 50%, noise\"] = {\n",
    "#     \"run_name\": \"2024-03-26_10-09-50\",\n",
    "#     \"ckpt_path\": os.path.join(DATA_PATH, \"models\", \"cnn\", \"2024-03-26_10-09-50\", \"decoder.pt\"),\n",
    "# }\n",
    "# runs_to_compare[\"Synth. data 75%\"] = {\n",
    "#     \"run_name\": \"2024-03-25_16-13-34\",\n",
    "#     \"ckpt_path\": os.path.join(DATA_PATH, \"models\", \"cnn\", \"2024-03-25_16-13-34\", \"decoder.pt\"),\n",
    "# }\n",
    "# runs_to_compare[\"Synth. data 100%\"] = {\n",
    "#     \"run_name\": \"2024-03-25_23-47-06\",\n",
    "#     \"ckpt_path\": os.path.join(DATA_PATH, \"models\", \"cnn\", \"2024-03-25_23-47-06\", \"decoder.pt\"),\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Fine-tuning \"\"\"\n",
    "runs_to_compare[\"Fine-tuned (all datasets -> mouse #1 data)\"] = {\n",
    "    \"run_name\": \"2024-04-02_10-45-50\",\n",
    "    \"ckpt_path\": os.path.join(DATA_PATH, \"models\", \"cnn\", \"2024-04-02_10-45-50\", \"decoder.pt\"),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Table 1 (Initial comparison) \"\"\"\n",
    "# runs_to_compare = torch.load( # Inverted Encoder\n",
    "#     \"encoder_inversion_eval_all_mice_26-03-24.pt\", pickle_module=dill\n",
    "# )\n",
    "runs_to_compare = torch.load( # Inverted Encoder\n",
    "    \"encoder_inversion_eval_mouse_1_12-04-24.pt\", pickle_module=dill\n",
    ")\n",
    "runs_to_compare[\"CNN-FC (M-1)\"] = {\n",
    "    \"run_name\": \"2024-04-08_00-43-03\",\n",
    "    \"ckpt_path\": os.path.join(DATA_PATH, \"models\", \"cnn\", \"2024-04-08_00-43-03\", \"decoder.pt\"),\n",
    "}\n",
    "runs_to_compare[\"CNN-Conv (M-1)\"] = {\n",
    "    \"run_name\": \"2024-03-27_11-35-11\",\n",
    "    \"ckpt_path\": os.path.join(DATA_PATH, \"models\", \"cnn\", \"2024-03-27_11-35-11\", \"decoder.pt\"),\n",
    "}\n",
    "runs_to_compare[\"CNN-MEI (M-1)\"] = {\n",
    "    \"run_name\": \"2024-04-09_08-42-29\",\n",
    "    \"ckpt_path\": os.path.join(DATA_PATH, \"models\", \"cnn\", \"2024-04-09_08-42-29\", \"decoder.pt\"),\n",
    "}\n",
    "runs_to_compare[\"CNN-FC (M-All)\"] = {\n",
    "    \"run_name\": \"2024-04-08_00-39-27\",\n",
    "    \"ckpt_path\": os.path.join(DATA_PATH, \"models\", \"cnn\", \"2024-04-08_00-39-27\", \"decoder.pt\"),\n",
    "}\n",
    "runs_to_compare[\"CNN-Conv (M-All)\"] = {\n",
    "    \"run_name\": \"2024-03-27_23-26-05\",\n",
    "    \"ckpt_path\": os.path.join(DATA_PATH, \"models\", \"cnn\", \"2024-03-27_23-26-05\", \"decoder.pt\"),\n",
    "}\n",
    "runs_to_compare[\"CNN-MEI (M-All)\"] = {\n",
    "    \"run_name\": \"2024-04-09_08-46-00\",\n",
    "    \"ckpt_path\": os.path.join(DATA_PATH, \"models\", \"cnn\", \"2024-04-09_08-46-00\", \"decoder.pt\"),\n",
    "}\n",
    "runs_to_compare[\"GAN (M-1)\"] = {\n",
    "    \"run_name\": \"2024-04-10_11-06-28\",\n",
    "    \"ckpt_path\": os.path.join(DATA_PATH, \"models\", \"gan\", \"2024-04-10_11-06-28\", \"decoder.pt\"),\n",
    "}\n",
    "runs_to_compare[\"GAN (M-All)\"] = {\n",
    "    \"run_name\": \"2024-04-10_17-36-41\",\n",
    "    \"ckpt_path\": os.path.join(DATA_PATH, \"models\", \"gan\", \"2024-04-10_17-36-41\", \"decoder.pt\"),\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Table 2 (Encoder matching) \"\"\"\n",
    "runs_to_compare[\"CNN-Conv (M-1)\"] = {\n",
    "    \"run_name\": \"2024-03-27_11-35-11\",\n",
    "    \"ckpt_path\": os.path.join(DATA_PATH, \"models\", \"cnn\", \"2024-03-27_11-35-11\", \"decoder.pt\"),\n",
    "}\n",
    "runs_to_compare[\"CNN-Conv w/ encoder matching (M-1)\"] = {\n",
    "    \"run_name\": \"2024-04-11_10-22-00\",\n",
    "    \"ckpt_path\": os.path.join(DATA_PATH, \"models\", \"cnn\", \"2024-04-11_10-22-00\", \"decoder.pt\"),\n",
    "}\n",
    "# runs_to_compare[\"CNN-Conv (M-All)\"] = {\n",
    "#     \"run_name\": \"2024-03-27_23-26-05\",\n",
    "#     \"ckpt_path\": os.path.join(DATA_PATH, \"models\", \"cnn\", \"2024-03-27_23-26-05\", \"decoder.pt\"),\n",
    "# }\n",
    "# runs_to_compare[\"CNN-Conv w/ encoder matching (M-All)\"] = {\n",
    "#     \"run_name\": \"2024-04-11_10-18-14\",\n",
    "#     \"ckpt_path\": os.path.join(DATA_PATH, \"models\", \"cnn\", \"2024-04-11_10-18-14\", \"decoder.pt\"),\n",
    "# }\n",
    "runs_to_compare[\"CNN-MEI (M-1)\"] = {\n",
    "    \"run_name\": \"2024-04-09_08-42-29\",\n",
    "    \"ckpt_path\": os.path.join(DATA_PATH, \"models\", \"cnn\", \"2024-04-09_08-42-29\", \"decoder.pt\"),\n",
    "}\n",
    "runs_to_compare[\"CNN-MEI w/ encoder matching (M-1)\"] = {\n",
    "    \"run_name\": \"2024-04-12_23-44-06\",\n",
    "    \"ckpt_path\": os.path.join(DATA_PATH, \"models\", \"cnn\", \"2024-04-12_23-44-06\", \"decoder.pt\"),\n",
    "}\n",
    "# runs_to_compare[\"GAN (M-1)\"] = {\n",
    "#     \"run_name\": \"2024-04-10_11-06-28\",\n",
    "#     \"ckpt_path\": os.path.join(DATA_PATH, \"models\", \"cnn\", \"2024-04-10_11-06-28\", \"decoder.pt\"),\n",
    "# }\n",
    "# runs_to_compare[\"GAN w/ encoder matching (M-1)\"] = {\n",
    "#     \"run_name\": \"...\",\n",
    "#     \"ckpt_path\": os.path.join(DATA_PATH, \"models\", \"gan\", \"...\", \"decoder.pt\"),\n",
    "# }\n",
    "# runs_to_compare[\"GAN (M-All)\"] = {\n",
    "#     \"run_name\": \"2024-04-10_17-36-41\",\n",
    "#     \"ckpt_path\": os.path.join(DATA_PATH, \"models\", \"gan\", \"2024-04-10_17-36-41\", \"decoder.pt\"),\n",
    "# }\n",
    "# runs_to_compare[\"GAN w/ encoder matching (M-All)\"] = {\n",
    "#     \"run_name\": \"...\",\n",
    "#     \"ckpt_path\": os.path.join(DATA_PATH, \"models\", \"gan\", \"...\", \"decoder.pt\"),\n",
    "# }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Table 3 (Synthetic data M-1/S-1) \"\"\"\n",
    "# runs_to_compare = torch.load( # Inverted Encoder (all mice)\n",
    "#     \"encoder_inversion_eval_all_mice_26-03-24.pt\", pickle_module=dill\n",
    "# )\n",
    "runs_to_compare = torch.load( # Inverted Encoder (single mouse)\n",
    "    \"encoder_inversion_eval_mouse_1_12-04-24.pt\", pickle_module=dill\n",
    ")\n",
    "runs_to_compare[\"CNN-Conv (0%)\"] = {\n",
    "    \"run_name\": \"2024-03-27_11-35-11\",\n",
    "    \"ckpt_path\": os.path.join(DATA_PATH, \"models\", \"cnn\", \"2024-03-27_11-35-11\", \"decoder.pt\"),\n",
    "}\n",
    "runs_to_compare[\"CNN-Conv (25%)\"] = {\n",
    "    \"run_name\": \"2024-03-27_23-16-33\",\n",
    "    \"ckpt_path\": os.path.join(DATA_PATH, \"models\", \"cnn\", \"2024-03-27_23-16-33\", \"decoder.pt\"),\n",
    "}\n",
    "runs_to_compare[\"CNN-Conv (50%)\"] = {\n",
    "    \"run_name\": \"2024-03-27_18-15-44\",\n",
    "    \"ckpt_path\": os.path.join(DATA_PATH, \"models\", \"cnn\", \"2024-03-27_18-15-44\", \"decoder.pt\"),\n",
    "}\n",
    "runs_to_compare[\"CNN-Conv (87.5%)\"] = {\n",
    "    \"run_name\": \"2024-04-08_21-11-50\",\n",
    "    \"ckpt_path\": os.path.join(DATA_PATH, \"models\", \"cnn\", \"2024-04-08_21-11-50\", \"decoder.pt\"),\n",
    "}\n",
    "runs_to_compare[\"CNN-Conv (100%)\"] = {\n",
    "    \"run_name\": \"2024-04-08_21-09-33\",\n",
    "    \"ckpt_path\": os.path.join(DATA_PATH, \"models\", \"cnn\", \"2024-04-08_21-09-33\", \"decoder.pt\"),\n",
    "}\n",
    "\n",
    "# runs_to_compare[\"CNN-MEI (0%)\"] = {\n",
    "#     \"run_name\": \"2024-04-09_08-42-29\",\n",
    "#     \"ckpt_path\": os.path.join(DATA_PATH, \"models\", \"cnn\", \"2024-04-09_08-42-29\", \"decoder.pt\"),\n",
    "# }\n",
    "# runs_to_compare[\"CNN-MEI (25%)\"] = {\n",
    "#     \"run_name\": \"2024-04-12_11-41-07\",\n",
    "#     \"ckpt_path\": os.path.join(DATA_PATH, \"models\", \"cnn\", \"2024-04-12_11-41-07\", \"decoder.pt\"),\n",
    "# }\n",
    "# runs_to_compare[\"CNN-MEI (50%)\"] = {\n",
    "#     \"run_name\": \"2024-04-12_11-26-43\",\n",
    "#     \"ckpt_path\": os.path.join(DATA_PATH, \"models\", \"cnn\", \"2024-04-12_11-26-43\", \"decoder.pt\"),\n",
    "# }\n",
    "# runs_to_compare[\"CNN-MEI (87.5%)\"] = {\n",
    "#     \"run_name\": \"2024-04-12_11-38-37\",\n",
    "#     \"ckpt_path\": os.path.join(DATA_PATH, \"models\", \"cnn\", \"2024-04-12_11-38-37\", \"decoder.pt\"),\n",
    "# }\n",
    "# runs_to_compare[\"CNN-MEI (100%)\"] = {\n",
    "#     \"run_name\": \"2024-04-12_11-31-42\",\n",
    "#     \"ckpt_path\": os.path.join(DATA_PATH, \"models\", \"cnn\", \"2024-04-12_11-31-42\", \"decoder.pt\"),\n",
    "# }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Metrics \"\"\"\n",
    "loss_fns = {\n",
    "    \"Log SSIM Loss\": SSIMLoss(\n",
    "        window=config[\"crop_win\"],\n",
    "        log_loss=True,\n",
    "        inp_normalized=True,\n",
    "        inp_standardized=False,\n",
    "        reduction=\"sum\",\n",
    "    ),\n",
    "    \"Log MultiSSIM Loss\": MultiSSIMLoss(\n",
    "        window=config[\"crop_win\"],\n",
    "        log_loss=True,\n",
    "        inp_normalized=True,\n",
    "        inp_standardized=False,\n",
    "        reduction=\"sum\",\n",
    "    ),\n",
    "    \"SSIM Loss\": SSIMLoss(\n",
    "        window=config[\"crop_win\"],\n",
    "        log_loss=False,\n",
    "        inp_normalized=True,\n",
    "        inp_standardized=False,\n",
    "        reduction=\"sum\",\n",
    "    ),\n",
    "    \"MultiSSIM Loss\": MultiSSIMLoss(\n",
    "        window=config[\"crop_win\"],\n",
    "        log_loss=False,\n",
    "        inp_normalized=True,\n",
    "        inp_standardized=False,\n",
    "        reduction=\"sum\",\n",
    "    ),\n",
    "    \"Perceptual Loss (VGG16)\": CroppedLoss(\n",
    "        window=config[\"crop_win\"],\n",
    "        normalize=False,\n",
    "        standardize=True,\n",
    "        loss_fn=VGGPerceptualLoss(\n",
    "            resize=False,\n",
    "            device=config[\"device\"],\n",
    "        ),\n",
    "    ),\n",
    "    # \"Perceptual Loss (Encoder)\": CroppedLoss(\n",
    "    #     window=config[\"crop_win\"],\n",
    "    #     normalize=True,\n",
    "    #     standardize=False,\n",
    "    #     loss_fn=EncoderPerceptualLoss(\n",
    "    #         encoder=encoder,\n",
    "    #         device=config[\"device\"],\n",
    "    #     ),\n",
    "    # ),\n",
    "    \"FFL\": CroppedLoss(\n",
    "        window=config[\"crop_win\"],\n",
    "        normalize=False,\n",
    "        standardize=True,\n",
    "        loss_fn=FFL(loss_weight=1, alpha=1.0),\n",
    "    ),\n",
    "    \"MSE\": lambda x_hat, x: F.mse_loss(\n",
    "        standardize(crop(x_hat, config[\"crop_win\"])),\n",
    "        standardize(crop(x, config[\"crop_win\"])),\n",
    "        reduction=\"none\",\n",
    "    ).mean((1,2,3)).sum(),\n",
    "    \"MAE\": lambda x_hat, x: F.l1_loss(\n",
    "        standardize(crop(x_hat, config[\"crop_win\"])),\n",
    "        standardize(crop(x, config[\"crop_win\"])),\n",
    "        reduction=\"none\",\n",
    "    ).mean((1,2,3)).sum(),\n",
    "}\n",
    "for k in loss_fns.keys():\n",
    "    loss_fns[k] = Loss(\n",
    "        model=None,\n",
    "        config={\n",
    "            \"loss_fn\": loss_fns[k],\n",
    "            \"l1_reg_mul\": 0,\n",
    "            \"l2_reg_mul\": 0,\n",
    "            \"con_reg_mul\": 0,\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fns[\"SSIML + PSL + FFL\"] = Loss(\n",
    "    model=None,\n",
    "    config={\n",
    "        \"loss_fn\": CroppedLoss(\n",
    "            window=config[\"crop_win\"],\n",
    "            normalize=False,\n",
    "            standardize=False,\n",
    "            loss_fn=lambda y_hat, y: loss_fns[\"SSIM Loss\"](y_hat, y) + loss_fns[\"Perceptual Loss (VGG16)\"](y_hat, y) + 2*loss_fns[\"FFL\"](y_hat, y)\n",
    "        ),\n",
    "        \"l1_reg_mul\": 0,\n",
    "        \"l2_reg_mul\": 0,\n",
    "        \"con_reg_mul\": 0,\n",
    "    }\n",
    ")\n",
    "loss_fns[\"SSIML + PSL\"] = Loss(\n",
    "    model=None,\n",
    "    config={\n",
    "        \"loss_fn\": CroppedLoss(\n",
    "            window=config[\"crop_win\"],\n",
    "            normalize=False,\n",
    "            standardize=False,\n",
    "            loss_fn=lambda y_hat, y: loss_fns[\"SSIM Loss\"](y_hat, y) + loss_fns[\"Perceptual Loss (VGG16)\"](y_hat, y)\n",
    "        ),\n",
    "        \"l1_reg_mul\": 0,\n",
    "        \"l2_reg_mul\": 0,\n",
    "        \"con_reg_mul\": 0,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### load models\n",
    "if config[\"comparison\"][\"load_best\"] and config[\"comparison\"][\"eval_all_ckpts\"]:\n",
    "    print(\"[WARNING] both the eval_all_ckpts and load_best are set to True - still loading current (not the best) decoders.\")\n",
    "assert config[\"comparison\"][\"eval_all_ckpts\"] is True or config[\"comparison\"][\"find_best_ckpt_according_to\"] is None\n",
    "assert config[\"comparison\"][\"find_best_ckpt_according_to\"] is None or config[\"comparison\"][\"load_best\"] is False\n",
    "\n",
    "for k in runs_to_compare.keys():\n",
    "    print(f\"Loading {k} model from ckpt (run name: {runs_to_compare[k]['run_name']})...\")\n",
    "    if \"test_losses\" in runs_to_compare[k]:\n",
    "        print(f\"  Skipping...\")\n",
    "        continue\n",
    "    run_dict = runs_to_compare[k]\n",
    "    run_name = run_dict[\"run_name\"]\n",
    "\n",
    "    ckpt_paths = []\n",
    "    if \"decoder\" in run_dict and run_dict[\"decoder\"] is not None:\n",
    "        ckpt_paths.append(None)\n",
    "    else:\n",
    "        if config[\"comparison\"][\"eval_all_ckpts\"]:\n",
    "            ckpts_dir = os.path.join(os.path.dirname(run_dict[\"ckpt_path\"]), \"ckpt\")\n",
    "            ckpt_paths.extend([os.path.join(os.path.dirname(run_dict[\"ckpt_path\"]), \"ckpt\", ckpt_name) for ckpt_name in os.listdir(ckpts_dir)])\n",
    "        else:\n",
    "            ckpt_paths.append(run_dict[\"ckpt_path\"])\n",
    "\n",
    "    ### find best ckpt according to some metric\n",
    "    if config[\"comparison\"][\"find_best_ckpt_according_to\"] is not None:\n",
    "        print(f\"  Finding the best ckpt according to {config['comparison']['find_best_ckpt_according_to']}...\")\n",
    "        best_ckpt_path, best_loss = None, np.inf\n",
    "        for ckpt_path in ckpt_paths:\n",
    "            ckpt = torch.load(ckpt_path, map_location=config[\"device\"], pickle_module=dill)\n",
    "            ckpt_config = ckpt[\"config\"]\n",
    "            ### TODO: remove (quick fix)\n",
    "            # if ckpt[\"best\"][f\"model\"][\"readins.21067-10-18.0.grid_net.0.weight\"].shape[-1] == 4:\n",
    "            #     for rc in ckpt_config[\"decoder\"][\"model\"][\"readins_config\"]:\n",
    "            #         rc[\"layers\"][0][1][\"grid_net_config\"] = {\n",
    "            #             \"in_channels\": 4, # x, y, resp\n",
    "            #             \"layers_config\": [(\"fc\", 32), (\"fc\", 64), (\"fc\", 16*9)],\n",
    "            #             \"act_fn\": nn.LeakyReLU,\n",
    "            #             \"out_act_fn\": nn.Identity,\n",
    "            #             \"dropout\": 0.1,\n",
    "            #             \"batch_norm\": False,\n",
    "            #         }\n",
    "            if \"meis_path\" in ckpt_config[\"decoder\"][\"model\"][\"readins_config\"][-1][\"layers\"][0][1] \\\n",
    "                and not os.path.exists(ckpt_config[\"decoder\"][\"model\"][\"readins_config\"][-1][\"layers\"][0][1][\"meis_path\"]):\n",
    "                # and \"/home/sobotj11/decoding-brain-activity/data/mouse_v1_sensorium22/meis/\" in ckpt_config[\"decoder\"][\"model\"][\"readins_config\"][-1][\"layers\"][0][1][\"meis_path\"]:\n",
    "                for rc in ckpt_config[\"decoder\"][\"model\"][\"readins_config\"]:\n",
    "                    rc[\"layers\"][0][1][\"meis_path\"] = rc[\"layers\"][0][1][\"meis_path\"].replace(\n",
    "                        \"/media/jsobotka/ext_ssd/csng_data/mouse_v1_sensorium22/meis/\",\n",
    "                        \"/home/sobotj11/decoding-brain-activity/data/mouse_v1_sensorium22/meis/\",\n",
    "                    )\n",
    "            decoder = MultiReadIn(**ckpt_config[\"decoder\"][\"model\"]).to(config[\"device\"])\n",
    "            decoder._load_state_dict(ckpt[\"decoder\"])\n",
    "            decoder.eval()\n",
    "            \n",
    "            ### eval\n",
    "            dls, neuron_coords = get_all_data(config=config)\n",
    "            val_loss = eval_decoder(\n",
    "                model=decoder,\n",
    "                dataloader=dls[\"mouse_v1\"][\"val\"],\n",
    "                loss_fns={config[\"comparison\"][\"find_best_ckpt_according_to\"]: loss_fns[config[\"comparison\"][\"find_best_ckpt_according_to\"]]},\n",
    "                normalize_decoded=False,\n",
    "                config=config,\n",
    "            )[config[\"comparison\"][\"find_best_ckpt_according_to\"]][\"total\"]\n",
    "            if val_loss < best_loss:\n",
    "                best_loss = val_loss\n",
    "                best_ckpt_path = ckpt_path\n",
    "        ckpt_paths = [best_ckpt_path]\n",
    "\n",
    "    ### eval all ckpts\n",
    "    print(f\"  Evaluating the ckpts on the test set...\")\n",
    "    all_test_losses, all_configs, all_histories, all_best_val_losses, all_stim_pred_best = [], [], [], [], []\n",
    "    for ckpt_path in ckpt_paths:\n",
    "        if \"decoder\" in run_dict and run_dict[\"decoder\"] is not None:\n",
    "            print(f\"  Using {k} model from run_dict...\")\n",
    "            decoder = run_dict[\"decoder\"]\n",
    "            ckpt = None\n",
    "        elif \"boosted_inverted_encoder\" in ckpt_path:\n",
    "            assert NotImplementedError(\"Not update, check.\")\n",
    "            ### load ckpt and init\n",
    "            ckpt = torch.load(ckpt_path, map_location=config[\"device\"], pickle_module=dill)\n",
    "            ckpt_config = ckpt[\"config\"]\n",
    "            decoder = BoostedInvertedEncoder(**ckpt_config[\"decoder\"][\"model\"]).to(config[\"device\"])\n",
    "            decoder.load_state_dict(ckpt[\"best\"][\"model\"], strict=True)\n",
    "            decoder.eval()\n",
    "        else:\n",
    "            ### load ckpt and init\n",
    "            ckpt = torch.load(ckpt_path, map_location=config[\"device\"], pickle_module=dill)\n",
    "            ckpt_config = ckpt[\"config\"]\n",
    "            ### TODO: remove (quick fix)\n",
    "            # if ckpt[\"best\"][f\"model\"][\"readins.21067-10-18.0.grid_net.0.weight\"].shape[-1] == 4:\n",
    "            #     for rc in ckpt_config[\"decoder\"][\"model\"][\"readins_config\"]:\n",
    "            #         rc[\"layers\"][0][1][\"grid_net_config\"] = {\n",
    "            #             \"in_channels\": 4, # x, y, resp\n",
    "            #             \"layers_config\": [(\"fc\", 32), (\"fc\", 64), (\"fc\", 16*9)],\n",
    "            #             \"act_fn\": nn.LeakyReLU,\n",
    "            #             \"out_act_fn\": nn.Identity,\n",
    "            #             \"dropout\": 0.1,\n",
    "            #             \"batch_norm\": False,\n",
    "            #         }\n",
    "            if \"meis_path\" in ckpt_config[\"decoder\"][\"model\"][\"readins_config\"][-1][\"layers\"][0][1] \\\n",
    "                and not os.path.exists(ckpt_config[\"decoder\"][\"model\"][\"readins_config\"][-1][\"layers\"][0][1][\"meis_path\"]):\n",
    "                # and \"/home/sobotj11/decoding-brain-activity/data/mouse_v1_sensorium22/meis/\" in ckpt_config[\"decoder\"][\"model\"][\"readins_config\"][-1][\"layers\"][0][1][\"meis_path\"]:\n",
    "                for rc in ckpt_config[\"decoder\"][\"model\"][\"readins_config\"]:\n",
    "                    rc[\"layers\"][0][1][\"meis_path\"] = rc[\"layers\"][0][1][\"meis_path\"].replace(\n",
    "                        \"/media/jsobotka/ext_ssd/csng_data/mouse_v1_sensorium22/meis/\",\n",
    "                        \"/home/sobotj11/decoding-brain-activity/data/mouse_v1_sensorium22/meis/\",\n",
    "                    )\n",
    "            decoder = MultiReadIn(**ckpt_config[\"decoder\"][\"model\"]).to(config[\"device\"])\n",
    "            if config[\"comparison\"][\"eval_all_ckpts\"] or not config[\"comparison\"][\"load_best\"]:\n",
    "                print(f\"  [WARNING] Not loading the best model from the ckpt.\")\n",
    "                decoder._load_state_dict(ckpt[\"decoder\"])\n",
    "            else:\n",
    "                decoder._load_state_dict(ckpt[\"best\"][\"model\"])\n",
    "            decoder.eval()\n",
    "        \n",
    "        ### get reconstructions\n",
    "        if decoder.__class__.__name__ == \"InvertedEncoder\":\n",
    "            stim_pred_best, _, _ = decoder(\n",
    "                resp.to(config[\"device\"]),\n",
    "                stim.to(config[\"device\"]),\n",
    "                additional_encoder_inp={\n",
    "                    \"data_key\": sample_data_key,\n",
    "                    \"pupil_center\": pupil_center.to(config[\"device\"]),\n",
    "                }\n",
    "            )\n",
    "            stim_pred_best = stim_pred_best.detach().cpu()\n",
    "        else:\n",
    "            stim_pred_best = decoder(\n",
    "                resp.to(config[\"device\"]),\n",
    "                data_key=sample_data_key,\n",
    "                neuron_coords=neuron_coords[sample_data_key],\n",
    "                pupil_center=pupil_center.to(config[\"device\"]),\n",
    "            ).detach().cpu()\n",
    "\n",
    "        ### eval\n",
    "        dls, neuron_coords = get_all_data(config=config)\n",
    "        test_losses = eval_decoder(\n",
    "            model=decoder,\n",
    "            dataloader=dls[\"mouse_v1\"][\"test\"],\n",
    "            loss_fns=loss_fns,\n",
    "            # normalize_decoded=True if \"l2o\" in k.lower() else False,\n",
    "            normalize_decoded=False,\n",
    "            config=config,\n",
    "        )\n",
    "\n",
    "        all_test_losses.append(test_losses)\n",
    "        all_configs.append(ckpt_config if ckpt is not None else None)\n",
    "        all_histories.append(ckpt[\"history\"] if ckpt is not None else None)\n",
    "        all_best_val_losses.append(ckpt[\"best\"][\"val_loss\"] if ckpt is not None else None)\n",
    "        all_stim_pred_best.append(stim_pred_best.detach().cpu())\n",
    "\n",
    "    ### save\n",
    "    runs_to_compare[k][\"test_losses\"] = all_test_losses\n",
    "    runs_to_compare[k][\"config\"] = all_configs\n",
    "    runs_to_compare[k][\"history\"] = all_histories\n",
    "    runs_to_compare[k][\"best_val_loss\"] = all_best_val_losses\n",
    "    runs_to_compare[k][\"stim_pred_best\"] = all_stim_pred_best\n",
    "    runs_to_compare[k][\"ckpt_paths\"] = ckpt_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### save the results\n",
    "if config[\"comparison\"][\"save_dir\"]:\n",
    "    torch.save({\n",
    "            \"runs\": runs_to_compare,\n",
    "            \"config\": config,\n",
    "        },\n",
    "        os.path.join(config[\"comparison\"][\"save_dir\"], f\"M-1_PSL_{datetime.now().strftime('%Y-%m-%d_%H-%M-%S')}.pt\"),\n",
    "        # os.path.join(config[\"comparison\"][\"save_dir\"], f\"M-1_{datetime.now().strftime('%Y-%m-%d_%H-%M-%S')}.pt\"),\n",
    "        pickle_module=dill,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from comparison_utils import plot_reconstructions_publication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_img_at_ax(ax, img):\n",
    "    ax.imshow(img.cpu().squeeze(), cmap=\"gray\")\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    ax.spines[\"top\"].set_visible(False)\n",
    "    ax.spines[\"right\"].set_visible(False)\n",
    "    ax.spines[\"left\"].set_visible(False)\n",
    "    ax.spines[\"bottom\"].set_visible(False)\n",
    "    return ax\n",
    "\n",
    "\n",
    "def plot_reconstructions_publication(runs_to_compare, stim, config, save_to=None):\n",
    "    fig = plt.figure(facecolor=\"white\")\n",
    "\n",
    "    img_grid_shape = (stim.shape[0], 1 + len(runs_to_compare))\n",
    "\n",
    "    ### plot comparison\n",
    "    for row_i in range(img_grid_shape[0]):\n",
    "        ### plot target\n",
    "        ax = fig.add_subplot(\n",
    "            img_grid_shape[0],\n",
    "            img_grid_shape[1],\n",
    "            1 + row_i*img_grid_shape[1],\n",
    "        )\n",
    "        ax = plot_img_at_ax(ax, crop(stim[row_i], config[\"crop_win\"]))\n",
    "        if row_i == 0:\n",
    "            ax.set_title(\"Target\", fontsize=5.5, fontweight=\"bold\", rotation = 45, va='baseline')\n",
    "        for col_j, k in enumerate(runs_to_compare.keys()):\n",
    "            for run_idx in range(len(runs_to_compare[k][\"stim_pred_best\"])):\n",
    "                ax = fig.add_subplot(\n",
    "                    img_grid_shape[0],\n",
    "                    img_grid_shape[1],\n",
    "                    1 + row_i*img_grid_shape[1] + 1 + col_j,\n",
    "                )\n",
    "                stim_pred = runs_to_compare[k][\"stim_pred_best\"][run_idx][row_i]\n",
    "                ax = plot_img_at_ax(ax, crop(stim_pred, config[\"crop_win\"]))\n",
    "                if row_i == 0:\n",
    "                    ax.set_title(k, fontsize=5.5, rotation=45, va='baseline')\n",
    "\n",
    "    plt.subplots_adjust(wspace=0., hspace=-0.4)\n",
    "    plt.show()\n",
    "\n",
    "    if save_to is not None:\n",
    "        fig.savefig(save_to, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### plot reconstructions\n",
    "plot_reconstructions_publication(\n",
    "    runs_to_compare=runs_to_compare,\n",
    "    stim=stim,\n",
    "    config=config,\n",
    "    save_to=os.path.join(config[\"comparison\"][\"save_dir\"], \"M-1_PSL_reconstructions.pdf\") \\\n",
    "        if config[\"comparison\"][\"save_dir\"] else None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### plot metrics\n",
    "plot_metrics_publication(\n",
    "    runs_to_compare=runs_to_compare,\n",
    "    losses_to_plot=[\n",
    "        \"SSIM Loss\",\n",
    "        # \"Log SSIM Loss\",\n",
    "        # \"MultiSSIM Loss\",\n",
    "        # \"Log MultiSSIM Loss\",\n",
    "        \"MSE\",\n",
    "        # \"MAE\",\n",
    "        \"FFL\",\n",
    "        \"Perceptual Loss (VGG16)\",\n",
    "        # \"Perceptual Loss (Encoder)\",\n",
    "    ],\n",
    "    bar_width=0.7,\n",
    "    save_to=os.path.join(config[\"comparison\"][\"save_dir\"], \"M-1_PSL_metrics.pdf\") \\\n",
    "        if config[\"comparison\"][\"save_dir\"] else None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### plot progression over training\n",
    "plot_over_training(\n",
    "    runs_to_compare=runs_to_compare,\n",
    "    to_plot=\"val_loss\",\n",
    "    conv_win=10,\n",
    "    ckpt_idx=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### plot metrics\n",
    "plot_metrics(\n",
    "    runs_to_compare=runs_to_compare,\n",
    "    losses_to_plot=[\n",
    "        \"SSIM Loss\",\n",
    "        # \"Log SSIM Loss\",\n",
    "        # \"MultiSSIM Loss\",\n",
    "        # \"Log MultiSSIM Loss\",\n",
    "        \"MSE\",\n",
    "        # \"MAE\",\n",
    "        # \"FFL\",\n",
    "        \"Perceptual Loss (VGG16)\",\n",
    "        # \"Perceptual Loss (Encoder)\",\n",
    "    ],\n",
    "    bar_width=0.7,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### plot reconstructions\n",
    "plot_reconstructions(\n",
    "    runs_to_compare=runs_to_compare,\n",
    "    stim=stim,\n",
    "    config=config,\n",
    "    loss_fns=loss_fns,\n",
    "    sample_data_key=sample_data_key,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
