{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from copy import deepcopy\n",
    "import dill\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "import lovely_tensors as lt\n",
    "import wandb\n",
    "from nnfabrik.builder import get_data\n",
    "from focal_frequency_loss import FocalFrequencyLoss as FFL\n",
    "\n",
    "import csng\n",
    "from csng.InvertedEncoder import InvertedEncoder\n",
    "from csng.CNN_Decoder import CNN_Decoder\n",
    "from csng.utils import crop, plot_comparison, standardize, normalize, get_mean_and_std, count_parameters, plot_losses\n",
    "from csng.losses import (\n",
    "    MultiSSIMLoss,\n",
    "    SSIMLoss,\n",
    "    CroppedLoss,\n",
    "    Loss,\n",
    "    MS_SSIMLoss,\n",
    "    PerceptualLoss,\n",
    "    EncoderPerceptualLoss,\n",
    "    VGGPerceptualLoss,\n",
    ")\n",
    "from csng.data import MixedBatchLoader\n",
    "from csng.readins import (\n",
    "    MultiReadIn,\n",
    "    HypernetReadIn,\n",
    "    ConvReadIn,\n",
    "    AttentionReadIn,\n",
    "    FCReadIn,\n",
    "    AutoEncoderReadIn,\n",
    "    Conv1dReadIn,\n",
    ")\n",
    "\n",
    "from BoostedInvertedEncoder import BoostedInvertedEncoder\n",
    "from encoder import get_encoder\n",
    "from data_utils import get_mouse_v1_data, PerSampleStoredDataset, append_syn_dataloaders\n",
    "\n",
    "lt.monkey_patch()\n",
    "\n",
    "DATA_PATH = os.path.join(os.environ[\"DATA_PATH\"], \"mouse_v1_sensorium22\")\n",
    "print(f\"{DATA_PATH=}\")\n",
    "\n",
    "%env \"WANDB_NOTEBOOK_NAME\" \"cnn_decoder.ipynb\"\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"data\": {\n",
    "        \"mixing_strategy\": \"parallel_min\", # needed only with multiple base dataloaders\n",
    "    },\n",
    "    \"device\": \"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    "    \"seed\": 0,\n",
    "    \"crop_win\": (22, 36),\n",
    "    \"wandb\": None,\n",
    "}\n",
    "print(f\"... Running on {config['device']} ...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(config[\"seed\"])\n",
    "torch.manual_seed(config[\"seed\"])\n",
    "random.seed(config[\"seed\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloaders = dict()\n",
    "config[\"data\"][\"mouse_v1\"] = None\n",
    "config[\"data\"][\"syn_dataset_config\"] = None\n",
    "config[\"data\"][\"data_augmentation\"] = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mouse V1 dataset (Sensorium 2022)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### prep data config\n",
    "config[\"data\"][\"mouse_v1\"] = {\n",
    "    \"dataset_fn\": \"sensorium.datasets.static_loaders\",\n",
    "    \"dataset_config\": {\n",
    "        \"paths\": [ # from https://gin.g-node.org/cajal/Sensorium2022/src/master\n",
    "            # os.path.join(DATA_PATH, \"static26872-17-20-GrayImageNet-94c6ff995dac583098847cfecd43e7b6.zip\"), # mouse 1\n",
    "            # os.path.join(DATA_PATH, \"static27204-5-13-GrayImageNet-94c6ff995dac583098847cfecd43e7b6.zip\"), # sensorium+ (mouse 2)\n",
    "            os.path.join(DATA_PATH, \"static21067-10-18-GrayImageNet-94c6ff995dac583098847cfecd43e7b6.zip\"), # pretraining (mouse 3)\n",
    "            # os.path.join(DATA_PATH, \"static22846-10-16-GrayImageNet-94c6ff995dac583098847cfecd43e7b6.zip\"), # pretraining (mouse 4)\n",
    "            # os.path.join(DATA_PATH, \"static23343-5-17-GrayImageNet-94c6ff995dac583098847cfecd43e7b6.zip\"), # pretraining (mouse 5)\n",
    "            # os.path.join(DATA_PATH, \"static23656-14-22-GrayImageNet-94c6ff995dac583098847cfecd43e7b6.zip\"), # pretraining (mouse 6)\n",
    "            # os.path.join(DATA_PATH, \"static23964-4-22-GrayImageNet-94c6ff995dac583098847cfecd43e7b6.zip\"), # pretraining (mouse 7)\n",
    "        ],\n",
    "        \"normalize\": True,\n",
    "        \"scale\": 0.25, # 256x144 -> 64x36\n",
    "        \"include_behavior\": False,\n",
    "        \"add_behavior_as_channels\": False,\n",
    "        \"include_eye_position\": True,\n",
    "        \"exclude\": None,\n",
    "        \"file_tree\": True,\n",
    "        \"cuda\": \"cuda\" in config[\"device\"],\n",
    "        \"batch_size\": 7,\n",
    "        \"seed\": config[\"seed\"],\n",
    "        \"use_cache\": False,\n",
    "    },\n",
    "    \"skip_train\": False,\n",
    "    \"skip_val\": False,\n",
    "    \"skip_test\": False,\n",
    "    \"normalize_neuron_coords\": True,\n",
    "    \"average_test_multitrial\": True,\n",
    "    \"save_test_multitrial\": True,\n",
    "    \"test_batch_size\": 7,\n",
    "    \"device\": config[\"device\"],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### get dataloaders and cell coordinates\n",
    "dataloaders, neuron_coords = get_mouse_v1_data(config[\"data\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### show data\n",
    "sample_data_key = dataloaders[\"mouse_v1\"][\"test\"].data_keys[0]\n",
    "datapoint = next(iter(dataloaders[\"mouse_v1\"][\"test\"].dataloaders[0]))\n",
    "stim, resp = datapoint.images, datapoint.responses\n",
    "pupil_center = datapoint.pupil_center\n",
    "print(\n",
    "    f\"Training dataset:\\t {sum(len(dl) * config['data']['mouse_v1']['dataset_config']['batch_size'] for dl in dataloaders['mouse_v1']['train'].dataloaders)} samples\"\n",
    "    f\"\\nValidation dataset:\\t {sum(len(dl) * config['data']['mouse_v1']['dataset_config']['batch_size'] for dl in dataloaders['mouse_v1']['val'].dataloaders)} samples\"\n",
    "    f\"\\nTest dataset:\\t\\t {sum(len(dl) * config['data']['mouse_v1']['dataset_config']['batch_size'] for dl in dataloaders['mouse_v1']['test'].dataloaders)} samples\"\n",
    "    f\"\\nTest (no resp) dataset:\\t {sum(len(dl) * config['data']['mouse_v1']['dataset_config']['batch_size'] for dl in dataloaders['mouse_v1']['test_no_resp'].dataloaders)} samples\"\n",
    "\n",
    "    \"\\n\\nstimuli:\"\n",
    "    f\"\\n  {stim.shape}\"\n",
    "    f\"\\n  min={stim.min().item():.3f}  max={stim.max().item():.3f}\"\n",
    "    f\"\\n  mean={stim.mean().item():.3f}  std={stim.std().item():.3f}\"\n",
    "    \"\\nresponses:\"\n",
    "    f\"\\n  {resp.shape}\"\n",
    "    f\"\\n  min={resp.min().item():.3f}  max={resp.max().item():.3f}\"\n",
    "    f\"\\n  mean={resp.mean().item():.3f}  std={resp.std().item():.3f}\"\n",
    "    \"\\nneuronal coordinates:\"\n",
    "    f\"\\n  {neuron_coords[sample_data_key].shape}\"\n",
    "    f\"\\n  min={neuron_coords[sample_data_key].min():.3f}  max={neuron_coords[sample_data_key].max():.3f}\"\n",
    "    f\"\\n  mean={neuron_coords[sample_data_key].mean():.3f}  std={neuron_coords[sample_data_key].std():.3f}\"\n",
    ")\n",
    "\n",
    "### plot sample data\n",
    "sample_idx = 0\n",
    "\n",
    "fig = plt.figure(figsize=(16, 6))\n",
    "ax = fig.add_subplot(131)\n",
    "ax.imshow(stim[sample_idx].squeeze().unsqueeze(-1).cpu(), cmap=\"gray\")\n",
    "\n",
    "ax = fig.add_subplot(132)\n",
    "ax.imshow(crop(stim[sample_idx].cpu(), config[\"crop_win\"]).squeeze().unsqueeze(-1), cmap=\"gray\")\n",
    "\n",
    "### bin the neuronal responses based on their neuron coordinates and sum within each bin -> 2D grid of vals\n",
    "coords = neuron_coords[sample_data_key]\n",
    "H, W = stim.shape[-2:] # the size of the grid\n",
    "n_x_bins, n_y_bins = 32, 18 # number of bins in each dimension\n",
    "min_x, max_x, min_y, max_y = coords[:,0].min().item(), coords[:,0].max().item(), coords[:,1].min().item(), coords[:,1].max().item()\n",
    "x_bins = torch.linspace(min_x, max_x, n_x_bins + 1)\n",
    "y_bins = torch.linspace(min_y, max_y, n_y_bins + 1)\n",
    "binned_resp = torch.zeros(n_y_bins, n_x_bins)\n",
    "for i in range(n_y_bins):\n",
    "    for j in range(n_x_bins):\n",
    "        ### mask of the neurons in the bin\n",
    "        mask = (x_bins[j] <= coords[:,0]) &\\\n",
    "               (coords[:,0] < x_bins[j + 1]) &\\\n",
    "               (y_bins[i] <= coords[:,1]) &\\\n",
    "               (coords[:,1] < y_bins[i + 1])\n",
    "        binned_resp[i,j] = resp[sample_idx, mask.cpu()].sum(0)\n",
    "ax = fig.add_subplot(133)\n",
    "ax.imshow(binned_resp.squeeze().cpu(), cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Synthetic dataset (different image stimuli -> encoder -> responses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### append synthetic data\n",
    "config[\"data\"][\"syn_dataset_config\"] = {\n",
    "    \"data_keys\": [\n",
    "        # \"21067-10-18\",\n",
    "        # \"22846-10-16\",\n",
    "        # \"23343-5-17\",\n",
    "        # \"23656-14-22\",\n",
    "        # \"23964-4-22\",\n",
    "    ],\n",
    "    \"batch_size\": 3,\n",
    "    \"append_data_parts\": [\"train\"],\n",
    "    \"data_key_prefix\": \"syn\",\n",
    "}\n",
    "\n",
    "dataloaders = append_syn_dataloaders(dataloaders, config=config[\"data\"][\"syn_dataset_config\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### show data\n",
    "syn_stim, syn_resp, syn_pupil_center = next(iter(dataloaders[\"mouse_v1\"][\"train\"].dataloaders[-1]))\n",
    "print(\n",
    "    f\"Training dataset:\\t {sum(len(dl) * config['data']['dataset_config']['batch_size'] for dl in dataloaders['mouse_v1']['train'].dataloaders)} samples\"\n",
    "    f\"\\nValidation dataset:\\t {sum(len(dl) * config['data']['dataset_config']['batch_size'] for dl in dataloaders['mouse_v1']['val'].dataloaders)} samples\"\n",
    "    f\"\\nTest dataset:\\t\\t {sum(len(dl) * config['data']['dataset_config']['batch_size'] for dl in dataloaders['mouse_v1']['test'].dataloaders)} samples\"\n",
    "    f\"\\nTest (no resp) dataset:\\t {sum(len(dl) * config['data']['dataset_config']['batch_size'] for dl in dataloaders['mouse_v1']['test_no_resp'].dataloaders)} samples\"\n",
    "\n",
    "    \"\\n\\nstimuli:\"\n",
    "    f\"\\n  {syn_stim.shape}\"\n",
    "    f\"\\n  min={syn_stim.min().item():.3f}  max={syn_stim.max().item():.3f}\"\n",
    "    f\"\\n  mean={syn_stim.mean().item():.3f}  std={syn_stim.std().item():.3f}\"\n",
    "    \"\\nresponses:\"\n",
    "    f\"\\n  {syn_resp.shape}\"\n",
    "    f\"\\n  min={syn_resp.min().item():.3f}  max={syn_resp.max().item():.3f}\"\n",
    "    f\"\\n  mean={syn_resp.mean().item():.3f}  std={syn_resp.std().item():.3f}\"\n",
    "    \"\\nNeuron coordinates:\"\n",
    "    f\"\\n  {neuron_coords[sample_data_key].shape}\"\n",
    "    f\"\\n  min={neuron_coords[sample_data_key].min():.3f}  max={neuron_coords[sample_data_key].max():.3f}\"\n",
    "    f\"\\n  mean={neuron_coords[sample_data_key].mean():.3f}  std={neuron_coords[sample_data_key].std():.3f}\"\n",
    "    \"\\nPupil center:\"\n",
    "    f\"\\n  {syn_pupil_center.shape}\"\n",
    "    f\"\\n  min={syn_pupil_center.min().item():.3f}  max={syn_pupil_center.max().item():.3f}\"\n",
    "    f\"\\n  mean={syn_pupil_center.mean().item():.3f}  std={syn_pupil_center.std().item():.3f}\"\n",
    ")\n",
    "\n",
    "fig = plt.figure(figsize=(16, 6))\n",
    "ax = fig.add_subplot(121)\n",
    "ax.imshow(syn_stim[0].squeeze().unsqueeze(-1).cpu(), cmap=\"gray\")\n",
    "\n",
    "ax = fig.add_subplot(122)\n",
    "reshape_to = None\n",
    "for i in range(30, 150):\n",
    "    if syn_resp.shape[-1] % i == 0:\n",
    "        reshape_to = (i, syn_resp.shape[-1] // i)\n",
    "        break\n",
    "if reshape_to != None:\n",
    "    ax.imshow(syn_resp[0].view(reshape_to).squeeze(0).unsqueeze(-1).cpu(), cmap=\"gray\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = get_encoder(device=config[\"device\"], eval_mode=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare decoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_decoder(model, dataloader, loss_fns, normalize_decoded, config):\n",
    "    model.eval()\n",
    "    val_losses = {loss_fn_name: {\"total\": 0} for loss_fn_name in loss_fns.keys()}\n",
    "    i = 0\n",
    "    denom_data_keys = {}\n",
    "\n",
    "    for b in dataloader:\n",
    "        ### combine from all data keys\n",
    "        for data_key, stim, resp, neuron_coords, pupil_center in b:\n",
    "            if model.__class__.__name__ == \"InvertedEncoder\":\n",
    "                stim_pred, _, _ = model(\n",
    "                    resp_target=resp,\n",
    "                    stim_target=stim,\n",
    "                    additional_encoder_inp={\n",
    "                        \"data_key\": data_key,\n",
    "                        \"pupil_center\": pupil_center,\n",
    "                    }\n",
    "                )\n",
    "            elif hasattr(model, \"core\") and model.core.__class__.__name__ == \"L2O_Decoder\":\n",
    "                raise NotImplementedError(\"L2O_Decoder not implemented yet - data needs to be standardized\")\n",
    "                stim_pred, _ = model(\n",
    "                    x=resp,\n",
    "                    data_key=data_key,\n",
    "                    neuron_coords=neuron_coords,\n",
    "                    pupil_center=pupil_center,\n",
    "                    additional_core_inp=dict(\n",
    "                        train=False,\n",
    "                        stim=None,\n",
    "                        resp=resp,\n",
    "                        neuron_coords=neuron_coords,\n",
    "                        pupil_center=pupil_center,\n",
    "                        data_key=data_key,\n",
    "                        n_steps=config[\"decoder\"][\"n_steps\"],\n",
    "                        x_hat_history_iters=None,\n",
    "                    ),\n",
    "                )\n",
    "            elif isinstance(model, BoostedInvertedEncoder):\n",
    "                stim_pred, _, _ = model(\n",
    "                    resp,\n",
    "                    train=False,\n",
    "                    data_key=data_key,\n",
    "                    neuron_coords=neuron_coords,\n",
    "                    pupil_center=pupil_center,\n",
    "                )\n",
    "            else:\n",
    "                stim_pred = model(\n",
    "                    resp,\n",
    "                    data_key=data_key,\n",
    "                    neuron_coords=neuron_coords,\n",
    "                    pupil_center=pupil_center,\n",
    "                )\n",
    "\n",
    "            if normalize_decoded:\n",
    "                stim_pred = normalize(stim_pred)\n",
    "\n",
    "            for loss_fn_name, loss_fn in loss_fns.items():\n",
    "                loss = loss_fn(stim_pred, stim, data_key=data_key, phase=\"val\").item()\n",
    "                val_losses[loss_fn_name][\"total\"] += loss\n",
    "                val_losses[loss_fn_name][data_key] = loss if data_key not in val_losses[loss_fn_name] else val_losses[loss_fn_name][data_key] + loss\n",
    "            \n",
    "            i += stim.shape[0]\n",
    "            denom_data_keys[data_key] = denom_data_keys[data_key] + stim.shape[0] if data_key in denom_data_keys else stim.shape[0]\n",
    "\n",
    "    for loss_name in val_losses:\n",
    "        val_losses[loss_name][\"total\"] /= i\n",
    "        for k in denom_data_keys:\n",
    "            val_losses[loss_name][k] /= denom_data_keys[k]\n",
    "\n",
    "    return val_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_data(config):\n",
    "    dls, neuron_coords = get_mouse_v1_data(config=config[\"data\"])\n",
    "    if \"syn_dataset_config\" in config[\"data\"] and config[\"data\"][\"syn_dataset_config\"] is not None:\n",
    "        dls = append_syn_dataloaders(dls, config=config[\"data\"][\"syn_dataset_config\"]) # append synthetic data\n",
    "    if \"data_augmentation\" in config[\"data\"] and config[\"data\"][\"data_augmentation\"] is not None:\n",
    "        dls = append_data_aug_dataloaders(\n",
    "            dataloaders=dls,\n",
    "            config=config[\"data\"][\"data_augmentation\"],\n",
    "        )\n",
    "    return dls, neuron_coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### config for collecting results (1)\n",
    "runs_to_compare = {}\n",
    "# runs_to_compare = torch.load(\n",
    "#     \"encoder_inversion_eval_all_mice_26-03-24.pt\", pickle_module=dill\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Encoder Inversion \"\"\"\n",
    "# runs_to_compare[\"Inverted Encoder\"] = torch.load(\"encoder_inversion_eval_all_mice.pt\", pickle_module=dill)[\"Inverted Encoder\"]\n",
    "runs_to_compare[\"Inverted Encoder\"] = {\n",
    "    \"decoder\": InvertedEncoder(\n",
    "        encoder=encoder,\n",
    "        img_dims=stim.shape[1:],\n",
    "        stim_pred_init=\"zeros\",\n",
    "        opter_cls=torch.optim.SGD,\n",
    "        opter_config={\"lr\": 1500, \"momentum\": 0},\n",
    "        n_steps=400,\n",
    "        resp_loss_fn=F.mse_loss,\n",
    "        stim_loss_fn=SSIMLoss(\n",
    "            window=config[\"crop_win\"],\n",
    "            log_loss=True,\n",
    "            inp_normalized=True,\n",
    "            inp_standardized=False,\n",
    "        ),\n",
    "        img_gauss_blur_config=None,\n",
    "        img_grad_gauss_blur_config={\"kernel_size\": 17, \"sigma\": 2},\n",
    "        device=config[\"device\"],\n",
    "    ).to(config[\"device\"]),\n",
    "    \"run_name\": None\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### config for collecting results (2)\n",
    "# ### FCReadIn\n",
    "# \"FCReadIn\": {\n",
    "#     \"run_name\": \"2024-02-25_17-09-59\",\n",
    "#     \"ckpt_path\": os.path.join(DATA_PATH, \"models\", \"cnn\", \"2024-02-25_17-09-59\", \"decoder.pt\"),\n",
    "# },\n",
    "# \"FCReadIn - Autoencoding\": {\n",
    "#     \"run_name\": \"2024-02-27_00-27-17\",\n",
    "#     \"ckpt_path\": os.path.join(DATA_PATH, \"models\", \"cnn\", \"2024-02-27_00-27-17\", \"decoder.pt\"),\n",
    "# },\n",
    "# \"FCReadIn - Contrastive reg.\": {\n",
    "#     \"run_name\": \"2024-02-28_21-27-46\",\n",
    "#     \"ckpt_path\": os.path.join(DATA_PATH, \"models\", \"cnn\", \"2024-02-28_21-27-46\", \"decoder.pt\"),\n",
    "# },\n",
    "\n",
    "# ### ConvReadIn\n",
    "# \"ConvReadIn\": {\n",
    "#     \"run_name\": \"2024-02-25_21-16-59\",\n",
    "#     \"ckpt_path\": os.path.join(DATA_PATH, \"models\", \"cnn\", \"2024-02-25_21-16-59\", \"decoder.pt\"),\n",
    "# },\n",
    "# # \"ConvReadIn - no shift\": {\n",
    "# \"ConvReadIn - no pupil center training\": {\n",
    "#     \"run_name\": \"2024-03-06_12-46-53\",\n",
    "#     \"ckpt_path\": os.path.join(DATA_PATH, \"models\", \"cnn\", \"2024-03-06_12-46-53\", \"decoder.pt\"),\n",
    "# },\n",
    "# \"ConvReadIn - Autoencoding\": {\n",
    "#     \"run_name\": \"2024-02-27_13-01-15\",\n",
    "#     \"ckpt_path\": os.path.join(DATA_PATH, \"models\", \"cnn\", \"2024-02-27_13-01-15\", \"decoder.pt\"),\n",
    "# },\n",
    "# \"ConvReadIn - Contrastive reg.\": {\n",
    "#     \"run_name\": \"2024-02-27_00-04-30\",\n",
    "#     \"ckpt_path\": os.path.join(DATA_PATH, \"models\", \"cnn\", \"2024-02-27_00-04-30\", \"decoder.pt\"),\n",
    "# },\n",
    "# \"ConvReadIn - Fine-tuned\": {\n",
    "#     \"run_name\": \"2024-02-28_00-55-12\",\n",
    "#     \"ckpt_path\": os.path.join(DATA_PATH, \"models\", \"cnn\", \"2024-02-28_00-55-12\", \"decoder.pt\"),\n",
    "# },\n",
    "# \"ConvReadIn - From scratch\": { # comparison to the above\n",
    "#     \"run_name\": \"2024-02-28_00-59-51\",\n",
    "#     \"ckpt_path\": os.path.join(DATA_PATH, \"models\", \"cnn\", \"2024-02-28_00-59-51\", \"decoder.pt\"),\n",
    "# },\n",
    "# runs_to_compare[\"ConvReadIn - Con. reg.\"] = {\n",
    "#     \"run_name\": \"2024-03-02_12-28-42\",\n",
    "#     \"ckpt_path\": os.path.join(DATA_PATH, \"models\", \"cnn\", \"2024-03-02_12-28-42\", \"decoder.pt\"),\n",
    "# }\n",
    "# runs_to_compare[\"ConvReadIn - Con. reg., no shifter\"] = {\n",
    "#     \"run_name\": \"2024-03-18_01-12-49\",\n",
    "#     \"ckpt_path\": os.path.join(DATA_PATH, \"models\", \"cnn\", \"2024-03-18_01-12-49\", \"decoder.pt\"),\n",
    "# }\n",
    "# runs_to_compare[\"ConvReadIn - Con. reg. + Fine-tuned\"] = {\n",
    "#         \"run_name\": \"2024-02-28_13-08-22\",\n",
    "#         \"ckpt_path\": os.path.join(DATA_PATH, \"models\", \"cnn\", \"2024-02-28_13-08-22\", \"decoder.pt\"),\n",
    "#     }\n",
    "# runs_to_compare[\"ConvReadIn - Con. reg. (large) with neuron embeddings\"] = {\n",
    "#     \"run_name\": \"2024-03-03_00-59-02\",\n",
    "#     \"ckpt_path\": os.path.join(DATA_PATH, \"models\", \"cnn\", \"2024-03-03_00-59-02\", \"decoder.pt\"),\n",
    "# }\n",
    "# runs_to_compare[\"ConvReadIn - Con. reg. + Data aug.\"] = {\n",
    "#     \"run_name\": \"2024-03-08_13-08-36\",\n",
    "#     \"ckpt_path\": os.path.join(DATA_PATH, \"models\", \"cnn\", \"2024-03-08_13-08-36\", \"decoder.pt\"),\n",
    "# }\n",
    "# runs_to_compare[\"ConvReadIn - Synth. data 43%\"] = {\n",
    "#     \"run_name\": \"2024-03-11_01-05-34\",\n",
    "#     \"ckpt_path\": os.path.join(DATA_PATH, \"models\", \"cnn\", \"2024-03-11_01-05-34\", \"decoder.pt\"),\n",
    "# }\n",
    "# runs_to_compare[\"ConvReadIn - Synth. data 30% + Data aug.\"] = {\n",
    "#     \"run_name\": \"2024-03-11_20-03-03\",\n",
    "#     \"ckpt_path\": os.path.join(DATA_PATH, \"models\", \"cnn\", \"2024-03-11_20-03-03\", \"decoder.pt\"),\n",
    "# }\n",
    "# runs_to_compare[\"Con. reg.\"] = {\n",
    "#     \"run_name\": \"2024-03-18_01-12-49\",\n",
    "#     \"ckpt_path\": os.path.join(DATA_PATH, \"models\", \"cnn\", \"2024-03-18_01-12-49\", \"decoder.pt\"),\n",
    "# }\n",
    "\n",
    "\n",
    "\n",
    "### Single datasets\n",
    "# runs_to_compare[\"ConvReadIn (mouse #1) - Fine-tuned\"] = {\n",
    "#     \"run_name\": \"2024-02-28_13-09-19\",\n",
    "#     \"ckpt_path\": os.path.join(DATA_PATH, \"models\", \"cnn\", \"2024-02-28_13-09-19\", \"decoder.pt\"),\n",
    "# }\n",
    "# runs_to_compare[\"ConvReadIn (mouse #1) - From scratch\"] = {\n",
    "#     \"run_name\": \"2024-02-28_15-10-47\",\n",
    "#     \"ckpt_path\": os.path.join(DATA_PATH, \"models\", \"cnn\", \"2024-02-28_15-10-47\", \"decoder.pt\"),\n",
    "# }\n",
    "# \"ConvReadIn (mouse #1) - With neuron embeddings\": {\n",
    "#     \"run_name\": \"2024-03-03_19-47-31\",\n",
    "#     \"ckpt_path\": os.path.join(DATA_PATH, \"models\", \"cnn\", \"2024-03-03_19-47-31\", \"decoder.pt\"),\n",
    "# },\n",
    "# runs_to_compare[\"ConvReadIn (mouse #1) - From scratch + Synth. data 50%\"] = {\n",
    "#     \"run_name\": \"2024-03-10_21-32-52\",\n",
    "#     \"ckpt_path\": os.path.join(DATA_PATH, \"models\", \"cnn\", \"2024-03-10_21-32-52\", \"decoder.pt\"),\n",
    "# }\n",
    "# runs_to_compare[\"ConvReadIn (mouse #1) - From scratch + Synth. data 40% + Data aug.\"] = {\n",
    "#     \"run_name\": \"2024-03-12_18-52-18\",\n",
    "#     \"ckpt_path\": os.path.join(DATA_PATH, \"models\", \"cnn\", \"2024-03-12_18-52-18\", \"decoder.pt\"),\n",
    "# }\n",
    "# runs_to_compare[\"ConvReadIn (mouse #1) - From scratch, SSIM\"] = {\n",
    "#     \"run_name\": \"2024-03-16_17-13-54\",\n",
    "#     \"ckpt_path\": os.path.join(DATA_PATH, \"models\", \"cnn\", \"2024-03-16_17-13-54\", \"decoder.pt\"),\n",
    "# }\n",
    "# runs_to_compare[\"ConvReadIn (mouse #1) - From scratch, SSIM, no z-coord\"] = {\n",
    "#     \"run_name\": \"2024-03-17_11-16-25\",\n",
    "#     \"ckpt_path\": os.path.join(DATA_PATH, \"models\", \"cnn\", \"2024-03-17_11-16-25\", \"decoder.pt\"),\n",
    "# }\n",
    "# runs_to_compare[\"ConvReadIn (mouse #1) - From scratch, MultiSSIM\"] = {\n",
    "#     \"run_name\": \"2024-03-16_21-01-52\",\n",
    "#     \"ckpt_path\": os.path.join(DATA_PATH, \"models\", \"cnn\", \"2024-03-16_21-01-52\", \"decoder.pt\"),\n",
    "# }\n",
    "# \"Boosted Inverted Encoder (mouse #1)\": {\n",
    "#     \"run_name\": \"2024-03-06_01-15-13\",\n",
    "#     \"ckpt_path\": os.path.join(DATA_PATH, \"models\", \"boosted_inverted_encoder\", \"2024-03-06_01-15-13\", \"decoder.pt\"),\n",
    "# },\n",
    "# \"Boosted Inverted Encoder (mouse #1)\": {\n",
    "#     \"run_name\": \"2024-03-07_01-01-23\",\n",
    "#     \"ckpt_path\": os.path.join(DATA_PATH, \"models\", \"boosted_inverted_encoder\", \"2024-03-07_01-01-23\", \"decoder.pt\"),\n",
    "# },"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" MEIReadIn \"\"\"\n",
    "# runs_to_compare[\"ConvReadIn (all datasets)\"] = {\n",
    "#     \"run_name\": \"2024-03-26_10-36-00\",\n",
    "#     \"ckpt_path\": os.path.join(DATA_PATH, \"models\", \"cnn\", \"2024-03-26_10-36-00\", \"decoder.pt\"),\n",
    "# }\n",
    "# runs_to_compare[\"MEIReadIn (all datasets)\"] = {\n",
    "#     \"run_name\": \"2024-03-24_14-24-59\",\n",
    "#     \"ckpt_path\": os.path.join(DATA_PATH, \"models\", \"cnn\", \"2024-03-24_14-24-59\", \"decoder.pt\"),\n",
    "# }\n",
    "\n",
    "# runs_to_compare[\"ConvReadIn (mouse #1)\"] = {\n",
    "#     \"run_name\": \"2024-03-24_11-07-15\",\n",
    "#     \"ckpt_path\": os.path.join(DATA_PATH, \"models\", \"cnn\", \"2024-03-24_11-07-15\", \"decoder.pt\"),\n",
    "# }\n",
    "# runs_to_compare[\"MEIReadIn (mouse #1)\"] = {\n",
    "#     \"run_name\": \"2024-03-25_16-22-15\",\n",
    "#     \"ckpt_path\": os.path.join(DATA_PATH, \"models\", \"cnn\", \"2024-03-25_16-22-15\", \"decoder.pt\"),\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Training w/ different loss functions \"\"\"\n",
    "runs_to_compare[\"Log SSIM\"] = {\n",
    "    \"run_name\": \"2024-03-16_17-13-54\",\n",
    "    \"ckpt_path\": os.path.join(DATA_PATH, \"models\", \"cnn\", \"2024-03-16_17-13-54\", \"decoder.pt\"),\n",
    "}\n",
    "runs_to_compare[\"Log MultiSSIM\"] = {\n",
    "    \"run_name\": \"2024-03-16_21-01-52\",\n",
    "    \"ckpt_path\": os.path.join(DATA_PATH, \"models\", \"cnn\", \"2024-03-16_21-01-52\", \"decoder.pt\"),\n",
    "}\n",
    "runs_to_compare[\"MSE\"] = {\n",
    "    \"run_name\": \"2024-03-13_16-43-29\",\n",
    "    \"ckpt_path\": os.path.join(DATA_PATH, \"models\", \"cnn\", \"2024-03-13_16-43-29\", \"decoder.pt\"),\n",
    "}\n",
    "runs_to_compare[\"0.5 * MSE + 0.5 * Log SSIM\"] = {\n",
    "    \"run_name\": \"2024-03-14_00-46-57\",\n",
    "    \"ckpt_path\": os.path.join(DATA_PATH, \"models\", \"cnn\", \"2024-03-14_00-46-57\", \"decoder.pt\"),\n",
    "}\n",
    "runs_to_compare[\"0.9 * MSE + 0.1 * Log SSIM\"] = {\n",
    "    \"run_name\": \"2024-03-14_13-23-58\",\n",
    "    \"ckpt_path\": os.path.join(DATA_PATH, \"models\", \"cnn\", \"2024-03-14_13-23-58\", \"decoder.pt\"),\n",
    "}\n",
    "runs_to_compare[\"0.1 * MSE + 0.9 * Log SSIM\"] = {\n",
    "    \"run_name\": \"2024-03-14_19-40-02\",\n",
    "    \"ckpt_path\": os.path.join(DATA_PATH, \"models\", \"cnn\", \"2024-03-14_19-40-02\", \"decoder.pt\"),\n",
    "}\n",
    "runs_to_compare[\"MAE\"] = {\n",
    "    \"run_name\": \"2024-03-16_13-40-03\",\n",
    "    \"ckpt_path\": os.path.join(DATA_PATH, \"models\", \"cnn\", \"2024-03-16_13-40-03\", \"decoder.pt\"),\n",
    "}\n",
    "runs_to_compare[\"FFL\"] = {\n",
    "    \"run_name\": \"2024-03-17_00-36-23\",\n",
    "    \"ckpt_path\": os.path.join(DATA_PATH, \"models\", \"cnn\", \"2024-03-17_00-36-23\", \"decoder.pt\"),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Synthetic data comparison (new stimuli) \"\"\"\n",
    "### all datasets\n",
    "# runs_to_compare[\"Synth. data 0%\"] = {\n",
    "#     \"run_name\": \"2024-03-26_10-36-00\",\n",
    "#     \"ckpt_path\": os.path.join(DATA_PATH, \"models\", \"cnn\", \"2024-03-26_10-36-00\", \"decoder.pt\"),\n",
    "# }\n",
    "# runs_to_compare[\"Synth. data 25%\"] = {\n",
    "#     \"run_name\": \"2024-03-24_11-43-39\",\n",
    "#     \"ckpt_path\": os.path.join(DATA_PATH, \"models\", \"cnn\", \"2024-03-24_11-43-39\", \"decoder.pt\"),\n",
    "# }\n",
    "# runs_to_compare[\"Synth. data 50%\"] = {\n",
    "#     \"run_name\": \"2024-03-24_00-22-38\",\n",
    "#     \"ckpt_path\": os.path.join(DATA_PATH, \"models\", \"cnn\", \"2024-03-24_00-22-38\", \"decoder.pt\"),\n",
    "# }\n",
    "# runs_to_compare[\"Synth. data 75%\"] = {\n",
    "#     \"run_name\": \"2024-03-24_20-58-11\",\n",
    "#     \"ckpt_path\": os.path.join(DATA_PATH, \"models\", \"cnn\", \"2024-03-24_20-58-11\", \"decoder.pt\"),\n",
    "# }\n",
    "# runs_to_compare[\"Synth. data 100%\"] = {\n",
    "#     \"run_name\": \"2024-03-25_21-37-04\",\n",
    "#     \"ckpt_path\": os.path.join(DATA_PATH, \"models\", \"cnn\", \"2024-03-25_21-37-04\", \"decoder.pt\"),\n",
    "# }\n",
    "\n",
    "### single datasets\n",
    "# runs_to_compare[\"Synth. data 0% (all datasets)\"] = {\n",
    "#     \"run_name\": \"2024-03-26_10-36-00\",\n",
    "#     \"ckpt_path\": os.path.join(DATA_PATH, \"models\", \"cnn\", \"2024-03-26_10-36-00\", \"decoder.pt\"),\n",
    "# }\n",
    "# runs_to_compare[\"Synth. data 0%\"] = {\n",
    "#     \"run_name\": \"2024-03-24_11-07-15\",\n",
    "#     \"ckpt_path\": os.path.join(DATA_PATH, \"models\", \"cnn\", \"2024-03-24_11-07-15\", \"decoder.pt\"),\n",
    "# }\n",
    "# runs_to_compare[\"Synth. data 25%\"] = {\n",
    "#     \"run_name\": \"2024-03-24_11-10-27\",\n",
    "#     \"ckpt_path\": os.path.join(DATA_PATH, \"models\", \"cnn\", \"2024-03-24_11-10-27\", \"decoder.pt\"),\n",
    "# }\n",
    "# runs_to_compare[\"Synth. data 25%, noise\"] = {\n",
    "#     \"run_name\": \"2024-03-26_14-06-06\",\n",
    "#     \"ckpt_path\": os.path.join(DATA_PATH, \"models\", \"cnn\", \"2024-03-26_14-06-06\", \"decoder.pt\"),\n",
    "# }\n",
    "# runs_to_compare[\"Synth. data 50%\"] = {\n",
    "#     \"run_name\": \"2024-03-24_11-00-40\",\n",
    "#     \"ckpt_path\": os.path.join(DATA_PATH, \"models\", \"cnn\", \"2024-03-24_11-00-40\", \"decoder.pt\"),\n",
    "# }\n",
    "# runs_to_compare[\"Synth. data 50%, noise\"] = {\n",
    "#     \"run_name\": \"2024-03-26_10-09-50\",\n",
    "#     \"ckpt_path\": os.path.join(DATA_PATH, \"models\", \"cnn\", \"2024-03-26_10-09-50\", \"decoder.pt\"),\n",
    "# }\n",
    "# runs_to_compare[\"Synth. data 75%\"] = {\n",
    "#     \"run_name\": \"2024-03-25_16-13-34\",\n",
    "#     \"ckpt_path\": os.path.join(DATA_PATH, \"models\", \"cnn\", \"2024-03-25_16-13-34\", \"decoder.pt\"),\n",
    "# }\n",
    "# runs_to_compare[\"Synth. data 100%\"] = {\n",
    "#     \"run_name\": \"2024-03-25_23-47-06\",\n",
    "#     \"ckpt_path\": os.path.join(DATA_PATH, \"models\", \"cnn\", \"2024-03-25_23-47-06\", \"decoder.pt\"),\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Metrics \"\"\"\n",
    "loss_fns = {\n",
    "    \"Log SSIM Loss\": SSIMLoss(\n",
    "        window=config[\"crop_win\"],\n",
    "        log_loss=True,\n",
    "        inp_normalized=True,\n",
    "        inp_standardized=False,\n",
    "        reduction=\"sum\",\n",
    "    ),\n",
    "    \"Log MultiSSIM Loss\": MultiSSIMLoss(\n",
    "        window=config[\"crop_win\"],\n",
    "        log_loss=True,\n",
    "        inp_normalized=True,\n",
    "        inp_standardized=False,\n",
    "        reduction=\"sum\",\n",
    "    ),\n",
    "    \"SSIM Loss\": SSIMLoss(\n",
    "        window=config[\"crop_win\"],\n",
    "        log_loss=False,\n",
    "        inp_normalized=True,\n",
    "        inp_standardized=False,\n",
    "        reduction=\"sum\",\n",
    "    ),\n",
    "    \"MultiSSIM Loss\": MultiSSIMLoss(\n",
    "        window=config[\"crop_win\"],\n",
    "        log_loss=False,\n",
    "        inp_normalized=True,\n",
    "        inp_standardized=False,\n",
    "        reduction=\"sum\",\n",
    "    ),\n",
    "    \"Perceptual Loss (VGG16)\": CroppedLoss(\n",
    "        window=config[\"crop_win\"],\n",
    "        normalize=False,\n",
    "        standardize=True,\n",
    "        loss_fn=VGGPerceptualLoss(\n",
    "            resize=False,\n",
    "            device=config[\"device\"],\n",
    "        ),\n",
    "    ),\n",
    "    \"Perceptual Loss (Encoder)\": CroppedLoss(\n",
    "        window=config[\"crop_win\"],\n",
    "        normalize=True,\n",
    "        standardize=False,\n",
    "        loss_fn=EncoderPerceptualLoss(\n",
    "            encoder=encoder,\n",
    "            device=config[\"device\"],\n",
    "        ),\n",
    "    ),\n",
    "    \"FFL\": CroppedLoss(\n",
    "        window=config[\"crop_win\"],\n",
    "        normalize=False,\n",
    "        standardize=True,\n",
    "        loss_fn=FFL(loss_weight=1, alpha=1.0),\n",
    "    ),\n",
    "    \"MSE\": lambda x_hat, x: F.mse_loss(\n",
    "        standardize(crop(x_hat, config[\"crop_win\"])),\n",
    "        standardize(crop(x, config[\"crop_win\"])),\n",
    "        reduction=\"none\",\n",
    "    ).mean((1,2,3)).sum(),\n",
    "    \"MAE\": lambda x_hat, x: F.l1_loss(\n",
    "        standardize(crop(x_hat, config[\"crop_win\"])),\n",
    "        standardize(crop(x, config[\"crop_win\"])),\n",
    "        reduction=\"none\",\n",
    "    ).mean((1,2,3)).sum(),\n",
    "}\n",
    "for k in loss_fns.keys():\n",
    "    loss_fns[k] = Loss(\n",
    "        model=None,\n",
    "        config={\n",
    "            \"loss_fn\": loss_fns[k],\n",
    "            \"l1_reg_mul\": 0,\n",
    "            \"l2_reg_mul\": 0,\n",
    "            \"con_reg_mul\": 0,\n",
    "        }\n",
    "    )\n",
    "\n",
    "eval_all_ckpts = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_best = False\n",
    "eval_all_ckpts = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### load models\n",
    "if load_best and eval_all_ckpts:\n",
    "    print(\"[WARNING] both the eval_all_ckpts and load_best are set to True - still loading current (not the best) decoders.\")\n",
    "\n",
    "for k in runs_to_compare.keys():\n",
    "    if \"test_losses\" in runs_to_compare[k]:\n",
    "        continue\n",
    "    run_dict = runs_to_compare[k]\n",
    "    run_name = run_dict[\"run_name\"]\n",
    "\n",
    "    ckpt_paths = []\n",
    "    if \"decoder\" in run_dict and run_dict[\"decoder\"] is not None:\n",
    "        ckpt_paths.append(None)\n",
    "    else:\n",
    "        if eval_all_ckpts:\n",
    "            ckpts_dir = os.path.join(os.path.dirname(run_dict[\"ckpt_path\"]), \"ckpt\")\n",
    "            ckpt_paths.extend([os.path.join(os.path.dirname(run_dict[\"ckpt_path\"]), \"ckpt\", ckpt_name) for ckpt_name in os.listdir(ckpts_dir)])\n",
    "        else:\n",
    "            ckpt_paths.append(run_dict[\"ckpt_path\"])\n",
    "\n",
    "    ### eval all ckpts\n",
    "    all_test_losses, all_configs, all_histories, all_best_val_losses, all_stim_pred_best = [], [], [], [], []\n",
    "    for ckpt_path in ckpt_paths:\n",
    "        if \"decoder\" in run_dict and run_dict[\"decoder\"] is not None:\n",
    "            print(f\"Using {k} model from run_dict...\")\n",
    "            decoder = run_dict[\"decoder\"]\n",
    "            ckpt = None\n",
    "        elif \"boosted_inverted_encoder\" in ckpt_path:\n",
    "            assert NotImplementedError(\"Not update, check.\")\n",
    "            ### load ckpt and init\n",
    "            ckpt = torch.load(ckpt_path, map_location=config[\"device\"], pickle_module=dill)\n",
    "            ckpt_config = ckpt[\"config\"]\n",
    "            decoder = BoostedInvertedEncoder(**ckpt_config[\"decoder\"][\"model\"]).to(config[\"device\"])\n",
    "            decoder.load_state_dict(ckpt[\"best\"][\"model\"], strict=True)\n",
    "            decoder.eval()\n",
    "        else:\n",
    "            print(f\"Loading {k} model from ckpt (run name: {run_name})...\")\n",
    "            ### load ckpt and init\n",
    "            ckpt = torch.load(ckpt_path, map_location=config[\"device\"], pickle_module=dill)\n",
    "            ckpt_config = ckpt[\"config\"]\n",
    "            ### TODO: remove (quick fix)\n",
    "            # if ckpt[\"best\"][f\"model\"][\"readins.21067-10-18.0.grid_net.0.weight\"].shape[-1] == 4:\n",
    "            #     for rc in ckpt_config[\"decoder\"][\"model\"][\"readins_config\"]:\n",
    "            #         rc[\"layers\"][0][1][\"grid_net_config\"] = {\n",
    "            #             \"in_channels\": 4, # x, y, resp\n",
    "            #             \"layers_config\": [(\"fc\", 32), (\"fc\", 64), (\"fc\", 16*9)],\n",
    "            #             \"act_fn\": nn.LeakyReLU,\n",
    "            #             \"out_act_fn\": nn.Identity,\n",
    "            #             \"dropout\": 0.1,\n",
    "            #             \"batch_norm\": False,\n",
    "            #         }\n",
    "            # for rc in ckpt_config[\"decoder\"][\"model\"][\"readins_config\"]:\n",
    "            #     rc[\"layers\"][0][1][\"meis_path\"] = rc[\"layers\"][0][1][\"meis_path\"].replace(\n",
    "            #         \"/home/sobotj11/decoding-brain-activity/data/mouse_v1_sensorium22/meis/\",\n",
    "            #         \"/media/jsobotka/ext_ssd/csng_data/mouse_v1_sensorium22/meis/\"\n",
    "            #     )\n",
    "            decoder = MultiReadIn(**ckpt_config[\"decoder\"][\"model\"]).to(config[\"device\"])\n",
    "            if eval_all_ckpts or not load_best:\n",
    "                decoder.load_state_dict(ckpt[\"decoder\"])\n",
    "            else:\n",
    "                decoder.load_state_dict(ckpt[\"best\"][\"model\"])\n",
    "            decoder.eval()\n",
    "        \n",
    "        ### get reconstructions\n",
    "        if decoder.__class__.__name__ == \"InvertedEncoder\":\n",
    "            stim_pred_best, _, _ = decoder(\n",
    "                resp.to(config[\"device\"]),\n",
    "                stim.to(config[\"device\"]),\n",
    "                additional_encoder_inp={\n",
    "                    \"data_key\": sample_data_key,\n",
    "                    \"pupil_center\": pupil_center.to(config[\"device\"]),\n",
    "                }\n",
    "            )\n",
    "            stim_pred_best = stim_pred_best.detach().cpu()\n",
    "        else:\n",
    "            stim_pred_best = decoder(\n",
    "                resp.to(config[\"device\"]),\n",
    "                data_key=sample_data_key,\n",
    "                neuron_coords=neuron_coords[sample_data_key],\n",
    "                pupil_center=pupil_center.to(config[\"device\"]),\n",
    "            ).detach().cpu()\n",
    "\n",
    "        ### eval\n",
    "        dls, neuron_coords = get_all_data(config=config)\n",
    "        test_losses = eval_decoder(\n",
    "            model=decoder,\n",
    "            dataloader=dls[\"mouse_v1\"][\"test\"],\n",
    "            loss_fns=loss_fns,\n",
    "            # normalize_decoded=True if \"l2o\" in k.lower() else False,\n",
    "            normalize_decoded=False,\n",
    "            config=config,\n",
    "        )\n",
    "\n",
    "        all_test_losses.append(test_losses)\n",
    "        all_configs.append(ckpt_config if ckpt is not None else None)\n",
    "        all_histories.append(ckpt[\"history\"] if ckpt is not None else None)\n",
    "        all_best_val_losses.append(ckpt[\"best\"][\"val_loss\"] if ckpt is not None else None)\n",
    "        all_stim_pred_best.append(stim_pred_best.detach().cpu())\n",
    "\n",
    "    ### save\n",
    "    runs_to_compare[k][\"test_losses\"] = all_test_losses\n",
    "    runs_to_compare[k][\"config\"] = all_configs\n",
    "    runs_to_compare[k][\"history\"] = all_histories\n",
    "    runs_to_compare[k][\"best_val_loss\"] = all_best_val_losses\n",
    "    runs_to_compare[k][\"stim_pred_best\"] = all_stim_pred_best\n",
    "    runs_to_compare[k][\"ckpt_paths\"] = ckpt_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### save all_test_losses\n",
    "# torch.save(runs_to_compare, \"16-03-24__encoder_inversion_eval_all_mice.pt\", pickle_module=dill)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### plot losses together\n",
    "\n",
    "### config\n",
    "to_plot = \"val_loss\"\n",
    "conv_win = 10\n",
    "ckpt_idx = 0\n",
    "\n",
    "### plot\n",
    "fig = plt.figure(figsize=(10, 6))\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "for k, run_dict in runs_to_compare.items():\n",
    "    if run_dict[\"history\"][ckpt_idx] is None or to_plot not in run_dict[\"history\"][ckpt_idx]:\n",
    "        print(f\"Skipping {k}...\")\n",
    "        continue\n",
    "    if conv_win is not None and (run_dict[\"history\"][ckpt_idx] is not None and np.nan not in run_dict[\"history\"][ckpt_idx]):\n",
    "        vals_to_plot = np.convolve(run_dict[\"history\"][ckpt_idx][to_plot], np.ones(conv_win) / conv_win, mode=\"valid\")\n",
    "    else:\n",
    "        vals_to_plot = run_dict[\"history\"][ckpt_idx][to_plot]\n",
    "    ax.plot(\n",
    "        [t for t in range(len(vals_to_plot)) if vals_to_plot[t] is not np.nan],\n",
    "        [v for v in vals_to_plot if v is not np.nan],\n",
    "        label=k,\n",
    "        linewidth=3,\n",
    "    )\n",
    "\n",
    "if to_plot == \"train_loss\":\n",
    "    ax.set_title(\"Training log SSIM loss\", fontsize=16, pad=20)\n",
    "elif to_plot == \"val_loss\":\n",
    "    ax.set_title(\"Validation log SSIM loss\", fontsize=16, pad=20)\n",
    "else:\n",
    "    raise ValueError(f\"Unknown loss type: {to_plot}\")\n",
    "\n",
    "ax.set_xlabel(\"Epoch\", fontsize=15, labelpad=20)\n",
    "ax.set_ylabel(\"Log SSIM loss\", fontsize=15, labelpad=20)\n",
    "# ax.set_ylim(1.25, None)\n",
    "# ax.set_ylim(1.3, 1.75)\n",
    "# ax.set_xlim(0, 80)\n",
    "ax.legend(\n",
    "    loc=\"upper right\",\n",
    "    # loc=\"upper center\",\n",
    "    # loc=\"lower left\",\n",
    "    # loc=\"lower center\",\n",
    "    fontsize=14,\n",
    "    frameon=False,\n",
    "    # bbox_to_anchor=(1.16, 1),\n",
    "    bbox_transform=ax.transAxes,\n",
    "    # title=\"\",\n",
    "    title_fontsize=15,\n",
    "    ncol=1,\n",
    ")\n",
    "# increase width of legend lines\n",
    "leg = ax.get_legend()\n",
    "for legobj in leg.legendHandles:\n",
    "    legobj.set_linewidth(4.0)\n",
    "\n",
    "\n",
    "# set larger font for x and y ticks\n",
    "ax.tick_params(axis=\"both\", which=\"major\", labelsize=14)\n",
    "\n",
    "# remove top and right spines\n",
    "ax.spines[\"top\"].set_visible(False)\n",
    "ax.spines[\"right\"].set_visible(False)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def autolabel(rects):\n",
    "    \"\"\"Attach a text label above each bar in *rects*, displaying its height.\n",
    "    https://matplotlib.org/3.1.1/gallery/lines_bars_and_markers/barchart.html\n",
    "    \"\"\"\n",
    "    for rect in rects:\n",
    "        height = rect.get_height()\n",
    "        ax.annotate(\n",
    "            f\"{height:.3f}\",\n",
    "            xy=(rect.get_x() + rect.get_width() / 2, height),\n",
    "            xytext=(0, 10),  # 3 points vertical offset\n",
    "            textcoords=\"offset points\",\n",
    "            ha='center', va='bottom',\n",
    "            fontsize=14,\n",
    "            rotation=90,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### plot comparison of metrics\n",
    "losses_to_plot = [\n",
    "    \"SSIM Loss\",\n",
    "    # \"Log SSIM Loss\",\n",
    "    # \"MultiSSIM Loss\",\n",
    "    # \"Log MultiSSIM Loss\",\n",
    "    \"MSE\",\n",
    "    \"MAE\",\n",
    "    \"FFL\",\n",
    "    \"Perceptual Loss (VGG16)\",\n",
    "    # \"Perceptual Loss (Encoder)\",\n",
    "]\n",
    "colors = [\n",
    "    \"#1f77b4\",\n",
    "    \"#ff7f0e\",\n",
    "    \"#2ca02c\",\n",
    "    \"#d62728\",\n",
    "    \"#9467bd\",\n",
    "    \"#8c564b\",\n",
    "    \"#e377c2\",\n",
    "    \"#7f7f7f\",\n",
    "    \"#bcbd22\",\n",
    "]\n",
    "bar_width = 0.7\n",
    "plot_recons = False\n",
    "\n",
    "### plot\n",
    "for run_idx in range(len(runs_to_compare[k][\"test_losses\"])):\n",
    "    ### bar plot of test losses\n",
    "    fig = plt.figure(figsize=(16, 6))\n",
    "    ax = fig.add_subplot(111)\n",
    "    print(run_dict[\"ckpt_paths\"][run_idx])\n",
    "\n",
    "    ### grouped bar plot\n",
    "    for i, (k, run_dict) in enumerate(runs_to_compare.items()):\n",
    "        for j, loss in enumerate(losses_to_plot):\n",
    "            rects = ax.bar(\n",
    "                i - bar_width / len(losses_to_plot) + j * bar_width / len(losses_to_plot),\n",
    "                run_dict[\"test_losses\"][run_idx][loss][\"total\"],\n",
    "                width=bar_width / len(losses_to_plot),\n",
    "                color=colors[j],\n",
    "            )\n",
    "            autolabel(rects)\n",
    "\n",
    "    ### add legend with color explanation\n",
    "    from matplotlib import patches as mpatches\n",
    "    ax.legend(\n",
    "        handles=[\n",
    "            mpatches.Patch(color=colors[i], label=loss)\n",
    "            for i, loss in enumerate(losses_to_plot)\n",
    "        ],\n",
    "        loc=\"upper center\",\n",
    "        bbox_to_anchor=(0.5, 1.28),\n",
    "        ncol=len(losses_to_plot),\n",
    "        fontsize=14,\n",
    "        frameon=False,\n",
    "    )\n",
    "\n",
    "    ax.set_title(\n",
    "        \"Test Losses\",\n",
    "        fontsize=18,\n",
    "        pad=90,\n",
    "    )\n",
    "    ax.set_xticks(range(len(runs_to_compare)))\n",
    "    ax.set_xticklabels(runs_to_compare.keys())\n",
    "    ### with rotatation of the xtick labels\n",
    "    ax.set_xticklabels(\n",
    "        [k for k in runs_to_compare.keys()],\n",
    "        rotation=15,\n",
    "        ha=\"right\",\n",
    "    )\n",
    "    ax.tick_params(axis=\"both\", which=\"major\", labelsize=14)\n",
    "    ax.set_xlabel(\"Decoder\", fontsize=14, labelpad=20)\n",
    "    ax.set_ylabel(\"Loss\", fontsize=14, labelpad=20)\n",
    "    ax.set_ylim(0, None)\n",
    "\n",
    "    # remove top and right spines\n",
    "    ax.spines[\"top\"].set_visible(False)\n",
    "    ax.spines[\"right\"].set_visible(False)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    ### plot reconstructions\n",
    "    # if plot_recons:\n",
    "    #     for _k in runs_to_compare.keys():\n",
    "    #         print(_k)\n",
    "    #         plot_comparison(\n",
    "    #             stim,\n",
    "    #             runs_to_compare[_k][\"stim_pred_best\"][run_idx],\n",
    "    #             pred_title=f\"Reconstructed ({_k})\",\n",
    "    #         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### plot reconstructions\n",
    "def dict_to_str(d):\n",
    "    return \", \".join([f\"{k}: {v:.3f}\" for k, v in d.items()])\n",
    "for k in runs_to_compare.keys():\n",
    "    for run_idx in range(len(runs_to_compare[k][\"stim_pred_best\"])):\n",
    "        print(k, \"\\n\", run_dict[\"ckpt_paths\"][run_idx])\n",
    "        stim_pred = runs_to_compare[k][\"stim_pred_best\"][run_idx]\n",
    "        recon_losses = dict()\n",
    "        for loss_fn_name, loss_fn in loss_fns.items():\n",
    "            recon_losses[loss_fn_name] = loss_fn(\n",
    "                stim_pred[:8].to(config[\"device\"]), stim[:8].to(config[\"device\"]), data_key=sample_data_key, phase=\"val\"\n",
    "            ).item() / stim_pred[:8].shape[0]\n",
    "            if not (\n",
    "                \"VGG\" in loss_fn_name \\\n",
    "                or \"FFL\" in loss_fn_name \\\n",
    "                or \"Log\" in loss_fn_name \\\n",
    "                or loss_fn_name == \"MSE\" \\\n",
    "                or loss_fn_name == \"MAE\"\n",
    "            ):\n",
    "                del recon_losses[loss_fn_name]\n",
    "        print(dict_to_str(recon_losses))\n",
    "        fig = plot_comparison(\n",
    "            target=crop(stim[:8], config[\"crop_win\"]).cpu(),\n",
    "            pred=crop(stim_pred[:8], config[\"crop_win\"]).cpu(),\n",
    "        )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
