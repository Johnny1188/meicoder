{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from copy import deepcopy\n",
    "import dill\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "import lovely_tensors as lt\n",
    "import wandb\n",
    "from nnfabrik.builder import get_data\n",
    "\n",
    "import csng\n",
    "from csng.CNN_Decoder import CNN_Decoder\n",
    "from csng.utils import crop, plot_comparison, standardize, normalize, get_mean_and_std, count_parameters, plot_losses\n",
    "from csng.losses import SSIMLoss, MSELossWithCrop, Loss\n",
    "from csng.data import MixedBatchLoader\n",
    "from csng.readins import (\n",
    "    MultiReadIn,\n",
    "    HypernetReadIn,\n",
    "    ConvReadIn,\n",
    "    AttentionReadIn,\n",
    "    FCReadIn,\n",
    "    AutoEncoderReadIn,\n",
    "    Conv1dReadIn,\n",
    "    LocalizedFCReadIn,\n",
    ")\n",
    "\n",
    "from data_utils import (\n",
    "    get_mouse_v1_data,\n",
    "    append_syn_dataloaders,\n",
    "    append_data_aug_dataloaders,\n",
    "    RespGaussianNoise,\n",
    ")\n",
    "\n",
    "lt.monkey_patch()\n",
    "\n",
    "DATA_PATH = os.path.join(os.environ[\"DATA_PATH\"], \"mouse_v1_sensorium22\")\n",
    "print(f\"{DATA_PATH=}\")\n",
    "\n",
    "%env \"WANDB_NOTEBOOK_NAME\" \"cnn_decoder.ipynb\"\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"data\": {\n",
    "        \"mixing_strategy\": \"parallel_min\", # needed only with multiple base dataloaders\n",
    "    },\n",
    "    \"device\": \"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    "    \"seed\": 0,\n",
    "    # \"crop_win\": None,\n",
    "    # \"crop_win\": (slice(7, 29), slice(15, 51)),\n",
    "    \"crop_win\": (22, 36),\n",
    "    # \"wandb\": None,\n",
    "    \"wandb\": {\n",
    "        \"project\": \"CSNG\",\n",
    "        \"group\": \"sensorium_2022\",\n",
    "    },\n",
    "}\n",
    "print(f\"... Running on {config['device']} ...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(config[\"seed\"])\n",
    "torch.manual_seed(config[\"seed\"])\n",
    "random.seed(config[\"seed\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloaders = dict()\n",
    "config[\"data\"][\"syn_dataset_config\"] = None\n",
    "config[\"data\"][\"data_augmentation\"] = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mouse V1 dataset (Sensorium 2022)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### prep data config\n",
    "filenames = [ # from https://gin.g-node.org/cajal/Sensorium2022/src/master\n",
    "    # \"static26872-17-20-GrayImageNet-94c6ff995dac583098847cfecd43e7b6.zip\", # mouse 1\n",
    "    # \"static27204-5-13-GrayImageNet-94c6ff995dac583098847cfecd43e7b6.zip\", # sensorium+ (mouse 2)\n",
    "    \"static21067-10-18-GrayImageNet-94c6ff995dac583098847cfecd43e7b6.zip\", # pretraining (mouse 3)\n",
    "    # \"static22846-10-16-GrayImageNet-94c6ff995dac583098847cfecd43e7b6.zip\", # pretraining (mouse 4)\n",
    "    # \"static23343-5-17-GrayImageNet-94c6ff995dac583098847cfecd43e7b6.zip\", # pretraining (mouse 5)\n",
    "    # \"static23656-14-22-GrayImageNet-94c6ff995dac583098847cfecd43e7b6.zip\", # pretraining (mouse 6)\n",
    "    # \"static23964-4-22-GrayImageNet-94c6ff995dac583098847cfecd43e7b6.zip\", # pretraining (mouse 7)\n",
    "]\n",
    "for f_idx, f_name in enumerate(filenames):\n",
    "    filenames[f_idx] = os.path.join(DATA_PATH, f_name)\n",
    "\n",
    "config[\"data\"].update({\n",
    "    \"paths\": filenames,\n",
    "    \"dataset_fn\": \"sensorium.datasets.static_loaders\",\n",
    "    \"dataset_config\": {\n",
    "        \"paths\": filenames,\n",
    "        \"normalize\": True,\n",
    "        \"scale\": 0.25, # 256x144 -> 64x36\n",
    "        \"include_behavior\": False,\n",
    "        \"add_behavior_as_channels\": False,\n",
    "        \"include_eye_position\": True,\n",
    "        \"exclude\": None,\n",
    "        \"file_tree\": True,\n",
    "        \"cuda\": False,\n",
    "        \"batch_size\": 8,\n",
    "        # \"batch_size\": 7,\n",
    "        \"seed\": config[\"seed\"],\n",
    "        \"use_cache\": False,\n",
    "    },\n",
    "    \"normalize_neuron_coords\": True,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### get dataloaders and cell coordinates\n",
    "dataloaders, neuron_coords = get_mouse_v1_data(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### show data\n",
    "sample_data_key = dataloaders[\"mouse_v1\"][\"val\"].data_keys[0]\n",
    "datapoint = next(iter(dataloaders[\"mouse_v1\"][\"val\"].dataloaders[0]))\n",
    "stim, resp = datapoint.images, datapoint.responses\n",
    "pupil_center = datapoint.pupil_center\n",
    "print(\n",
    "    f\"Training dataset:\\t {sum(len(dl) * config['data']['dataset_config']['batch_size'] for dl in dataloaders['mouse_v1']['train'].dataloaders)} samples\"\n",
    "    f\"\\nValidation dataset:\\t {sum(len(dl) * config['data']['dataset_config']['batch_size'] for dl in dataloaders['mouse_v1']['val'].dataloaders)} samples\"\n",
    "    f\"\\nTest dataset:\\t\\t {sum(len(dl) * config['data']['dataset_config']['batch_size'] for dl in dataloaders['mouse_v1']['test'].dataloaders)} samples\"\n",
    "    f\"\\nTest (no resp) dataset:\\t {sum(len(dl) * config['data']['dataset_config']['batch_size'] for dl in dataloaders['mouse_v1']['test_no_resp'].dataloaders)} samples\"\n",
    "\n",
    "    \"\\n\\nstimuli:\"\n",
    "    f\"\\n  {stim.shape}\"\n",
    "    f\"\\n  min={stim.min().item():.3f}  max={stim.max().item():.3f}\"\n",
    "    f\"\\n  mean={stim.mean().item():.3f}  std={stim.std().item():.3f}\"\n",
    "    \"\\nresponses:\"\n",
    "    f\"\\n  {resp.shape}\"\n",
    "    f\"\\n  min={resp.min().item():.3f}  max={resp.max().item():.3f}\"\n",
    "    f\"\\n  mean={resp.mean().item():.3f}  std={resp.std().item():.3f}\"\n",
    "    \"\\nneuronal coordinates:\"\n",
    "    f\"\\n  {neuron_coords[sample_data_key].shape}\"\n",
    "    f\"\\n  min={neuron_coords[sample_data_key].min():.3f}  max={neuron_coords[sample_data_key].max():.3f}\"\n",
    "    f\"\\n  mean={neuron_coords[sample_data_key].mean():.3f}  std={neuron_coords[sample_data_key].std():.3f}\"\n",
    ")\n",
    "\n",
    "### plot sample data\n",
    "sample_idx = 0\n",
    "\n",
    "fig = plt.figure(figsize=(16, 6))\n",
    "ax = fig.add_subplot(131)\n",
    "ax.imshow(stim[sample_idx].squeeze().unsqueeze(-1).cpu(), cmap=\"gray\")\n",
    "\n",
    "ax = fig.add_subplot(132)\n",
    "ax.imshow(crop(stim[sample_idx].cpu(), config[\"crop_win\"]).squeeze().unsqueeze(-1), cmap=\"gray\")\n",
    "\n",
    "### bin the neuronal responses based on their neuron coordinates and sum within each bin -> 2D grid of vals\n",
    "coords = neuron_coords[sample_data_key]\n",
    "H, W = stim.shape[-2:] # the size of the grid\n",
    "n_x_bins, n_y_bins = 32, 18 # number of bins in each dimension\n",
    "min_x, max_x, min_y, max_y = coords[:,0].min().item(), coords[:,0].max().item(), coords[:,1].min().item(), coords[:,1].max().item()\n",
    "x_bins = torch.linspace(min_x, max_x, n_x_bins + 1)\n",
    "y_bins = torch.linspace(min_y, max_y, n_y_bins + 1)\n",
    "binned_resp = torch.zeros(n_y_bins, n_x_bins)\n",
    "for i in range(n_x_bins):\n",
    "    for j in range(n_y_bins):\n",
    "        ### mask of the neurons in the bin\n",
    "        mask = (x_bins[i] <= coords[:,0]) &\\\n",
    "               (coords[:,0] < x_bins[i + 1]) &\\\n",
    "               (y_bins[j] <= coords[:,1]) &\\\n",
    "               (coords[:,1] < y_bins[j + 1])\n",
    "        binned_resp[j,i] = resp[sample_idx, mask.cpu()].sum(0)\n",
    "ax = fig.add_subplot(133)\n",
    "ax.imshow(binned_resp.squeeze().cpu(), cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config[\"data\"][\"data_augmentation\"] = {\n",
    "    \"data_transforms\": [RespGaussianNoise(0.1)],\n",
    "    \"append_data_parts\": [\"train\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloaders = append_data_aug_dataloaders(\n",
    "    dataloaders=dataloaders,\n",
    "    config=config[\"data\"][\"data_augmentation\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Synthetic dataset (different image stimuli -> encoder -> responses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### append synthetic data\n",
    "config[\"data\"][\"syn_dataset_config\"] = {\n",
    "    \"data_keys\": [\n",
    "        # \"21067-10-18\",\n",
    "        # \"22846-10-16\",\n",
    "        # \"23343-5-17\",\n",
    "        # \"23656-14-22\",\n",
    "        # \"23964-4-22\",\n",
    "    ],\n",
    "    \"batch_size\": 3,\n",
    "    \"append_data_parts\": [\"train\"],\n",
    "    \"data_key_prefix\": \"syn\",\n",
    "}\n",
    "\n",
    "dataloaders = append_syn_dataloaders(dataloaders, config=config[\"data\"][\"syn_dataset_config\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### show data\n",
    "syn_stim, syn_resp, syn_pupil_center = next(iter(dataloaders[\"mouse_v1\"][\"train\"].dataloaders[-1]))\n",
    "print(\n",
    "    f\"Training dataset:\\t {sum(len(dl) * config['data']['dataset_config']['batch_size'] for dl in dataloaders['mouse_v1']['train'].dataloaders)} samples\"\n",
    "    f\"\\nValidation dataset:\\t {sum(len(dl) * config['data']['dataset_config']['batch_size'] for dl in dataloaders['mouse_v1']['val'].dataloaders)} samples\"\n",
    "    f\"\\nTest dataset:\\t\\t {sum(len(dl) * config['data']['dataset_config']['batch_size'] for dl in dataloaders['mouse_v1']['test'].dataloaders)} samples\"\n",
    "    f\"\\nTest (no resp) dataset:\\t {sum(len(dl) * config['data']['dataset_config']['batch_size'] for dl in dataloaders['mouse_v1']['test_no_resp'].dataloaders)} samples\"\n",
    "\n",
    "    \"\\n\\nstimuli:\"\n",
    "    f\"\\n  {syn_stim.shape}\"\n",
    "    f\"\\n  min={syn_stim.min().item():.3f}  max={syn_stim.max().item():.3f}\"\n",
    "    f\"\\n  mean={syn_stim.mean().item():.3f}  std={syn_stim.std().item():.3f}\"\n",
    "    \"\\nresponses:\"\n",
    "    f\"\\n  {syn_resp.shape}\"\n",
    "    f\"\\n  min={syn_resp.min().item():.3f}  max={syn_resp.max().item():.3f}\"\n",
    "    f\"\\n  mean={syn_resp.mean().item():.3f}  std={syn_resp.std().item():.3f}\"\n",
    "    \"\\nNeuron coordinates:\"\n",
    "    f\"\\n  {neuron_coords[sample_data_key].shape}\"\n",
    "    f\"\\n  min={neuron_coords[sample_data_key].min():.3f}  max={neuron_coords[sample_data_key].max():.3f}\"\n",
    "    f\"\\n  mean={neuron_coords[sample_data_key].mean():.3f}  std={neuron_coords[sample_data_key].std():.3f}\"\n",
    "    \"\\nPupil center:\"\n",
    "    f\"\\n  {syn_pupil_center.shape}\"\n",
    "    f\"\\n  min={syn_pupil_center.min().item():.3f}  max={syn_pupil_center.max().item():.3f}\"\n",
    "    f\"\\n  mean={syn_pupil_center.mean().item():.3f}  std={syn_pupil_center.std().item():.3f}\"\n",
    ")\n",
    "\n",
    "fig = plt.figure(figsize=(16, 6))\n",
    "ax = fig.add_subplot(121)\n",
    "ax.imshow(syn_stim[0].squeeze().unsqueeze(-1).cpu(), cmap=\"gray\")\n",
    "\n",
    "ax = fig.add_subplot(122)\n",
    "reshape_to = None\n",
    "for i in range(30, 150):\n",
    "    if syn_resp.shape[-1] % i == 0:\n",
    "        reshape_to = (i, syn_resp.shape[-1] // i)\n",
    "        break\n",
    "if reshape_to != None:\n",
    "    ax.imshow(syn_resp[0].view(reshape_to).squeeze(0).unsqueeze(-1).cpu(), cmap=\"gray\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### load encoder\n",
    "print(\"Loading encoder...\")\n",
    "\n",
    "from lurz2020.models.models import se2d_fullgaussian2d\n",
    "\n",
    "### load pretrained encoder ckpt\n",
    "encoder_ckpt = torch.load(\n",
    "    os.path.join(DATA_PATH, \"models\", \"encoder.pt\"),\n",
    "    map_location=config[\"device\"],\n",
    "    pickle_module=dill,\n",
    ")\n",
    "\n",
    "### get temporary dataloaders for the encoder\n",
    "_dataloaders = get_data(\n",
    "    encoder_ckpt[\"config\"][\"data\"][\"dataset_fn\"],\n",
    "    encoder_ckpt[\"config\"][\"data\"][\"dataset_config\"]\n",
    ")\n",
    "\n",
    "### init encoder\n",
    "encoder = se2d_fullgaussian2d(\n",
    "    **encoder_ckpt[\"config\"][\"encoder\"][\"model_config\"],\n",
    "    dataloaders=_dataloaders,\n",
    "    seed=encoder_ckpt[\"config\"][\"seed\"],\n",
    ").float()\n",
    "encoder.load_state_dict(encoder_ckpt[\"encoder_state\"], strict=True)\n",
    "encoder.to(config[\"device\"])\n",
    "encoder.eval()\n",
    "del _dataloaders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, dataloader, opter, loss_fn, config, verbose=True):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    n_batches = len(dataloader)\n",
    "\n",
    "    ### run\n",
    "    for batch_idx, b in enumerate(dataloader):\n",
    "        opter.zero_grad()\n",
    "        loss = 0\n",
    "\n",
    "        ### combine from all data keys\n",
    "        for data_key, stim, resp, neuron_coords, pupil_center in b:\n",
    "            ### get loss\n",
    "            stim_pred = model(\n",
    "                resp,\n",
    "                data_key=data_key,\n",
    "                neuron_coords=neuron_coords,\n",
    "                pupil_center=pupil_center\n",
    "            )\n",
    "            loss += loss_fn(stim_pred, stim, data_key=data_key, phase=\"train\", neuron_coords=neuron_coords, pupil_center=pupil_center)\n",
    "            model.set_additional_loss(\n",
    "                inp={\n",
    "                    \"resp\": resp,\n",
    "                    \"stim\": stim,\n",
    "                    \"neuron_coords\": neuron_coords,\n",
    "                    \"pupil_center\": pupil_center,\n",
    "                    \"data_key\": data_key,\n",
    "                }, out={\n",
    "                    \"stim_pred\": stim_pred,\n",
    "                },\n",
    "            )\n",
    "            loss += model.get_additional_loss(data_key=data_key)\n",
    "\n",
    "        ### update\n",
    "        loss /= len(b)\n",
    "        loss.backward()\n",
    "        opter.step()\n",
    "\n",
    "        ### log\n",
    "        train_loss += loss.item()\n",
    "        if verbose and batch_idx % 100 == 0:\n",
    "            print(f\"Training progress: [{batch_idx}/{n_batches} ({100. * batch_idx / n_batches:.0f}%)]\"\n",
    "                  f\"  Loss: {loss.item():.6f}\")\n",
    "\n",
    "    train_loss /= n_batches\n",
    "    return train_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def val(model, dataloader, loss_fn, config, only_data_keys=None):\n",
    "    model.eval()\n",
    "    val_losses = {\"total\": 0}\n",
    "    denom_data_keys = {}\n",
    "    with torch.no_grad():\n",
    "        for b in dataloader:\n",
    "            ### combine from all data keys\n",
    "            for data_key, stim, resp, neuron_coords, pupil_center in b:\n",
    "                if only_data_keys is not None and data_key not in only_data_keys:\n",
    "                    continue\n",
    "                stim_pred = model(\n",
    "                    resp,\n",
    "                    data_key=data_key,\n",
    "                    neuron_coords=neuron_coords,\n",
    "                    pupil_center=pupil_center,\n",
    "                )\n",
    "                loss = loss_fn(stim_pred, stim, data_key=data_key, phase=\"val\").item()\n",
    "                val_losses[data_key] = loss if data_key not in val_losses else val_losses[data_key] + loss\n",
    "                val_losses[\"total\"] += loss / len(b)\n",
    "                denom_data_keys[data_key] = denom_data_keys[data_key] + 1 if data_key in denom_data_keys else 1\n",
    "\n",
    "    val_losses[\"total\"] /= len(dataloader)\n",
    "    for k in denom_data_keys:\n",
    "        val_losses[k] /= denom_data_keys[k]\n",
    "    return val_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config[\"decoder\"] = {\n",
    "    \"model\": {\n",
    "        \"readins_config\": [\n",
    "            {\n",
    "                \"data_key\": data_key,\n",
    "                \"in_shape\": n_coords.shape[-2],\n",
    "                \"decoding_objective_config\": None,\n",
    "                # \"decoding_objective_config\": {\n",
    "                #     \"decoder_cls\": FCReadIn,\n",
    "                #     \"decoder_config\": {\n",
    "                #         \"in_shape\": 68*9*16,\n",
    "                #         \"layers_config\": [(\"fc\", 264), (\"fc\", d.n_neurons),],\n",
    "                #         \"act_fn\": nn.LeakyReLU,\n",
    "                #         \"out_act_fn\": nn.Identity,\n",
    "                #         \"dropout\": 0.0,\n",
    "                #         \"batch_norm\": False,\n",
    "                #     },\n",
    "                #     \"loss_fn\": nn.MSELoss(),\n",
    "                # },\n",
    "                \"layers\": [\n",
    "                    # (\"fc\", 432),\n",
    "                    # (\"unflatten\", 1, (3, 9, 16)),\n",
    "\n",
    "                    # (LocalizedFCReadIn, {\n",
    "                    #     \"in_shape\": d.n_neurons,\n",
    "                    #     \"layers\": [\n",
    "                    #         {\"n_bins\": 20, \"reduce_by\": 3},\n",
    "                    #         {\"n_bins\": 12, \"reduce_by\": 2},\n",
    "                    #         {\"n_bins\": 7, \"reduce_by\": 2},\n",
    "                    #         {\"n_bins\": 2, \"reduce_by\": 2},\n",
    "                    #     ],\n",
    "                    #     \"out_config\": {\n",
    "                    #         \"shape\": (3, 9, 16),\n",
    "                    #         \"method\": \"linear\",\n",
    "                    #     },\n",
    "                    #     \"act_fn\": nn.LeakyReLU,\n",
    "                    #     \"out_act_fn\": nn.Identity,\n",
    "                    #     \"dropout\": 0.15,\n",
    "                    #     \"batch_norm\": True,\n",
    "                    # }),\n",
    "\n",
    "                    # (AttentionReadIn, {\n",
    "                    #     \"in_shape\": d.n_neurons,\n",
    "                    #     \"shift_coords\": True,\n",
    "                    #     \"shifter_net_layers\": [\n",
    "                    #         (\"fc\", 10),\n",
    "                    #         (\"fc\", 10),\n",
    "                    #         (\"fc\", 2),\n",
    "                    #     ],\n",
    "                    #     \"shifter_net_act_fn\": nn.LeakyReLU,\n",
    "                    #     \"shifter_net_out_act_fn\": nn.Tanh,\n",
    "                    #     \"attn_config\": {\n",
    "                    #         \"layers\": 1,\n",
    "                    #         \"token_neurons\": 20,\n",
    "                    #         \"dim_head\": 256,\n",
    "                    #         \"dropout\": 0.1,\n",
    "                    #         \"attn_num_heads\": 1,\n",
    "                    #     },\n",
    "                    #     \"attn_interleave_config\": {\n",
    "                    #         \"layers\": [\n",
    "                    #             (\"fc\", 512),\n",
    "                    #             (\"act_fn\", nn.ReLU),\n",
    "                    #             (\"dropout\", 0.15),\n",
    "                    #             (\"fc\", 256)\n",
    "                    #         ],\n",
    "                    #         \"after_last\": True,\n",
    "                    #     },\n",
    "                    #     \"neuron_embed_dim\": 16,\n",
    "                    #     \"conv_out_config\": {\n",
    "                    #         \"out_channels\": 64,\n",
    "                    #         \"kernel_size\": 5,\n",
    "                    #         \"stride\": 1,\n",
    "                    #         \"padding\": 2,\n",
    "                    #         \"bias\": False,\n",
    "                    #         \"batch_norm\": True,\n",
    "                    #         \"act_fn\": nn.LeakyReLU,\n",
    "                    #     },\n",
    "                    # }),\n",
    "\n",
    "                    (ConvReadIn, {\n",
    "                        \"shift_coords\": True,\n",
    "                        \"learn_grid\": True,\n",
    "                        \"grid_l1_reg\": 8e-3,\n",
    "                        \"in_channels_group_size\": 1,\n",
    "                        \"pointwise_conv_config\": {\n",
    "                            \"in_channels\": n_coords.shape[-2],\n",
    "                            \"out_channels\": 144,\n",
    "                            \"act_fn\": nn.LeakyReLU,\n",
    "                            \"bias\": False,\n",
    "                            \"batch_norm\": True,\n",
    "                        },\n",
    "                        \"gauss_blur\": False,\n",
    "                        \"gauss_blur_kernel_size\": 7,\n",
    "                        \"gauss_blur_sigma\": \"fixed\", # \"fixed\", \"single\", \"per_neuron\"\n",
    "                        # \"gauss_blur_sigma\": \"per_neuron\", # \"fixed\", \"single\", \"per_neuron\"\n",
    "                        \"gauss_blur_sigma_init\": 1.5,\n",
    "                        \"neuron_emb_dim\": None,\n",
    "                    }),\n",
    "\n",
    "                    # (FCReadIn, {\n",
    "                    #     \"in_shape\": d.n_neurons,\n",
    "                    #     \"layers_config\": [\n",
    "                    #         (\"fc\", 432),\n",
    "                    #         (\"unflatten\", 1, (3, 9, 16)),\n",
    "                    #     ],\n",
    "                    #     \"act_fn\": nn.LeakyReLU,\n",
    "                    #     \"out_act_fn\": nn.Identity,\n",
    "                    #     \"batch_norm\": True,\n",
    "                    #     \"dropout\": 0.45,\n",
    "                    #     \"out_channels\": 3,\n",
    "                    # }),\n",
    "\n",
    "                    # (AutoEncoderReadIn, {\n",
    "                    #     \"loss_mul\": 1,\n",
    "                    #     \"encoder_config\": {\n",
    "                    #         \"in_shape\": d.n_neurons,\n",
    "                    #         \"layers_config\": [\n",
    "                    #             (\"fc\", 288),\n",
    "                    #             (\"unflatten\", 1, (2, 9, 16)),\n",
    "                    #         ],\n",
    "                    #         \"act_fn\": nn.LeakyReLU,\n",
    "                    #         \"out_act_fn\": nn.Identity,\n",
    "                    #         \"batch_norm\": True,\n",
    "                    #         \"dropout\": 0.2,\n",
    "                    #         \"out_channels\": 2,\n",
    "                    #     },\n",
    "                    #     \"decoder_config\": {\n",
    "                    #         \"layers_config\": [\n",
    "                    #             (\"fc\", 312),\n",
    "                    #             (\"fc\", d.n_neurons),\n",
    "                    #         ],\n",
    "                    #         \"act_fn\": nn.LeakyReLU,\n",
    "                    #         \"out_act_fn\": nn.Identity,\n",
    "                    #         \"batch_norm\": False,\n",
    "                    #         \"dropout\": 0.1,\n",
    "                    #     },\n",
    "                    # }),\n",
    "\n",
    "                    # (Conv1dReadIn, {\n",
    "                    #     # \"in_shape\": d.n_neurons,\n",
    "                    #     \"in_shape\": 1,\n",
    "                    #     \"out_channels\": 2,\n",
    "                    #     \"layers_config\": [\n",
    "                    #         (\"conv1d\", 64, 7, 3, 3),\n",
    "                    #         (\"conv1d\", 32, 7, 3, 3),\n",
    "                    #         (\"conv1d\", 16, 5, 2, 2),\n",
    "                    #         (\"conv1d\", 8, 4, 2, 1),\n",
    "                    #         (\"flatten\", 1, -1, 1632),\n",
    "                    #         (\"fc\", 288),\n",
    "                    #         (\"unflatten\", 1, (2, 9, 16)),\n",
    "                    #     ],\n",
    "                    #     \"act_fn\": nn.ReLU,\n",
    "                    #     \"out_act_fn\": nn.Identity,\n",
    "                    #     \"batch_norm\": True,\n",
    "                    #     \"dropout\": 0.15,\n",
    "                    # }),\n",
    "\n",
    "                #     (HypernetReadIn, {\n",
    "                #         \"n_neurons\": d.n_neurons,\n",
    "                #         \"hypernet_layers\": [\n",
    "                #             # (\"fc\", 40),\n",
    "                #             (\"fc\", 64),\n",
    "                #             (\"fc\", 64),\n",
    "                #             (\"fc\", 1152),\n",
    "                #         ],\n",
    "                #         \"hypernet_act_fn\": nn.LeakyReLU,\n",
    "                #         # \"hypernet_act_fn\": nn.Tanh,\n",
    "                #         \"hypernet_out_act_fn\": nn.Identity,\n",
    "                #         \"hypernet_dropout\": 0.,\n",
    "                #         \"hypernet_batch_norm\": False,\n",
    "                #         \"hypernet_init\": \"normal\",\n",
    "                #         \"hypernet_init_kwargs\": {\n",
    "                #             \"mean\": 0,\n",
    "                #             \"std\": 1/(d.n_neurons*1152),\n",
    "                #         },\n",
    "                #         \"hypernet_neuron_embed_dim\": 32,\n",
    "                #         \"target_in_shape\": d.n_neurons,\n",
    "                #         \"target_layers\": [\n",
    "                #             (\"fc\", 1152),\n",
    "                #             (\"unflatten\", 1, (8, 9, 16)),\n",
    "                #         ],\n",
    "                #         # \"target_act_fn\": nn.LeakyReLU,\n",
    "                #         \"target_act_fn\": nn.Identity,\n",
    "                #         \"target_out_act_fn\": nn.Identity,\n",
    "                #         \"target_dropout\": 0.15,\n",
    "                #         \"target_out_layer_norm\": True,\n",
    "                #         \"shift_coords\": True,\n",
    "                #         \"shifter_net_layers\": [\n",
    "                #             (\"fc\", 10),\n",
    "                #             (\"fc\", 10),\n",
    "                #             (\"fc\", 2),\n",
    "                #         ],\n",
    "                #         \"shifter_net_act_fn\": nn.LeakyReLU,\n",
    "                #         \"shifter_net_out_act_fn\": nn.Tanh,\n",
    "                #     }),\n",
    "                ],\n",
    "            # } for d, data_key in zip(dataloaders[\"mouse_v1\"][\"train\"].datasets, dataloaders[\"mouse_v1\"][\"train\"].data_keys)\n",
    "            } for data_key, n_coords in dataloaders[\"mouse_v1\"][\"train\"].neuron_coords.items()\n",
    "        ],\n",
    "        \"core_cls\": CNN_Decoder,\n",
    "        \"core_config\": {\n",
    "            \"resp_shape\": [144],\n",
    "            \"stim_shape\": list(stim.shape[1:]),\n",
    "            \"layers\": [\n",
    "                ### for conv_readin\n",
    "                # (\"deconv\", 256, 7, 2, 2),\n",
    "                (\"deconv\", 128, 7, 2, 1),\n",
    "                # (\"deconv\", 64, 5, 2, 2),\n",
    "                \n",
    "                # (\"deconv\", 128, 5, 1, 2),\n",
    "                (\"deconv\", 64, 5, 1, 1),\n",
    "\n",
    "                # (\"deconv\", 64, 5, 1, 2),\n",
    "                (\"deconv\", 32, 4, 1, 1),\n",
    "\n",
    "                # (\"deconv\", 64, 4, 1, 1),\n",
    "                # (\"deconv\", 32, 4, 1, 1),\n",
    "\n",
    "                # (\"deconv\", 64, 4, 1, 1),\n",
    "                # (\"deconv\", 32, 3, 1, 1),\n",
    "\n",
    "                (\"deconv\", 1, 3, 1, 0),\n",
    "\n",
    "\n",
    "                ### for attn_readin\n",
    "                # (\"deconv\", 64, 7, 2, 3),\n",
    "                # (\"deconv\", 32, 4, 1, 2),\n",
    "                # (\"deconv\", 1, 3, 1, 0),\n",
    "            ],\n",
    "            \"act_fn\": nn.ReLU,\n",
    "            \"out_act_fn\": nn.Identity,\n",
    "            \"dropout\": 0.3,\n",
    "            \"batch_norm\": True,\n",
    "        },\n",
    "    },\n",
    "    \"opter_cls\": torch.optim.Adam,\n",
    "    \"opter_kwargs\": {\n",
    "        \"lr\": 3e-4,\n",
    "    },\n",
    "    \"loss\": {\n",
    "        # \"loss_fn\": MSELossWithCrop(window=config[\"crop_win\"], standardize=False),\n",
    "        \"loss_fn\": SSIMLoss(\n",
    "            window=config[\"crop_win\"],\n",
    "            log_loss=True,\n",
    "            inp_normalized=True,\n",
    "            inp_standardized=False,\n",
    "        ),\n",
    "        \"l1_reg_mul\": 0,\n",
    "        \"l2_reg_mul\": 1e-5,\n",
    "        \"con_reg_mul\": 0,\n",
    "        # \"con_reg_mul\": 1,\n",
    "        \"con_reg_loss_fn\": SSIMLoss(\n",
    "            window=config[\"crop_win\"],\n",
    "            log_loss=True,\n",
    "            inp_normalized=True,\n",
    "            inp_standardized=False,\n",
    "        ),\n",
    "        \"encoder\": None,\n",
    "        # \"encoder\": encoder,\n",
    "    },\n",
    "    \"n_epochs\": 200,\n",
    "    \"load_ckpt\": None,\n",
    "    # \"load_ckpt\": {\n",
    "    #     # \"load_only_core\": False,\n",
    "    #     \"load_only_core\": True,\n",
    "    #     \"ckpt_path\": os.path.join(\n",
    "    #         DATA_PATH, \"models\", \"cat_v1_pretraining\", \"2024-02-27_19-17-39\", \"decoder.pt\"),\n",
    "    #         # DATA_PATH, \"models\", \"cnn\", \"2023-08-25_09-07-46\", \"ckpt\", \"decoder_40.pt\"),\n",
    "    # },\n",
    "    \"save_run\": True,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### initialize (and load ckpt if needed)\n",
    "if config[\"decoder\"][\"load_ckpt\"] != None:\n",
    "    print(f\"[INFO] Loading checkpoint from {config['decoder']['load_ckpt']['ckpt_path']}...\")\n",
    "    ckpt = torch.load(config[\"decoder\"][\"load_ckpt\"][\"ckpt_path\"], map_location=config[\"device\"], pickle_module=dill)\n",
    "\n",
    "    if config[\"decoder\"][\"load_ckpt\"][\"load_only_core\"]:\n",
    "        print(\"[INFO] Loading only the core of the model (no history, no best ckpt)...\")\n",
    "\n",
    "        ### init decoder (load only the core)\n",
    "        config[\"decoder\"][\"model\"][\"core_cls\"] = ckpt[\"config\"][\"decoder\"][\"model\"][\"core_cls\"]\n",
    "        config[\"decoder\"][\"model\"][\"core_config\"] = ckpt[\"config\"][\"decoder\"][\"model\"][\"core_config\"]\n",
    "        decoder = MultiReadIn(**config[\"decoder\"][\"model\"]).to(config[\"device\"])\n",
    "        decoder.load_state_dict({k:v for k,v in ckpt[\"best\"][\"model\"].items() if \"readin\" not in k}, strict=False)\n",
    "\n",
    "        ### init the rest\n",
    "        opter = config[\"decoder\"][\"opter_cls\"](decoder.parameters(), **config[\"decoder\"][\"opter_kwargs\"])\n",
    "        loss_fn = Loss(model=decoder, config=config[\"decoder\"][\"loss\"])\n",
    "        history = {\"train_loss\": [], \"val_loss\": []}\n",
    "        best = {\"val_loss\": np.inf, \"epoch\": 0, \"model\": None}\n",
    "    else:\n",
    "        print(\"[INFO] Loading the whole model (the latest - not the BEST; with history and best ckpt)...\")\n",
    "        history, config[\"decoder\"][\"model\"], best = ckpt[\"history\"], ckpt[\"config\"][\"decoder\"][\"model\"], ckpt[\"best\"]\n",
    "\n",
    "        decoder = MultiReadIn(**config[\"decoder\"][\"model\"]).to(config[\"device\"])\n",
    "        decoder.load_state_dict(ckpt[\"decoder\"])\n",
    "\n",
    "        opter = config[\"decoder\"][\"opter_cls\"](decoder.parameters(), **config[\"decoder\"][\"opter_kwargs\"])\n",
    "        opter.load_state_dict(ckpt[\"opter\"])\n",
    "        loss_fn = Loss(model=decoder, config=config[\"decoder\"][\"loss\"])\n",
    "else:\n",
    "    print(\"[INFO] Initializing the model from scratch...\")\n",
    "    decoder = MultiReadIn(**config[\"decoder\"][\"model\"]).to(config[\"device\"])\n",
    "    opter = config[\"decoder\"][\"opter_cls\"](decoder.parameters(), **config[\"decoder\"][\"opter_kwargs\"])\n",
    "    loss_fn = Loss(model=decoder, config=config[\"decoder\"][\"loss\"])\n",
    "    \n",
    "    history = {\"train_loss\": [], \"val_loss\": []}\n",
    "    best = {\"val_loss\": np.inf, \"epoch\": 0, \"model\": None}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### print model and fix sizes of stimuli\n",
    "with torch.no_grad():\n",
    "    stim_pred = decoder(resp.to(config[\"device\"]), data_key=sample_data_key, neuron_coords=neuron_coords[sample_data_key], pupil_center=pupil_center.to(config[\"device\"]))\n",
    "    if stim_pred.shape != crop(stim, config[\"crop_win\"]).shape:\n",
    "        print(f\"[WARNING] Stimulus prediction shape {stim_pred.shape} does not match stimulus shape {crop(stim, config['crop_win']).shape}.\")\n",
    "        assert stim_pred.shape[-2] >= crop(stim, config[\"crop_win\"]).shape[-2] \\\n",
    "            and stim_pred.shape[-1] >= crop(stim, config[\"crop_win\"]).shape[-1]\n",
    "        \n",
    "        # ### set crop function\n",
    "        # decoder.crop_stim_fn = lambda x: x[:, :, :crop(stim, config[\"crop_win\"]).shape[-2], :crop(stim, config[\"crop_win\"]).shape[-1]]\n",
    "        # stim_pred = decoder(resp.to(config[\"device\"]), data_key=sample_data_key, neuron_coords=neuron_coords[sample_data_key], pupil_center=pupil_center.to(config[\"device\"]))\n",
    "        # print(f\"[INFO] Stimulus prediction shape cropped to {stim_pred.shape}.\")\n",
    "\n",
    "    print(stim_pred.shape)\n",
    "    del stim_pred\n",
    "\n",
    "print(\n",
    "    f\"Number of parameters:\"\n",
    "    f\"\\n  whole model: {count_parameters(decoder)}\"\n",
    "    f\"\\n  core: {count_parameters(decoder.core)} ({count_parameters(decoder.core) / count_parameters(decoder) * 100:.2f}%)\"\n",
    "    f\"\\n  readins: {count_parameters(decoder.readins)} ({count_parameters(decoder.readins) / count_parameters(decoder) * 100:.2f}%)\"\n",
    "    f\"\\n    ({', '.join([f'{k}: {count_parameters(v)} [{count_parameters(v) / count_parameters(decoder) * 100:.2f}%]' for k, v in decoder.readins.items()])})\"\n",
    ")\n",
    "\n",
    "decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### prepare checkpointing and wandb logging\n",
    "config[\"run_name\"] = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "if config[\"decoder\"][\"save_run\"]:\n",
    "    ### save config\n",
    "    config[\"dir\"] = os.path.join(DATA_PATH, \"models\", \"cnn\", config[\"run_name\"])\n",
    "    os.makedirs(config[\"dir\"], exist_ok=True)\n",
    "    with open(os.path.join(config[\"dir\"], \"config.json\"), \"w\") as f:\n",
    "        json.dump(config, f, indent=4, default=str)\n",
    "    os.makedirs(os.path.join(config[\"dir\"], \"samples\"), exist_ok=True)\n",
    "    os.makedirs(os.path.join(config[\"dir\"], \"ckpt\"), exist_ok=True)\n",
    "    make_sample_path = lambda epoch, prefix: os.path.join(\n",
    "        config[\"dir\"], \"samples\", f\"{prefix}stim_comparison_{epoch}e.png\"\n",
    "    )\n",
    "\n",
    "    print(f\"Run name: {config['run_name']}\\nRun dir: {config['dir']}\")\n",
    "else:\n",
    "    make_sample_path = lambda epoch, prefix: None\n",
    "    print(\"[WARNING] Not saving the run and the config.\")\n",
    "\n",
    "if config[\"wandb\"]:\n",
    "    wdb_run = wandb.init(**config[\"wandb\"], name=config[\"run_name\"], config=config,\n",
    "        tags=[\n",
    "            config[\"decoder\"][\"model\"][\"core_cls\"].__name__,\n",
    "            config[\"decoder\"][\"model\"][\"readins_config\"][0][\"layers\"][0][0].__name__,\n",
    "            # \"contrastive_regularization\",\n",
    "            # \"cat_v1_pretraining\"\n",
    "        ],\n",
    "        notes=None)\n",
    "    wdb_run.watch(decoder)\n",
    "else:\n",
    "    print(\"[WARNING] Not using wandb.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### train\n",
    "s, e = len(history[\"train_loss\"]), config[\"decoder\"][\"n_epochs\"]\n",
    "for epoch in range(s, e):\n",
    "    print(f\"[{epoch + 1}/{e}]\")\n",
    "\n",
    "    ### train and val\n",
    "    dls, neuron_coords = get_mouse_v1_data(config=config)\n",
    "    if \"syn_dataset_config\" in config[\"data\"] and config[\"data\"][\"syn_dataset_config\"] is not None:\n",
    "        dls = append_syn_dataloaders(dls, config=config[\"data\"][\"syn_dataset_config\"]) # append synthetic data\n",
    "    if \"data_augmentation\" in config[\"data\"] and config[\"data\"][\"data_augmentation\"] is not None:\n",
    "        dls = append_data_aug_dataloaders(\n",
    "            dataloaders=dls,\n",
    "            config=config[\"data\"][\"data_augmentation\"],\n",
    "        )\n",
    "    train_dataloader, val_dataloader = dls[\"mouse_v1\"][\"train\"], dls[\"mouse_v1\"][\"val\"]\n",
    "    train_loss = train(\n",
    "        model=decoder,\n",
    "        dataloader=train_dataloader,\n",
    "        opter=opter,\n",
    "        loss_fn=loss_fn,\n",
    "        config=config,\n",
    "    )\n",
    "    val_losses = val(\n",
    "        model=decoder,\n",
    "        dataloader=val_dataloader,\n",
    "        loss_fn=loss_fn,\n",
    "        config=config,\n",
    "    )\n",
    "\n",
    "    ### save best model\n",
    "    if val_losses[\"total\"] < best[\"val_loss\"]:\n",
    "        best[\"val_loss\"] = val_losses[\"total\"]\n",
    "        best[\"epoch\"] = epoch\n",
    "        best[\"model\"] = deepcopy(decoder.state_dict())\n",
    "\n",
    "    ### log\n",
    "    history[\"train_loss\"].append(train_loss)\n",
    "    history[\"val_loss\"].append(val_losses[\"total\"])\n",
    "    if config[\"wandb\"]: wdb_run.log({\"train_loss\": train_loss, \"val_loss\": val_losses[\"total\"]}, commit=False)\n",
    "    print(f\"{train_loss=:.4f}, {val_losses['total']=:.4f}\", end=\"\")\n",
    "    for data_key, loss in val_losses.items():\n",
    "        if data_key != \"total\":\n",
    "            print(f\", {data_key}: {loss:.4f}\", end=\"\")\n",
    "    print(\"\")\n",
    "\n",
    "    ### plot reconstructions\n",
    "    stim_pred = decoder(\n",
    "        resp[:8].to(config[\"device\"]),\n",
    "        data_key=sample_data_key,\n",
    "        neuron_coords=neuron_coords[sample_data_key],\n",
    "        pupil_center=pupil_center[:8].to(config[\"device\"]),\n",
    "    ).detach()\n",
    "    fig = plot_comparison(target=crop(stim[:8], config[\"crop_win\"]).cpu(), pred=crop(stim_pred[:8], config[\"crop_win\"]).cpu(), save_to=make_sample_path(epoch, \"\"))\n",
    "    if config[\"wandb\"]: wdb_run.log({\"val_stim_reconstruction\": fig})\n",
    "\n",
    "    ### plot losses\n",
    "    if epoch % 5 == 0 and epoch > 0:\n",
    "        plot_losses(history=history, epoch=epoch, save_to=os.path.join(config[\"dir\"], f\"losses_{epoch}.png\") if config[\"decoder\"][\"save_run\"] else None)\n",
    "\n",
    "    ### save ckpt\n",
    "    if epoch % 5 == 0 and epoch > 0:\n",
    "        ### ckpt\n",
    "        if config[\"decoder\"][\"save_run\"]:\n",
    "            torch.save({\n",
    "                \"decoder\": decoder.state_dict(),\n",
    "                \"opter\": opter.state_dict(),\n",
    "                \"history\": history,\n",
    "                \"config\": config,\n",
    "                \"best\": best,\n",
    "            }, os.path.join(config[\"dir\"], \"ckpt\", f\"decoder_{epoch}.pt\"), pickle_module=dill)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### final evaluation + logging + saving\n",
    "print(f\"Best val loss: {best['val_loss']:.4f} at epoch {best['epoch']}\")\n",
    "\n",
    "### save final ckpt\n",
    "if config[\"decoder\"][\"save_run\"]:\n",
    "    torch.save({\n",
    "        \"decoder\": decoder.state_dict(),\n",
    "        \"opter\": opter.state_dict(),\n",
    "        \"history\": history,\n",
    "        \"config\": config,\n",
    "        \"best\": best,\n",
    "    }, os.path.join(config[\"dir\"], f\"decoder.pt\"), pickle_module=dill)\n",
    "\n",
    "### eval on test set w/ current params\n",
    "print(\"Evaluating on test set with current model...\")\n",
    "dls, neuron_coords = get_mouse_v1_data(config=config)\n",
    "if \"syn_dataset_config\" in config[\"data\"] and config[\"data\"][\"syn_dataset_config\"] is not None:\n",
    "    dls = append_syn_dataloaders(dls, config=config[\"data\"][\"syn_dataset_config\"])\n",
    "if \"data_augmentation\" in config[\"data\"] and config[\"data\"][\"data_augmentation\"] is not None:\n",
    "    dls = append_data_aug_dataloaders(\n",
    "        dataloaders=dls,\n",
    "        config=config[\"data\"][\"data_augmentation\"],\n",
    "    )\n",
    "test_loss_curr = val(\n",
    "    model=decoder,\n",
    "    dataloader=dls[\"mouse_v1\"][\"test\"],\n",
    "    loss_fn=loss_fn,\n",
    "    config=config,\n",
    ")\n",
    "print(f\"  Test loss (current model): {test_loss_curr['total']:.4f}\")\n",
    "\n",
    "### load best model\n",
    "decoder.load_state_dict(best[\"model\"])\n",
    "\n",
    "### eval on test set w/ best params\n",
    "print(\"Evaluating on test set with best model...\")\n",
    "dls, neuron_coords = get_mouse_v1_data(config=config)\n",
    "if \"syn_dataset_config\" in config[\"data\"] and config[\"data\"][\"syn_dataset_config\"] is not None:\n",
    "    dls = append_syn_dataloaders(dls, config=config[\"data\"][\"syn_dataset_config\"])\n",
    "if \"data_augmentation\" in config[\"data\"] and config[\"data\"][\"data_augmentation\"] is not None:\n",
    "    dls = append_data_aug_dataloaders(\n",
    "        dataloaders=dls,\n",
    "        config=config[\"data\"][\"data_augmentation\"],\n",
    "    )\n",
    "test_loss_final = val(\n",
    "    model=decoder,\n",
    "    dataloader=dls[\"mouse_v1\"][\"test\"],\n",
    "    loss_fn=loss_fn,\n",
    "    config=config,\n",
    ")\n",
    "print(f\"  Test loss (best model): {test_loss_final['total']:.4f}\")\n",
    "\n",
    "### plot reconstructions of the final model\n",
    "stim_pred_best = decoder(\n",
    "    resp.to(config[\"device\"]),\n",
    "    data_key=sample_data_key,\n",
    "    neuron_coords=neuron_coords[sample_data_key],\n",
    "    pupil_center=pupil_center.to(config[\"device\"]),\n",
    ").detach().cpu()\n",
    "fig = plot_comparison(\n",
    "    target=crop(stim[:8], config[\"crop_win\"]).cpu(),\n",
    "    pred=crop(stim_pred_best[:8], config[\"crop_win\"]).cpu(),\n",
    "    save_to=os.path.join(config[\"dir\"], \"stim_comparison_best.png\") if config[\"decoder\"][\"save_run\"] else None,\n",
    ")\n",
    "\n",
    "### log\n",
    "if config[\"wandb\"]:\n",
    "    wandb.run.summary[\"best_val_loss\"] = best[\"val_loss\"]\n",
    "    wandb.run.summary[\"best_epoch\"] = best[\"epoch\"]\n",
    "    wandb.run.summary[\"curr_test_loss\"] = test_loss_curr[\"total\"]\n",
    "    wandb.run.summary[\"final_test_loss\"] = test_loss_final[\"total\"]\n",
    "    wandb.run.summary[\"best_reconstruction\"] = fig\n",
    "\n",
    "### save/delete wandb run\n",
    "if config[\"wandb\"]:\n",
    "    if input(\"Delete run with 'd', save with anything else: \") == \"d\":\n",
    "        print(\"Deleting wandb run...\")\n",
    "        api = wandb.Api()\n",
    "        run = api.run(f\"johnny1188/{config['wandb']['project']}/{wdb_run.id}\")\n",
    "        run.delete()\n",
    "    else:\n",
    "        wdb_run.finish()\n",
    "\n",
    "### plot losses\n",
    "plot_losses(\n",
    "    history=history,\n",
    "    save_to=None if not config[\"decoder\"][\"save_run\"] else os.path.join(config[\"dir\"], f\"losses.png\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### show training reconstructions\n",
    "datapoint_training = next(iter(dls[\"mouse_v1\"][\"train\"].dataloaders[0]))\n",
    "stim_training, resp_training, pupil_center_training = datapoint_training.images, datapoint_training.responses, datapoint_training.pupil_center\n",
    "stim_training_pred_best = decoder(\n",
    "    resp_training.to(config[\"device\"]),\n",
    "    data_key=sample_data_key,\n",
    "    neuron_coords=neuron_coords[sample_data_key],\n",
    "    pupil_center=pupil_center_training.to(config[\"device\"]),\n",
    ").detach().cpu()\n",
    "plot_comparison(\n",
    "    target=crop(stim_training[:8], config[\"crop_win\"]).cpu(),\n",
    "    pred=crop(stim_training_pred_best[:8], config[\"crop_win\"]).cpu(),\n",
    "    save_to=os.path.join(config[\"dir\"], \"training_stim_comparison_best.png\") if config[\"decoder\"][\"save_run\"] else None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1 = MSELossWithCrop(window=config[\"crop_win\"], standardize=False)\n",
    "l2 = SSIMLoss(\n",
    "    window=config[\"crop_win\"],\n",
    "    log_loss=True,\n",
    "    inp_normalized=True,\n",
    "    inp_standardized=False,\n",
    ")\n",
    "l = lambda y_hat, y: 0.25 * l1(y_hat, y) + 0.75 * l2(y_hat, y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
