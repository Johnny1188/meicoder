{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import torch\n",
    "from torch import nn\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from copy import deepcopy\n",
    "import lovely_tensors as lt\n",
    "lt.monkey_patch()\n",
    "\n",
    "from csng.models.gan import GAN\n",
    "from csng.utils.data import crop\n",
    "from csng.data import get_dataloaders\n",
    "from csng.models.readins import MEIReadIn\n",
    "from csng.utils.mix import seed_all, update_config_paths, update_config_keys_to_value, plot_comparison, check_if_data_zscored\n",
    "from csng.models.utils.gan import init_decoder as init_gan_decoder\n",
    "from csng.models.utils.cnn import init_decoder as init_cnn_decoder\n",
    "from csng.losses import SSIMLoss, MSELoss, Loss, get_metrics, VGGPerceptualLoss\n",
    "from csng.models.readins import (\n",
    "    MultiReadIn,\n",
    "    ConvReadIn,\n",
    "    FCReadIn,\n",
    "    MEIReadIn,\n",
    ")\n",
    "from csng.models.utils.gan import train\n",
    "from csng.utils.comparison import eval_decoder\n",
    "from csng.losses import get_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### setup config\n",
    "config = {\n",
    "    \"device\": os.environ[\"DEVICE\"],\n",
    "    \"seed\": 0,\n",
    "    \"data\": {\"mixing_strategy\": \"parallel_min\"},\n",
    "    \"crop_wins\": {\"cat_v1\": (20, 20), \"mouse_v1\": (22, 36), \"brainreader_mouse\": (36, 64)},\n",
    "}\n",
    "\n",
    "print(f\"... Running on {config['device']} ...\")\n",
    "seed_all(config[\"seed\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load source dataset(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### set paths\n",
    "DATA_PATH = os.environ[\"DATA_PATH\"]\n",
    "DATA_PATH_CAT_V1 = os.path.join(DATA_PATH, \"cat_V1_spiking_model\", \"50K_single_trial_dataset\")\n",
    "DATA_PATH_MOUSE_V1 = os.path.join(DATA_PATH, \"mouse_v1_sensorium22\")\n",
    "DATA_PATH_BRAINREADER = os.path.join(DATA_PATH, \"brainreader\")\n",
    "\n",
    "print(f\"{DATA_PATH=}\")\n",
    "print(f\"{DATA_PATH_CAT_V1=}\")\n",
    "print(f\"{DATA_PATH_MOUSE_V1=}\")\n",
    "print(f\"{DATA_PATH_BRAINREADER=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### prep data config\n",
    "# brainreader mouse data\n",
    "# config[\"data\"][\"brainreader_mouse\"] = {\n",
    "#     \"device\": config[\"device\"],\n",
    "#     \"mixing_strategy\": config[\"data\"][\"mixing_strategy\"],\n",
    "#     \"max_batches\": None,\n",
    "#     \"data_dir\": os.path.join(DATA_PATH_BRAINREADER, \"data\"),\n",
    "#     \"batch_size\": 8,\n",
    "#     # \"sessions\": list(range(1, 23)),\n",
    "#     \"sessions\": [6],\n",
    "#     \"resize_stim_to\": (36, 64),\n",
    "#     \"normalize_stim\": True,\n",
    "#     \"normalize_resp\": False,\n",
    "#     \"div_resp_by_std\": True,\n",
    "#     \"clamp_neg_resp\": False,\n",
    "#     \"additional_keys\": None,\n",
    "#     \"avg_test_resp\": True,\n",
    "# }\n",
    "\n",
    "### cat v1 data\n",
    "config[\"data\"][\"cat_v1\"] = {\n",
    "    \"dataset_config\": {\n",
    "        \"train_path\": os.path.join(DATA_PATH_CAT_V1, \"datasets\", \"train\"),\n",
    "        \"val_path\": os.path.join(DATA_PATH_CAT_V1, \"datasets\", \"val\"),\n",
    "        \"test_path\": os.path.join(DATA_PATH_CAT_V1, \"datasets\", \"test\"),\n",
    "        \"image_size\": [50, 50],\n",
    "        \"crop\": False,\n",
    "        \"batch_size\": 4,\n",
    "        \"stim_keys\": (\"stim\",),\n",
    "        \"resp_keys\": (\"exc_resp\", \"inh_resp\"),\n",
    "        \"return_coords\": True,\n",
    "        \"return_ori\": False,\n",
    "        \"coords_ori_filepath\": os.path.join(DATA_PATH_CAT_V1, \"pos_and_ori.pkl\"),\n",
    "        \"cached\": False,\n",
    "        \"stim_normalize_mean\": 46.143,\n",
    "        \"stim_normalize_std\": 24.960,\n",
    "        \"resp_normalize_mean\": None, # don't center responses\n",
    "        \"resp_normalize_std\": torch.load(\n",
    "            os.path.join(DATA_PATH_CAT_V1, \"responses_std.pt\")\n",
    "        ),\n",
    "        \"clamp_neg_resp\": False,\n",
    "    },\n",
    "}\n",
    "\n",
    "# # mouse v1 data\n",
    "# config[\"data\"][\"mouse_v1\"] = {\n",
    "#     \"dataset_fn\": \"sensorium.datasets.static_loaders\",\n",
    "#     \"dataset_config\": {\n",
    "#         \"paths\": [ # from https://gin.g-node.org/cajal/Sensorium2022/src/master\n",
    "#             os.path.join(DATA_PATH_MOUSE_V1, \"static21067-10-18-GrayImageNet-94c6ff995dac583098847cfecd43e7b6.zip\"), # M-1\n",
    "#             os.path.join(DATA_PATH_MOUSE_V1, \"static22846-10-16-GrayImageNet-94c6ff995dac583098847cfecd43e7b6.zip\"), # M-2\n",
    "#             os.path.join(DATA_PATH_MOUSE_V1, \"static23343-5-17-GrayImageNet-94c6ff995dac583098847cfecd43e7b6.zip\"), # M-3\n",
    "#             os.path.join(DATA_PATH_MOUSE_V1, \"static23656-14-22-GrayImageNet-94c6ff995dac583098847cfecd43e7b6.zip\"), # M-4\n",
    "#             os.path.join(DATA_PATH_MOUSE_V1, \"static23964-4-22-GrayImageNet-94c6ff995dac583098847cfecd43e7b6.zip\"), # M-5\n",
    "#         ],\n",
    "#         \"normalize\": True,\n",
    "#         \"scale\": 0.25, # 256x144 -> 64x36\n",
    "#         \"include_behavior\": False,\n",
    "#         \"add_behavior_as_channels\": False,\n",
    "#         \"include_eye_position\": True,\n",
    "#         \"exclude\": None,\n",
    "#         \"file_tree\": True,\n",
    "#         \"cuda\": \"cuda\" in config[\"device\"],\n",
    "#         \"batch_size\": 8,\n",
    "#         \"seed\": config[\"seed\"],\n",
    "#         \"use_cache\": False,\n",
    "#     },\n",
    "#     \"skip_train\": False,\n",
    "#     \"skip_val\": False,\n",
    "#     \"skip_test\": False,\n",
    "#     \"normalize_neuron_coords\": True,\n",
    "#     \"average_test_multitrial\": True,\n",
    "#     \"save_test_multitrial\": True,\n",
    "#     \"test_batch_size\": 7,\n",
    "#     \"device\": config[\"device\"],\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls, neuron_coords = get_dataloaders(config)\n",
    "for tier, data_dict in dls.items():\n",
    "    print(f\"{tier}:\")\n",
    "    for data_name, dl in data_dict.items():\n",
    "        print(f\"  {data_name}: {len(dl)} batches\")\n",
    "        print(f\"    data keys: {', '.join(dl.data_keys)}\")\n",
    "        print(f\"    size of datasets: {', '.join([str(len(dl) * _dl.batch_size) for _dl in dl.dataloaders])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### show data\n",
    "sample_dataset = \"cat_v1\"\n",
    "sample_data_key = \"cat_v1\"\n",
    "tier = \"test\"\n",
    "sample_idx = 0\n",
    "\n",
    "datapoint = next(iter(dls[tier][sample_dataset].dataloaders[0]))\n",
    "stim, resp = datapoint.images, datapoint.responses\n",
    "print(\n",
    "    f\"Training dataset:\\t {sum(len(dl) * dl.batch_size for dl in dls['train'][sample_dataset].dataloaders)} samples\"\n",
    "    f\"\\nValidation dataset:\\t {sum(len(dl) * dl.batch_size for dl in dls['val'][sample_dataset].dataloaders)} samples\"\n",
    "    f\"\\nTest dataset:\\t\\t {sum(len(dl) * dl.batch_size for dl in dls['test'][sample_dataset].dataloaders)} samples\"\n",
    "\n",
    "    \"\\n\\nstimuli:\"\n",
    "    f\"\\n  {stim.shape}\"\n",
    "    f\"\\n  min={stim.min().item():.3f}  max={stim.max().item():.3f}\"\n",
    "    f\"\\n  mean={stim.mean().item():.3f}  std={stim.std().item():.3f}\"\n",
    "    \"\\nresponses:\"\n",
    "    f\"\\n  {resp.shape}\"\n",
    "    f\"\\n  min={resp.min().item():.3f}  max={resp.max().item():.3f}\"\n",
    "    f\"\\n  mean={resp.mean().item():.3f}  std={resp.std().item():.3f}\"\n",
    ")\n",
    "\n",
    "### plot sample data\n",
    "fig = plt.figure(figsize=(14, 6))\n",
    "ax = fig.add_subplot(131)\n",
    "ax.imshow(stim[sample_idx].cpu().squeeze().unsqueeze(-1), cmap=\"gray\")\n",
    "\n",
    "ax = fig.add_subplot(132)\n",
    "ax.imshow(crop(stim[sample_idx].cpu(), config[\"crop_wins\"][sample_data_key]).squeeze().unsqueeze(-1), cmap=\"gray\")\n",
    "\n",
    "ax = fig.add_subplot(133)\n",
    "to_show = resp[sample_idx].cpu()\n",
    "### pad with zeros\n",
    "if to_show.shape[-1] % (w := np.sqrt(resp[sample_idx].cpu().shape[0]).astype(int)) != 0:\n",
    "    to_show = torch.cat([to_show, torch.zeros(w - to_show.shape[-1] % w)], dim=-1)\n",
    "ax.imshow(to_show.view(w, -1).squeeze(0).unsqueeze(-1), cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load other external data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### shapes:\n",
    "# resp := responses of shape (batch, n_neurons)\n",
    "# neuron_coords := neural coordinates of shape {dataset_name: {data_key: (n_neurons, 2)}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up dataloaders for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StimulusResponseDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data_key, resps, stims, neuron_coords=None):\n",
    "        self.data_key = data_key\n",
    "        self.samples = [\n",
    "            self.tensors_to_datapoint(r, s, neuron_coords, data_key=data_key)\n",
    "            for r, s in zip(resps, stims)\n",
    "        ]\n",
    "\n",
    "    def tensors_to_datapoint(self, resp, stim, neuron_coords=None, **kwargs):\n",
    "        return [{\n",
    "            \"data_key\": self.data_key,\n",
    "            \"resp\": resp,\n",
    "            \"stim\": stim,\n",
    "            \"neuron_coords\": neuron_coords,\n",
    "            \"pupil_center\": None,\n",
    "            **kwargs,\n",
    "        }]\n",
    "\n",
    "    @staticmethod\n",
    "    def collate_fn(batch):\n",
    "        assert len(np.unique([b[0][\"data_key\"] for b in batch])) == 1\n",
    "        return [{\n",
    "            \"data_key\": batch[0][0][\"data_key\"],\n",
    "            \"resp\": torch.stack([b[0][\"resp\"] for b in batch]),\n",
    "            \"stim\": torch.stack([b[0][\"stim\"] for b in batch]),\n",
    "            \"neuron_coords\": batch[0][0][\"neuron_coords\"],\n",
    "            \"pupil_center\": None,\n",
    "        }]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.samples[idx]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### setup dataloaders for training (example)\n",
    "ft_dataloaders = { # need to reinitialize after each epoch!\n",
    "    \"train\": {\n",
    "        \"name_of_my_dataset\": iter(torch.utils.data.DataLoader(\n",
    "            StimulusResponseDataset(\n",
    "                data_key=\"cat_v1\",\n",
    "                resps=resp[:8],\n",
    "                stims=stim_pred[:8],\n",
    "                neuron_coords=neuron_coords[\"cat_v1\"][\"cat_v1\"],\n",
    "            ),\n",
    "            batch_size=2,\n",
    "            shuffle=True,\n",
    "            collate_fn=StimulusResponseDataset.collate_fn,\n",
    "        ))\n",
    "    },\n",
    "    \"val\": {\n",
    "        \"name_of_my_dataset\": iter(torch.utils.data.DataLoader(\n",
    "            StimulusResponseDataset(\n",
    "                data_key=\"cat_v1\",\n",
    "                resps=resp[:8],\n",
    "                stims=stim_pred[:8],\n",
    "                neuron_coords=neuron_coords[\"cat_v1\"][\"cat_v1\"],\n",
    "            ),\n",
    "            batch_size=2,\n",
    "            shuffle=False,\n",
    "            collate_fn=StimulusResponseDataset.collate_fn,\n",
    "        ))\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Decoding models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generative Adversarial Network (GAN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### decoder config\n",
    "inp_zscored = check_if_data_zscored(cfg=config)\n",
    "config[\"decoder\"] = {\n",
    "    \"readin_type\": (readin_type := \"mei\"), # \"conv\", \"fc\", \"mei\"\n",
    "    \"model\": {\n",
    "        \"readins_config\": [], # added later\n",
    "        \"core_cls\": GAN,\n",
    "        \"core_config\": {\n",
    "            \"G_kwargs\": {\n",
    "                \"in_shape\": (480,), # needs to match the # of channels of the readin output\n",
    "                \"layers\": {\n",
    "                    \"conv\": [\n",
    "                        (\"deconv\", 480, 7, 2, 3),\n",
    "                        (\"deconv\", 256, 5, 1, 2),\n",
    "                        (\"deconv\", 256, 5, 1, 1),\n",
    "                        (\"deconv\", 128, 4, 1, 1),\n",
    "                        (\"deconv\", 64, 3, 1, 1),\n",
    "                        (\"deconv\", 1, 3, 1, 0),\n",
    "                    ],\n",
    "                    \"fc\": [\n",
    "                        (\"deconv\", 480, 7, 2, 3),\n",
    "                        (\"deconv\", 256, 5, 1, 2),\n",
    "                        (\"deconv\", 256, 5, 1, 1),\n",
    "                        (\"deconv\", 128, 4, 1, 1),\n",
    "                        (\"deconv\", 64, 3, 1, 1),\n",
    "                        (\"deconv\", 1, 3, 1, 0),\n",
    "                    ],\n",
    "                    \"mei\": [\n",
    "                        (\"conv\", 480, 7, 1, 3),\n",
    "                        (\"conv\", 256, 5, 1, 2),\n",
    "                        (\"conv\", 256, 5, 1, 2),\n",
    "                        (\"conv\", 128, 3, 1, 1),\n",
    "                        (\"conv\", 64, 3, 1, 1),\n",
    "                        (\"conv\", 1, 3, 1, 1),\n",
    "                    ],\n",
    "                }[readin_type],\n",
    "                \"act_fn\": nn.ReLU,\n",
    "                \"out_act_fn\": nn.Identity,\n",
    "                \"dropout\": 0.35,\n",
    "                \"batch_norm\": True,\n",
    "            },\n",
    "            \"D_kwargs\": {\n",
    "                \"in_shape\": [1, 36, 64],\n",
    "                \"layers\": [\n",
    "                    (\"conv\", 256, 7, 2, 2),\n",
    "                    (\"conv\", 256, 5, 1, 2),\n",
    "                    (\"conv\", 128, 3, 1, 1),\n",
    "                    (\"conv\", 64, 3, 1, 1),\n",
    "                    (\"conv\", 64, 3, 1, 1),\n",
    "                    dict(), # filled later with discriminator's head\n",
    "                ],\n",
    "                \"act_fn\": nn.ReLU,\n",
    "                \"out_act_fn\": nn.Identity, # sigmoid already in layers[-1] (head)\n",
    "                \"dropout\": 0.3,\n",
    "                \"batch_norm\": True,\n",
    "            },\n",
    "        },\n",
    "    },\n",
    "    \"loss\": {\n",
    "        \"loss_fn\": dict(),\n",
    "        \"l1_reg_mul\": 0,\n",
    "        \"l2_reg_mul\": 0,\n",
    "    },\n",
    "    \"eval_loss_name\": \"Alex(5) Loss\",  # for \"higher is better\" metrics, use \"<name> Loss\"\n",
    "    \"G_opter_cls\": torch.optim.AdamW,\n",
    "    # \"G_opter_kwargs\": {\"lr\": 1e-4, \"weight_decay\": 0.08},\n",
    "    \"G_opter_kwargs\": {\"lr\": 3e-5, \"weight_decay\": 0.3},\n",
    "    \"D_opter_cls\": torch.optim.AdamW,\n",
    "    # \"D_opter_kwargs\": {\"lr\": 1e-4, \"weight_decay\": 0.08},\n",
    "    \"D_opter_kwargs\": {\"lr\": 3e-5, \"weight_decay\": 0.3},\n",
    "    \"G_reg\": {\"l1\": 0, \"l2\": 0},\n",
    "    \"D_reg\": {\"l1\": 0, \"l2\": 0},\n",
    "    \"G_adv_loss_mul\": 0.1,\n",
    "    \"G_stim_loss_mul\": 0.9,\n",
    "    \"D_real_loss_mul\": 0.5,\n",
    "    \"D_fake_loss_mul\": 0.5,\n",
    "    \"D_real_stim_labels_noise\": 0.05,\n",
    "    \"D_fake_stim_labels_noise\": 0.05,\n",
    "    \"n_epochs\": 300,\n",
    "    \"load_ckpt\": None,\n",
    "}\n",
    "\n",
    "### finish config for brainreader mouse\n",
    "if \"brainreader_mouse\" in config[\"data\"]:\n",
    "    _dls, _ = get_dataloaders(config=config)\n",
    "    for data_key, dset in zip(_dls[\"train\"][\"brainreader_mouse\"].data_keys, _dls[\"train\"][\"brainreader_mouse\"].datasets):\n",
    "        ### set crop wins and losses\n",
    "        config[\"crop_wins\"][data_key] = tuple(dset[0].images.shape[-2:])\n",
    "        config[\"decoder\"][\"loss\"][\"loss_fn\"][data_key] = SSIMLoss(window=config[\"crop_wins\"][data_key], log_loss=True, inp_normalized=True, inp_standardized=False)\n",
    "        # config[\"decoder\"][\"loss\"][\"loss_fn\"][data_key] = Loss(config=dict(\n",
    "        #     loss_fn=VGGPerceptualLoss(\n",
    "        #         resize=False,\n",
    "        #         device=config[\"device\"],\n",
    "        #         reduction=\"mean\",\n",
    "        #     ),\n",
    "        #     window=config[\"crop_wins\"][data_key],\n",
    "        #     standardize=True,\n",
    "        # ))\n",
    "\n",
    "        ### append discriminator's head\n",
    "        config[\"decoder\"][\"model\"][\"core_config\"][\"D_kwargs\"][\"layers\"][-1][data_key] = {\n",
    "            \"in_shape\": [1, 36, 64],\n",
    "            \"layers_config\": [(\"fc\", 1)],\n",
    "            \"act_fn\": nn.Identity,\n",
    "            \"out_act_fn\": nn.Sigmoid,\n",
    "        }\n",
    "\n",
    "        ### append readin\n",
    "        n_neurons = dset[0].responses.shape[-1]\n",
    "        config[\"decoder\"][\"model\"][\"readins_config\"].append({\n",
    "            \"data_key\": data_key,\n",
    "            \"in_shape\": n_neurons,\n",
    "            \"decoding_objective_config\": None,\n",
    "            \"layers\": {\n",
    "                \"conv\": [\n",
    "                    (ConvReadIn, {\n",
    "                        \"H\": 18,\n",
    "                        \"W\": 32,\n",
    "                        \"shift_coords\": False,\n",
    "                        \"learn_grid\": True,\n",
    "                        \"grid_l1_reg\": 8e-3,\n",
    "                        \"in_channels_group_size\": 1,\n",
    "                        \"grid_net_config\": {\n",
    "                            \"in_channels\": 1, # resp\n",
    "                            \"layers_config\": [(\"fc\", 8), (\"fc\", 64), (\"fc\", 18*32)],\n",
    "                            \"act_fn\": nn.LeakyReLU,\n",
    "                            \"out_act_fn\": nn.Identity,\n",
    "                            \"dropout\": 0.2,\n",
    "                            \"batch_norm\": False,\n",
    "                        },\n",
    "                        \"pointwise_conv_config\": {\n",
    "                            \"in_channels\": n_neurons,\n",
    "                            \"out_channels\": 480,\n",
    "                            \"act_fn\": nn.Identity,\n",
    "                            \"bias\": False,\n",
    "                            \"batch_norm\": True,\n",
    "                            \"dropout\": 0.2,\n",
    "                        },\n",
    "                        \"gauss_blur\": False,\n",
    "                        \"gauss_blur_kernel_size\": 7,\n",
    "                        \"gauss_blur_sigma\": \"fixed\", # \"fixed\", \"single\", \"per_neuron\"\n",
    "                        \"gauss_blur_sigma_init\": 1.5,\n",
    "                        \"neuron_emb_dim\": None,\n",
    "                    }),\n",
    "                ],\n",
    "                \"fc\": [\n",
    "                    (FCReadIn, {\n",
    "                        \"in_shape\": n_neurons,\n",
    "                        \"layers_config\": [\n",
    "                            (\"fc\", 1728),\n",
    "                            (\"unflatten\", 1, (3, 18, 32)),\n",
    "                        ],\n",
    "                        \"act_fn\": nn.LeakyReLU,\n",
    "                        \"out_act_fn\": nn.Identity,\n",
    "                        \"batch_norm\": True,\n",
    "                        \"dropout\": 0.15,\n",
    "                        \"apply_resp_transform\": False,\n",
    "                    }),\n",
    "                ],\n",
    "                \"mei\": [\n",
    "                    (MEIReadIn, {\n",
    "                        \"meis_path\": os.path.join(DATA_PATH_BRAINREADER, \"meis\", data_key,  \"meis.pt\"),\n",
    "                        \"n_neurons\": n_neurons,\n",
    "                        \"mei_resize_method\": \"resize\",\n",
    "                        \"mei_target_shape\": (36, 64),\n",
    "                        \"meis_trainable\": False,\n",
    "                        \"use_neuron_coords\": (_use_neuron_coords := False),\n",
    "                        \"neuron_emb_dim\": (_neuron_emb_dim := 32),\n",
    "                        \"pointwise_conv_config\": {\n",
    "                            \"out_channels\": 480,\n",
    "                            \"bias\": False,\n",
    "                            \"batch_norm\": True,\n",
    "                            \"act_fn\": nn.LeakyReLU,\n",
    "                            \"dropout\": 0.2,\n",
    "                        },\n",
    "                        \"ctx_net_config\": {\n",
    "                            \"in_channels\": 1 + 2*int(_use_neuron_coords) + (_neuron_emb_dim or 0), # resp, x, y, neuron_emb\n",
    "                            \"layers_config\": [(\"fc\", 128), (\"fc\", 36*64)],\n",
    "                            \"act_fn\": nn.LeakyReLU,\n",
    "                            \"out_act_fn\": nn.Identity,\n",
    "                            \"dropout\": 0.15,\n",
    "                            \"batch_norm\": True,\n",
    "                        },\n",
    "                        \"l2_reg_mul\": 0,\n",
    "                        \"apply_resp_transform\": False,\n",
    "                        \"shift_coords\": False,\n",
    "                        \"neuron_idxs\": None, # np.random.default_rng(seed=config[\"seed\"]).choice(n_neurons, size=int(n_neurons * 0.5), replace=False),\n",
    "                        # \"neuron_idxs\": np.random.default_rng(seed=config[\"seed\"]).choice(n_neurons, size=int(n_neurons * 0.05), replace=False),\n",
    "                        # \"neuron_idxs\": np.random.default_rng(seed=config[\"seed\"]).choice(n_neurons, size=500, replace=False),\n",
    "                        \"device\": config[\"device\"],\n",
    "                    }),\n",
    "                ],\n",
    "            }[config[\"decoder\"][\"readin_type\"]],\n",
    "        })\n",
    "\n",
    "### finish config for cat v1\n",
    "if \"cat_v1\" in config[\"data\"]:\n",
    "    ### set losses\n",
    "    config[\"decoder\"][\"loss\"][\"loss_fn\"][\"cat_v1\"] = SSIMLoss(window=config[\"crop_wins\"][\"cat_v1\"], log_loss=True, inp_normalized=True, inp_standardized=False)\n",
    "    # config[\"decoder\"][\"loss\"][\"loss_fn\"][\"cat_v1\"] = Loss(config=dict(\n",
    "    #     loss_fn=VGGPerceptualLoss(\n",
    "    #         resize=False,\n",
    "    #         device=config[\"device\"],\n",
    "    #         reduction=\"mean\",\n",
    "    #     ),\n",
    "    #     window=config[\"crop_wins\"][\"cat_v1\"],\n",
    "    #     standardize=True,\n",
    "    # ))\n",
    "\n",
    "    ### append discriminator's head\n",
    "    config[\"decoder\"][\"model\"][\"core_config\"][\"D_kwargs\"][\"layers\"][-1][\"cat_v1\"] = {\n",
    "        \"in_shape\": [1, *config[\"crop_wins\"][\"cat_v1\"]],\n",
    "        \"layers_config\": [(\"fc\", 1)],\n",
    "        \"act_fn\": nn.Identity,\n",
    "        \"out_act_fn\": nn.Sigmoid,\n",
    "    }\n",
    "\n",
    "    ### append readin\n",
    "    config[\"decoder\"][\"model\"][\"readins_config\"].append({\n",
    "        \"data_key\": \"cat_v1\",\n",
    "        \"in_shape\": 46875,\n",
    "        \"decoding_objective_config\": None,\n",
    "        \"layers\": {\n",
    "            \"conv\": [\n",
    "                (ConvReadIn, {\n",
    "                    \"H\": 8,\n",
    "                    \"W\": 8,\n",
    "                    \"shift_coords\": False,\n",
    "                    \"learn_grid\": True,\n",
    "                    \"grid_l1_reg\": 8e-3,\n",
    "                    \"in_channels_group_size\": 1,\n",
    "                    \"grid_net_config\": {\n",
    "                        \"in_channels\": 3, # x, y, resp\n",
    "                        \"layers_config\": [(\"fc\", 64), (\"fc\", 128), (\"fc\", 8*8)],\n",
    "                        \"act_fn\": nn.LeakyReLU,\n",
    "                        \"out_act_fn\": nn.Identity,\n",
    "                        \"dropout\": 0.15,\n",
    "                        \"batch_norm\": False,\n",
    "                    },\n",
    "                    \"pointwise_conv_config\": {\n",
    "                        \"in_channels\": 46875,\n",
    "                        \"out_channels\": 480,\n",
    "                        \"act_fn\": nn.Identity,\n",
    "                        \"bias\": False,\n",
    "                        \"batch_norm\": True,\n",
    "                        \"dropout\": 0.1,\n",
    "                    },\n",
    "                    \"gauss_blur\": False,\n",
    "                    \"gauss_blur_kernel_size\": 7,\n",
    "                    \"gauss_blur_sigma\": \"fixed\", # \"fixed\", \"single\", \"per_neuron\"\n",
    "                    # \"gauss_blur_sigma\": \"per_neuron\", # \"fixed\", \"single\", \"per_neuron\"\n",
    "                    \"gauss_blur_sigma_init\": 1.5,\n",
    "                    \"neuron_emb_dim\": None,\n",
    "                }),\n",
    "            ],\n",
    "            \"fc\": [\n",
    "                (FCReadIn, {\n",
    "                    \"in_shape\": 46875,\n",
    "                    \"layers_config\": [\n",
    "                        (\"fc\", 192),\n",
    "                        (\"unflatten\", 1, (3, 8, 8)),\n",
    "                    ],\n",
    "                    \"act_fn\": nn.LeakyReLU,\n",
    "                    \"out_act_fn\": nn.Identity,\n",
    "                    \"batch_norm\": True,\n",
    "                    \"dropout\": 0.15,\n",
    "                    \"out_channels\": 8,\n",
    "                }),\n",
    "            ],\n",
    "            \"mei\": [\n",
    "                (MEIReadIn, {\n",
    "                    \"meis_path\": os.path.join(DATA_PATH_CAT_V1, \"meis\", \"cat_v1\",  \"meis.pt\"),\n",
    "                    \"n_neurons\": 46875,\n",
    "                    \"mei_resize_method\": \"resize\",\n",
    "                    \"mei_target_shape\": config[\"crop_wins\"][\"cat_v1\"],\n",
    "                    \"meis_trainable\": False,\n",
    "                    \"use_neuron_coords\": (_use_neuron_coords := False),\n",
    "                    \"neuron_emb_dim\": (_neuron_emb_dim := 16),\n",
    "                    \"pointwise_conv_config\": {\n",
    "                        \"out_channels\": 480,\n",
    "                        \"bias\": False,\n",
    "                        \"batch_norm\": True,\n",
    "                        \"act_fn\": nn.LeakyReLU,\n",
    "                        \"dropout\": 0.15,\n",
    "                    },\n",
    "                    \"ctx_net_config\": {\n",
    "                        \"in_channels\": 1 + 2*int(_use_neuron_coords) + (_neuron_emb_dim or 0), # resp, x, y, neuron_emb\n",
    "                        \"layers_config\": [(\"fc\", 32), (\"fc\", 128), (\"fc\", np.prod(config[\"crop_wins\"][\"cat_v1\"]))],\n",
    "                        \"act_fn\": nn.LeakyReLU,\n",
    "                        \"out_act_fn\": nn.Identity,\n",
    "                        \"dropout\": 0.15,\n",
    "                        \"batch_norm\": True,\n",
    "                    },\n",
    "                    \"l2_reg_mul\": 0,\n",
    "                    \"apply_resp_transform\": False,\n",
    "                    \"shift_coords\": False,\n",
    "                    \"neuron_idxs\": None,\n",
    "                    # \"neuron_idxs\": np.random.default_rng(seed=config[\"seed\"]).choice(46875, size=int(46875 * 0.005), replace=False),\n",
    "                    # \"neuron_idxs\": np.random.default_rng(seed=config[\"seed\"]).choice(46875, size=500, replace=False),\n",
    "                    \"device\": config[\"device\"],\n",
    "                }),\n",
    "            ],\n",
    "        }[config[\"decoder\"][\"readin_type\"]],\n",
    "    })\n",
    "\n",
    "### finish config for mouse v1\n",
    "if \"mouse_v1\" in config[\"data\"]:\n",
    "    _dls, _neuron_coords = get_dataloaders(config=config)\n",
    "    for data_key, n_coords in _dls[\"train\"][\"mouse_v1\"].neuron_coords.items():\n",
    "        ### set crop wins and losses\n",
    "        config[\"crop_wins\"][data_key] = config[\"data\"][\"mouse_v1\"][\"crop_win\"]\n",
    "        config[\"decoder\"][\"loss\"][\"loss_fn\"][data_key] = SSIMLoss(window=config[\"crop_wins\"][data_key], log_loss=True, inp_normalized=True, inp_standardized=False)\n",
    "        # config[\"decoder\"][\"loss\"][\"loss_fn\"][data_key] = Loss(config=dict(\n",
    "        #     loss_fn=VGGPerceptualLoss(\n",
    "        #         resize=False,\n",
    "        #         device=config[\"device\"],\n",
    "        #         reduction=\"mean\",\n",
    "        #     ),\n",
    "        #     window=config[\"crop_wins\"][data_key],\n",
    "        #     standardize=True,\n",
    "        # ))\n",
    "\n",
    "        ### append discriminator's head\n",
    "        config[\"decoder\"][\"model\"][\"core_config\"][\"D_kwargs\"][\"layers\"][-1][data_key] = {\n",
    "            \"in_shape\": [1, *config[\"crop_wins\"][data_key]],\n",
    "            \"layers_config\": [(\"fc\", 1)],\n",
    "            \"act_fn\": nn.Identity,\n",
    "            \"out_act_fn\": nn.Sigmoid,\n",
    "        }\n",
    "\n",
    "        ### append readin\n",
    "        config[\"decoder\"][\"model\"][\"readins_config\"].append({\n",
    "            \"data_key\": data_key,\n",
    "            \"in_shape\": n_coords.shape[-2],\n",
    "            \"decoding_objective_config\": None,\n",
    "            \"layers\": {\n",
    "                \"conv\": [\n",
    "                    (ConvReadIn, {\n",
    "                        \"H\": 10,\n",
    "                        \"W\": 18,\n",
    "                        \"shift_coords\": False,\n",
    "                        \"learn_grid\": True,\n",
    "                        \"grid_l1_reg\": 8e-3,\n",
    "                        \"in_channels_group_size\": 1,\n",
    "                        \"grid_net_config\": {\n",
    "                            \"in_channels\": 3, # x, y, resp\n",
    "                            \"layers_config\": [(\"fc\", 32), (\"fc\", 86), (\"fc\", 18*10)],\n",
    "                            \"act_fn\": nn.LeakyReLU,\n",
    "                            \"out_act_fn\": nn.Identity,\n",
    "                            \"dropout\": 0.1,\n",
    "                            \"batch_norm\": False,\n",
    "                        },\n",
    "                        \"pointwise_conv_config\": {\n",
    "                            \"in_channels\": n_coords.shape[-2],\n",
    "                            \"out_channels\": 480,\n",
    "                            \"act_fn\": nn.Identity,\n",
    "                            \"bias\": False,\n",
    "                            \"batch_norm\": True,\n",
    "                            \"dropout\": 0.1,\n",
    "                        },\n",
    "                        \"gauss_blur\": False,\n",
    "                        \"gauss_blur_kernel_size\": 7,\n",
    "                        \"gauss_blur_sigma\": \"fixed\", # \"fixed\", \"single\", \"per_neuron\"\n",
    "                        \"gauss_blur_sigma_init\": 1.5,\n",
    "                        \"neuron_emb_dim\": None,\n",
    "                    }),\n",
    "                ],\n",
    "                \"fc\": [\n",
    "                    (FCReadIn, {\n",
    "                        \"in_shape\": n_coords.shape[-2],\n",
    "                        \"layers_config\": [\n",
    "                            (\"fc\", 540),\n",
    "                            (\"unflatten\", 1, (3, 10, 18)),\n",
    "                        ],\n",
    "                        \"act_fn\": nn.LeakyReLU,\n",
    "                        \"out_act_fn\": nn.Identity,\n",
    "                        \"batch_norm\": True,\n",
    "                        \"dropout\": 0.15,\n",
    "                    }),\n",
    "                ],\n",
    "                \"mei\": [\n",
    "                    (MEIReadIn, {\n",
    "                        \"meis_path\": os.path.join(DATA_PATH_MOUSE_V1, \"meis\", data_key,  \"meis.pt\"),\n",
    "                        \"n_neurons\": n_coords.shape[-2],\n",
    "                        \"mei_resize_method\": \"resize\",\n",
    "                        \"mei_target_shape\": config[\"crop_wins\"][data_key],\n",
    "                        \"meis_trainable\": False,\n",
    "                        \"use_neuron_coords\": (_use_neuron_coords := False),\n",
    "                        \"neuron_emb_dim\": (_neuron_emb_dim := 32),\n",
    "                        \"pointwise_conv_config\": {\n",
    "                            \"out_channels\": 480,\n",
    "                            \"bias\": False,\n",
    "                            \"batch_norm\": True,\n",
    "                            \"act_fn\": nn.LeakyReLU,\n",
    "                            \"dropout\": 0.2,\n",
    "                        },\n",
    "                        \"ctx_net_config\": {\n",
    "                            \"in_channels\": 1 + 2*int(_use_neuron_coords) + (_neuron_emb_dim or 0), # resp, x, y, neuron_emb\n",
    "                            \"layers_config\": [(\"fc\", 128), (\"fc\", np.prod(config[\"crop_wins\"][data_key]))],\n",
    "                            \"act_fn\": nn.LeakyReLU,\n",
    "                            \"out_act_fn\": nn.Identity,\n",
    "                            \"dropout\": 0.15,\n",
    "                            \"batch_norm\": True,\n",
    "                        },\n",
    "                        \"l2_reg_mul\": 0,\n",
    "                        \"l1_reg_mul\": 0,\n",
    "                        \"apply_resp_transform\": False,\n",
    "                        \"shift_coords\": False,\n",
    "                        \"neuron_idxs\": None,\n",
    "                        # \"neuron_idxs\": np.random.default_rng(seed=config[\"seed\"]).choice(n_coords.shape[-2], size=int(n_coords.shape[-2] * 0.015), replace=False),\n",
    "                        # \"neuron_idxs\": np.random.default_rng(seed=config[\"seed\"]).choice(n_coords.shape[-2], size=500, replace=False),\n",
    "                        \"device\": config[\"device\"],\n",
    "                    }),\n",
    "                ],\n",
    "            }[config[\"decoder\"][\"readin_type\"]],\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### config for loading a model checkpoint (run if you want to fine-tune/continue training a pretrained model)\n",
    "config[\"decoder\"][\"load_ckpt\"] = { # uncomment to load a checkpoint (and fine-tune)\n",
    "    \"ckpt_path\": os.path.join(\n",
    "        os.environ[\"DATA_PATH\"],\n",
    "        \"models\", \"gan\",\n",
    "        \"2025-04-25_20-19-46\", \"decoder_195.pt\",\n",
    "    ),\n",
    "    \"load_only_core\": False, # set to True if you want to keep only the core and reset the readins\n",
    "    \"load_best\": True, # load best model from the checkpoint (val. loss during pretraining)\n",
    "    \"load_opter_state\": False, # don't load optimizer state for fine-tuning\n",
    "    \"load_history\": False, # reset training history for fine-tuning\n",
    "    \"reset_best\": True, # reset best-model tracking for fine-tuning\n",
    "}\n",
    "\n",
    "### utility function for merging configuration from checkpoint with the current configuration\n",
    "def merge_configs_fn(cfg, ckpt_cfg):\n",
    "    \"\"\" Utility function for merging configuration from checkpoint (ckpt_cfg) with the current configuration \"\"\"\n",
    "    ckpt_cfg[\"decoder\"][\"load_ckpt\"] = cfg[\"decoder\"][\"load_ckpt\"]\n",
    "    ckpt_cfg = update_config_keys_to_value(ckpt_cfg, \"device\", cfg[\"device\"])\n",
    "    cfg = ckpt_cfg\n",
    "    cfg = update_config_paths(config=cfg, new_data_path=DATA_PATH)\n",
    "    return cfg, ckpt_cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### load model\n",
    "cfg, gan, loss_fn, history, best, ckpt = init_gan_decoder(config=config, merge_configs_fn=merge_configs_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show example reconstructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### decode\n",
    "with torch.no_grad():\n",
    "    stim_pred = gan(\n",
    "        resp.to(config[\"device\"]),\n",
    "        data_key=\"cat_v1\",\n",
    "        neuron_coords=neuron_coords[\"cat_v1\"][\"cat_v1\"]\n",
    "    ) # (batch, n_channels, h, w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### show comparison\n",
    "fig = plot_comparison(\n",
    "    target=crop(stim[:8], config[\"crop_wins\"][\"cat_v1\"]).cpu(),\n",
    "    pred=crop(stim_pred[:8], config[\"crop_wins\"][\"cat_v1\"]).cpu(),\n",
    "    show=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### train (example for a single epoch)\n",
    "gan.train()\n",
    "single_epoch_training_history = train(\n",
    "    model=gan,\n",
    "    dataloaders=ft_dataloaders[\"train\"],\n",
    "    loss_fn=loss_fn,\n",
    "    config=cfg,\n",
    "    history=history,\n",
    "    log_freq=100,\n",
    "    wdb_run=None,\n",
    "    device=cfg[\"device\"],\n",
    ")\n",
    "\n",
    "### eval\n",
    "gan.eval()\n",
    "val_losses = eval_decoder(\n",
    "    model=gan,\n",
    "    dataloaders=ft_dataloaders[\"val\"],\n",
    "    loss_fns={\"cat_v1\": get_metrics(\n",
    "        inp_zscored=True,\n",
    "        crop_win=cfg[\"crop_wins\"][\"cat_v1\"],\n",
    "        device=cfg[\"device\"]\n",
    "    )},\n",
    "    crop_wins=cfg[\"crop_wins\"],\n",
    "    device=cfg[\"device\"],\n",
    ")[\"total\"]\n",
    "\n",
    "print(dict(val_losses))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "csng",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
