{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import torch\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import lovely_tensors as lt\n",
    "lt.monkey_patch()\n",
    "\n",
    "from csng.utils.data import crop\n",
    "from csng.data import get_dataloaders\n",
    "from csng.utils.mix import seed_all\n",
    "\n",
    "### set paths\n",
    "DATA_PATH = os.environ[\"DATA_PATH\"]\n",
    "DATA_PATH_CAT_V1 = os.path.join(DATA_PATH, \"cat_V1_spiking_model\", \"50K_single_trial_dataset\")\n",
    "DATA_PATH_MOUSE_V1 = os.path.join(DATA_PATH, \"mouse_v1_sensorium22\")\n",
    "DATA_PATH_BRAINREADER = os.path.join(DATA_PATH, \"brainreader\")\n",
    "\n",
    "print(f\"{DATA_PATH=}\")\n",
    "print(f\"{DATA_PATH_CAT_V1=}\")\n",
    "print(f\"{DATA_PATH_MOUSE_V1=}\")\n",
    "print(f\"{DATA_PATH_BRAINREADER=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### setup config\n",
    "config = {\n",
    "    \"device\": os.environ[\"DEVICE\"],\n",
    "    \"seed\": 0,\n",
    "    \"save_run\": True,\n",
    "    \"wandb\": {\n",
    "        \"project\": os.environ[\"WANDB_PROJECT\"],\n",
    "        \"group\": \"cnn_decoder\",\n",
    "    },\n",
    "    \"data\": {\n",
    "        \"mixing_strategy\": \"parallel_min\", # needed only with multiple base dataloaders\n",
    "        \"max_training_batches\": None,\n",
    "    },\n",
    "    \"crop_wins\": dict(),\n",
    "}\n",
    "\n",
    "print(f\"... Running on {config['device']} ...\")\n",
    "seed_all(config[\"seed\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### prep data config\n",
    "# brainreader mouse data\n",
    "config[\"data\"][\"brainreader_mouse\"] = {\n",
    "    \"device\": config[\"device\"],\n",
    "    \"mixing_strategy\": config[\"data\"][\"mixing_strategy\"],\n",
    "    \"max_batches\": None,\n",
    "    \"data_dir\": os.path.join(DATA_PATH_BRAINREADER, \"data\"),\n",
    "    \"batch_size\": 8,\n",
    "    \"sessions\": list(range(1, 23)),\n",
    "    \"resize_stim_to\": (36, 64),\n",
    "    \"normalize_stim\": True,\n",
    "    \"normalize_resp\": False,\n",
    "    \"div_resp_by_std\": True,\n",
    "    \"clamp_neg_resp\": False,\n",
    "    \"additional_keys\": None,\n",
    "    \"avg_test_resp\": True,\n",
    "}\n",
    "\n",
    "# cat v1 data\n",
    "config[\"data\"][\"cat_v1\"] = {\n",
    "    \"crop_win\": (20, 20),\n",
    "    \"dataset_config\": {\n",
    "        \"train_path\": os.path.join(DATA_PATH_CAT_V1, \"datasets\", \"train\"),\n",
    "        \"val_path\": os.path.join(DATA_PATH_CAT_V1, \"datasets\", \"val\"),\n",
    "        \"test_path\": os.path.join(DATA_PATH_CAT_V1, \"datasets\", \"test\"),\n",
    "        \"image_size\": [50, 50],\n",
    "        \"crop\": False,\n",
    "        \"batch_size\": 8,\n",
    "        \"stim_keys\": (\"stim\",),\n",
    "        \"resp_keys\": (\"exc_resp\", \"inh_resp\"),\n",
    "        \"return_coords\": True,\n",
    "        \"return_ori\": False,\n",
    "        \"coords_ori_filepath\": os.path.join(DATA_PATH_CAT_V1, \"pos_and_ori.pkl\"),\n",
    "        \"cached\": False,\n",
    "        \"stim_normalize_mean\": 46.143,\n",
    "        \"stim_normalize_std\": 24.960,\n",
    "        \"resp_normalize_mean\": torch.load(\n",
    "            os.path.join(DATA_PATH_CAT_V1, \"responses_mean.pt\")\n",
    "        ),\n",
    "        \"resp_normalize_std\": torch.load(\n",
    "            os.path.join(DATA_PATH_CAT_V1, \"responses_std.pt\")\n",
    "        ),\n",
    "    },\n",
    "}\n",
    "\n",
    "# mouse v1 data\n",
    "config[\"data\"][\"mouse_v1\"] = {\n",
    "    \"dataset_fn\": \"sensorium.datasets.static_loaders\",\n",
    "    \"dataset_config\": {\n",
    "        \"paths\": [ # from https://gin.g-node.org/cajal/Sensorium2022/src/master\n",
    "            os.path.join(DATA_PATH_MOUSE_V1, \"static21067-10-18-GrayImageNet-94c6ff995dac583098847cfecd43e7b6.zip\"), # M-1\n",
    "            os.path.join(DATA_PATH_MOUSE_V1, \"static22846-10-16-GrayImageNet-94c6ff995dac583098847cfecd43e7b6.zip\"), # M-2\n",
    "            os.path.join(DATA_PATH_MOUSE_V1, \"static23343-5-17-GrayImageNet-94c6ff995dac583098847cfecd43e7b6.zip\"), # M-3\n",
    "            os.path.join(DATA_PATH_MOUSE_V1, \"static23656-14-22-GrayImageNet-94c6ff995dac583098847cfecd43e7b6.zip\"), # M-4\n",
    "            os.path.join(DATA_PATH_MOUSE_V1, \"static23964-4-22-GrayImageNet-94c6ff995dac583098847cfecd43e7b6.zip\"), # M-5\n",
    "        ],\n",
    "        \"normalize\": True,\n",
    "        \"scale\": 0.25, # 256x144 -> 64x36\n",
    "        \"include_behavior\": False,\n",
    "        \"add_behavior_as_channels\": False,\n",
    "        \"include_eye_position\": True,\n",
    "        \"exclude\": None,\n",
    "        \"file_tree\": True,\n",
    "        \"cuda\": \"cuda\" in config[\"device\"],\n",
    "        \"batch_size\": 8,\n",
    "        \"seed\": config[\"seed\"],\n",
    "        \"use_cache\": False,\n",
    "    },\n",
    "    \"crop_win\": (22, 36),\n",
    "    \"skip_train\": False,\n",
    "    \"skip_val\": False,\n",
    "    \"skip_test\": False,\n",
    "    \"normalize_neuron_coords\": True,\n",
    "    \"average_test_multitrial\": True,\n",
    "    \"save_test_multitrial\": True,\n",
    "    \"test_batch_size\": 7,\n",
    "    \"device\": config[\"device\"],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls, neuron_coords = get_dataloaders(config)\n",
    "for tier, data_dict in dls.items():\n",
    "    print(f\"{tier}:\")\n",
    "    for data_name, dl in data_dict.items():\n",
    "        for data_key, dset in zip(dl.data_keys, dl.datasets):\n",
    "            config[\"crop_wins\"][data_key] = tuple(dset[0].images.shape[-2:])\n",
    "        print(f\"  {data_name}: {len(dl)} batches\")\n",
    "        print(f\"    data keys: {', '.join(dl.data_keys)}\")\n",
    "        print(f\"    size of datasets: {', '.join([str(len(dl) * _dl.batch_size) for _dl in dl.dataloaders])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neuron_coords[\"cat_v1\"][\"cat_v1\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### show data\n",
    "data_name = \"brainreader_mouse\"\n",
    "sample_data_key = \"1\"\n",
    "tier = \"test\"\n",
    "sample_idx = 0\n",
    "\n",
    "datapoint = next(iter(dls[tier][data_name].dataloaders[0]))\n",
    "stim, resp = datapoint.images, datapoint.responses\n",
    "print(\n",
    "    f\"Training dataset:\\t {sum(len(dl) * dl.batch_size for dl in dls['train'][data_name].dataloaders)} samples\"\n",
    "    f\"\\nValidation dataset:\\t {sum(len(dl) * dl.batch_size for dl in dls['val'][data_name].dataloaders)} samples\"\n",
    "    f\"\\nTest dataset:\\t\\t {sum(len(dl) * dl.batch_size for dl in dls['test'][data_name].dataloaders)} samples\"\n",
    "\n",
    "    \"\\n\\nstimuli:\"\n",
    "    f\"\\n  {stim.shape}\"\n",
    "    f\"\\n  min={stim.min().item():.3f}  max={stim.max().item():.3f}\"\n",
    "    f\"\\n  mean={stim.mean().item():.3f}  std={stim.std().item():.3f}\"\n",
    "    \"\\nresponses:\"\n",
    "    f\"\\n  {resp.shape}\"\n",
    "    f\"\\n  min={resp.min().item():.3f}  max={resp.max().item():.3f}\"\n",
    "    f\"\\n  mean={resp.mean().item():.3f}  std={resp.std().item():.3f}\"\n",
    ")\n",
    "\n",
    "### plot sample data\n",
    "fig = plt.figure(figsize=(14, 6))\n",
    "ax = fig.add_subplot(131)\n",
    "ax.imshow(stim[sample_idx].cpu().squeeze().unsqueeze(-1), cmap=\"gray\")\n",
    "\n",
    "ax = fig.add_subplot(132)\n",
    "ax.imshow(crop(stim[sample_idx].cpu(), config[\"crop_wins\"][sample_data_key]).squeeze().unsqueeze(-1), cmap=\"gray\")\n",
    "\n",
    "ax = fig.add_subplot(133)\n",
    "to_show = resp[sample_idx].cpu()\n",
    "### pad with zeros\n",
    "if to_show.shape[-1] % (w := np.sqrt(resp[sample_idx].cpu().shape[0]).astype(int)) != 0:\n",
    "    to_show = torch.cat([to_show, torch.zeros(w - to_show.shape[-1] % w)], dim=-1)\n",
    "ax.imshow(to_show.view(w, -1).squeeze(0).unsqueeze(-1), cmap=\"gray\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "csng",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
