{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import torch\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from copy import deepcopy\n",
    "import lovely_tensors as lt\n",
    "lt.monkey_patch()\n",
    "\n",
    "from csng.utils.data import crop\n",
    "from csng.data import get_dataloaders, get_sample_data\n",
    "from csng.models.readins import MEIReadIn\n",
    "from csng.utils.mix import seed_all, update_config_paths, update_config_keys_to_value, plot_comparison\n",
    "from csng.models.utils.gan import init_decoder as init_gan_decoder\n",
    "from csng.models.utils.cnn import init_decoder as init_cnn_decoder\n",
    "from csng.models.utils.gan import train\n",
    "from csng.utils.comparison import eval_decoder\n",
    "from csng.losses import get_metrics\n",
    "from csng.brainreader_mouse.encoder import get_encoder as get_encoder_brainreader\n",
    "from csng.mouse_v1.encoder import get_encoder as get_encoder_sensorium_mouse_v1\n",
    "from csng.cat_v1.encoder import get_encoder as get_encoder_cat_v1\n",
    "\n",
    "### set paths\n",
    "DATA_PATH = os.environ[\"DATA_PATH\"]\n",
    "DATA_PATH_CAT_V1 = os.path.join(DATA_PATH, \"cat_V1_spiking_model\", \"50K_single_trial_dataset\")\n",
    "DATA_PATH_MOUSE_V1 = os.path.join(DATA_PATH, \"mouse_v1_sensorium22\")\n",
    "DATA_PATH_BRAINREADER = os.path.join(DATA_PATH, \"brainreader\")\n",
    "print(f\"{DATA_PATH=}\\n{DATA_PATH_CAT_V1=}\\n{DATA_PATH_MOUSE_V1=}\\n{DATA_PATH_BRAINREADER=}\")\n",
    "\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### setup config\n",
    "config = {\n",
    "    \"device\": os.environ[\"DEVICE\"],\n",
    "    \"seed\": 0,\n",
    "    \"data\": {\"mixing_strategy\": \"sequential\"},\n",
    "    \"crop_wins\": {\"cat_v1\": (20, 20), \"mouse_v1\": (22, 36), \"brainreader_mouse\": (36, 64)},\n",
    "}\n",
    "\n",
    "print(f\"... Running on {config['device']} ...\")\n",
    "seed_all(config[\"seed\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load source dataset(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### prep data config\n",
    "# brainreader mouse data\n",
    "config[\"data\"][\"brainreader_mouse\"] = {\n",
    "    \"device\": config[\"device\"],\n",
    "    \"mixing_strategy\": config[\"data\"][\"mixing_strategy\"],\n",
    "    \"max_batches\": None,\n",
    "    \"data_dir\": os.path.join(DATA_PATH_BRAINREADER, \"data\"),\n",
    "    \"batch_size\": 8,\n",
    "    # \"sessions\": list(range(1, 7)),\n",
    "    \"sessions\": [6],\n",
    "    \"resize_stim_to\": (36, 64),\n",
    "    \"normalize_stim\": True,\n",
    "    \"normalize_resp\": False,\n",
    "    \"div_resp_by_std\": True,\n",
    "    \"clamp_neg_resp\": False,\n",
    "    \"additional_keys\": None,\n",
    "    \"avg_test_resp\": True,\n",
    "    \"train_datapoint_idxs_to_use\": None,\n",
    "    # \"train_datapoint_idxs_to_use\": np.random.default_rng(seed=config[\"seed\"]).choice(4500, size=int(4500 * 0.5), replace=False),\n",
    "}\n",
    "\n",
    "### cat v1 data\n",
    "# config[\"data\"][\"cat_v1\"] = {\n",
    "#     \"dataset_config\": {\n",
    "#         \"train_path\": os.path.join(DATA_PATH_CAT_V1, \"datasets\", \"train\"),\n",
    "#         \"val_path\": os.path.join(DATA_PATH_CAT_V1, \"datasets\", \"val\"),\n",
    "#         \"test_path\": os.path.join(DATA_PATH_CAT_V1, \"datasets\", \"test\"),\n",
    "#         \"image_size\": [50, 50],\n",
    "#         \"crop\": False,\n",
    "#         \"batch_size\": 4,\n",
    "#         \"stim_keys\": (\"stim\",),\n",
    "#         \"resp_keys\": (\"exc_resp\", \"inh_resp\"),\n",
    "#         \"return_coords\": True,\n",
    "#         \"return_ori\": False,\n",
    "#         \"coords_ori_filepath\": os.path.join(DATA_PATH_CAT_V1, \"pos_and_ori.pkl\"),\n",
    "#         \"cached\": False,\n",
    "#         \"stim_normalize_mean\": 46.143,\n",
    "#         \"stim_normalize_std\": 24.960,\n",
    "#         # \"resp_normalize_mean\": None, # don't center responses\n",
    "#         \"resp_normalize_std\": torch.load(\n",
    "#             os.path.join(DATA_PATH_CAT_V1, \"responses_std.pt\")\n",
    "#         ),\n",
    "#         \"clamp_neg_resp\": False,\n",
    "#     },\n",
    "# }\n",
    "\n",
    "# # mouse v1 data\n",
    "# config[\"data\"][\"mouse_v1\"] = {\n",
    "#     \"dataset_fn\": \"sensorium.datasets.static_loaders\",\n",
    "#     \"dataset_config\": {\n",
    "#         \"paths\": [ # from https://gin.g-node.org/cajal/Sensorium2022/src/master\n",
    "#             os.path.join(DATA_PATH_MOUSE_V1, \"static21067-10-18-GrayImageNet-94c6ff995dac583098847cfecd43e7b6.zip\"), # M-1\n",
    "#             # os.path.join(DATA_PATH_MOUSE_V1, \"static22846-10-16-GrayImageNet-94c6ff995dac583098847cfecd43e7b6.zip\"), # M-2\n",
    "#             # os.path.join(DATA_PATH_MOUSE_V1, \"static23343-5-17-GrayImageNet-94c6ff995dac583098847cfecd43e7b6.zip\"), # M-3\n",
    "#             # os.path.join(DATA_PATH_MOUSE_V1, \"static23656-14-22-GrayImageNet-94c6ff995dac583098847cfecd43e7b6.zip\"), # M-4\n",
    "#             # os.path.join(DATA_PATH_MOUSE_V1, \"static23964-4-22-GrayImageNet-94c6ff995dac583098847cfecd43e7b6.zip\"), # M-5\n",
    "#         ],\n",
    "#         \"normalize\": True,\n",
    "#         \"z_score_responses\": False,\n",
    "#         \"scale\": 0.25, # 256x144 -> 64x36\n",
    "#         \"include_behavior\": False,\n",
    "#         \"add_behavior_as_channels\": False,\n",
    "#         \"include_eye_position\": True,\n",
    "#         \"exclude\": None,\n",
    "#         \"file_tree\": True,\n",
    "#         \"cuda\": \"cuda\" in config[\"device\"],\n",
    "#         # \"batch_size\": 5,\n",
    "#         \"batch_size\": 16,\n",
    "#         \"drop_last\": True,\n",
    "#         \"use_cache\": False,\n",
    "#         \"train_datapoint_idxs_to_use\": None,\n",
    "#         # \"train_datapoint_idxs_to_use\": np.random.default_rng(seed=config[\"seed\"]).choice(4473, size=int(4473 * 0.5), replace=False),\n",
    "#     },\n",
    "#     \"crop_win\": (22, 36),\n",
    "#     \"skip_train\": False,\n",
    "#     \"skip_val\": False,\n",
    "#     \"skip_test\": False,\n",
    "#     \"normalize_neuron_coords\": True,\n",
    "#     \"average_test_multitrial\": True,\n",
    "#     \"save_test_multitrial\": True,\n",
    "#     \"test_batch_size\": 7,\n",
    "#     \"neuron_coords_to_use\": None, # if None, uses the neuron coordinates from the dataset\n",
    "#     \"device\": config[\"device\"],\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls, neuron_coords = get_dataloaders(config)\n",
    "for tier, data_dict in dls.items():\n",
    "    print(f\"{tier}:\")\n",
    "    for data_name, dl in data_dict.items():\n",
    "        print(f\"  {data_name}: {len(dl)} batches\")\n",
    "        print(f\"    data keys: {', '.join(dl.data_keys)}\")\n",
    "        print(f\"    size of datasets: {', '.join([str(len(dl) * _dl.batch_size) for _dl in dl.dataloaders])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### get sample data\n",
    "s = get_sample_data(dls=dls, config=config, sample_from_tier=\"val\")\n",
    "resp, stim, sample_dataset, sample_data_key = s[\"resp\"], s[\"stim\"], s[\"sample_dataset\"], s[\"sample_data_key\"]\n",
    "print(f\"{sample_dataset=}, {sample_data_key=}, {resp.shape=}, {stim.shape=}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Decoding models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inverted Encoder (InvEnc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### load encoder\n",
    "encoder = get_encoder_brainreader(\n",
    "    ckpt_path=os.path.join(DATA_PATH, \"models\", \"encoder_b6.pt\"),\n",
    "    eval_mode=True,\n",
    "    device=config[\"device\"],\n",
    ")\n",
    "encoder.training = False\n",
    "encoder.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generative Adversarial Network (GAN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### config for model to load\n",
    "config[\"decoder\"] = {\n",
    "    \"load_ckpt\": {\n",
    "        \"ckpt_path\": os.path.join(\n",
    "            DATA_PATH,\n",
    "            \"models\",\n",
    "            \"gan\",\n",
    "            \"2025-02-27_18-49-52\",\n",
    "            \"decoder.pt\",\n",
    "        ),\n",
    "        \"load_only_core\": False, # set to True if you want to keep only the core and reset the readins\n",
    "        \"load_best\": True, # load best model (val. loss during pretraining)\n",
    "        \"load_opter_state\": False, # don't load optimizer state for fine-tuning\n",
    "        \"load_history\": False, # reset training history for fine-tuning\n",
    "        \"reset_best\": True, # reset best-model tracking for fine-tuning\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### utility functions\n",
    "def merge_configs_fn(cfg, ckpt_cfg):\n",
    "    \"\"\" Utility function for mergins config from checkpoint (ckpt_cfg) with the current config \"\"\"\n",
    "    ckpt_cfg[\"decoder\"][\"load_ckpt\"] = cfg[\"decoder\"][\"load_ckpt\"]\n",
    "    ckpt_cfg = update_config_keys_to_value(ckpt_cfg, \"device\", cfg[\"device\"])\n",
    "    cfg = ckpt_cfg\n",
    "    cfg = update_config_paths(config=cfg, new_data_path=DATA_PATH)\n",
    "    return cfg, ckpt_cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### load model\n",
    "cfg, gan, loss_fn, history, best, ckpt = init_gan_decoder(config=config, merge_configs_fn=merge_configs_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combined Inverted Encoder and Generative Adversarial Network (InvEnc-GAN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision.transforms import GaussianBlur\n",
    "import featurevis\n",
    "from featurevis import ops\n",
    "from featurevis import utils as fvutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gan_resp_loss_fn(resp_pred, resp, x_hat, data_key=None, neuron_coords=None, pupil_center=None):\n",
    "    # stim_pred_from_resp_pred = decoder(resp_pred, data_key=data_key, neuron_coords=neuron_coords, pupil_center=pupil_center)\n",
    "    # stim_pred_from_resp_gt = decoder(resp, data_key=data_key, neuron_coords=neuron_coords, pupil_center=pupil_center)\n",
    "    return decoder(resp_pred, data_key=data_key, neuron_coords=neuron_coords, pupil_center=pupil_center)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InvertedEncoderDecoder(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        encoder,\n",
    "        decoder,\n",
    "        img_dims=(1, 36, 64),\n",
    "        stim_pred_init=\"zeros\",\n",
    "        opter_cls=torch.optim.SGD,\n",
    "        opter_config={\"lr\": 50},\n",
    "        n_steps=1000,\n",
    "        resp_loss_fn=lambda resp_pred, resp_target: F.mse_loss(resp_pred, resp_target, reduction=\"none\").mean(-1).sum(),\n",
    "        stim_loss_fn=lambda stim_pred, stim_target: F.mse_loss(stim_pred, stim_target, reduction=\"none\").mean((-1, -2, -3)).sum(),\n",
    "        img_gauss_blur_config=None,\n",
    "        img_gauss_blur_freq=1,\n",
    "        img_grad_gauss_blur_config=None,\n",
    "        img_grad_gauss_blur_freq=1,\n",
    "        device=\"cpu\",\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder.requires_grad_(False)\n",
    "        self.encoder.training = False\n",
    "        self.encoder.eval()\n",
    "\n",
    "        self.decoder = decoder.requires_grad_(False)\n",
    "        self.decoder.training = False\n",
    "        self.decoder.eval()\n",
    "\n",
    "        self.stim_pred_init = stim_pred_init\n",
    "        self.img_dims = img_dims\n",
    "        self.opter_cls = opter_cls\n",
    "        self.opter_config = opter_config\n",
    "        self.n_steps = n_steps\n",
    "        self.resp_loss_fn = resp_loss_fn\n",
    "        self.stim_loss_fn = stim_loss_fn\n",
    "        \n",
    "        self.img_gauss_blur_config = img_gauss_blur_config\n",
    "        self.img_gauss_blur_freq = img_gauss_blur_freq\n",
    "        self.img_gauss_blur = None if img_gauss_blur_config is None else GaussianBlur(**img_gauss_blur_config)\n",
    "        self.img_grad_gauss_blur_config = img_grad_gauss_blur_config\n",
    "        self.img_grad_gauss_blur_freq = img_grad_gauss_blur_freq\n",
    "        self.img_grad_gauss_blur = None if img_grad_gauss_blur_config is None else GaussianBlur(**img_grad_gauss_blur_config)\n",
    "\n",
    "        self.resp_pred = None\n",
    "        self.history = None\n",
    "\n",
    "        self.device = device\n",
    "\n",
    "    def _init_x_hat(self, B, resp=None, data_key=None, neuron_coords=None, pupil_center=None):\n",
    "        ### init decoded img\n",
    "        if self.stim_pred_init == \"zeros\":\n",
    "            x_hat = torch.zeros((B, *self.img_dims), requires_grad=True, device=self.device)\n",
    "        elif self.stim_pred_init == \"rand\":\n",
    "            x_hat = torch.rand((B, *self.img_dims), requires_grad=True, device=self.device)\n",
    "        elif self.stim_pred_init == \"randn\":\n",
    "            x_hat = torch.randn((B, *self.img_dims), requires_grad=True, device=self.device)\n",
    "        elif self.stim_pred_init == \"decoder\":\n",
    "            x_hat = self.decoder(resp, data_key=data_key, neuron_coords=neuron_coords, pupil_center=pupil_center)\n",
    "            x_hat = x_hat.detach().clone().requires_grad_(True)\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown stim_pred_init: {self.stim_pred_init}\")\n",
    "        return x_hat\n",
    "\n",
    "    def forward(self, resp, data_key=None, neuron_coords=None, pupil_center=None, ckpt_config=None, stim_target=None):\n",
    "        assert resp.ndim > 1, \"resp should be at least 2d (batch_dim, neurons_dim)\"\n",
    "\n",
    "        ### init decoded img\n",
    "        x_hat = self._init_x_hat(resp.size(0) if resp.ndim > 1 else 1, resp=resp, data_key=data_key, neuron_coords=neuron_coords, pupil_center=pupil_center)\n",
    "\n",
    "        ### optimize decoded img\n",
    "        opter = self.opter_cls([x_hat], **self.opter_config)\n",
    "        history = {\"resp_loss\": [], \"stim_loss\": [], \"best\": {\"stim_loss\": np.inf, \"stim_pred\": None}}\n",
    "        for step_i in range(self.n_steps):\n",
    "            opter.zero_grad()\n",
    "\n",
    "            resp_pred = self.encoder(x_hat, data_key=data_key, pupil_center=pupil_center)\n",
    "            resp_loss = self.resp_loss_fn(resp_pred, resp)\n",
    "\n",
    "            # stim_pred_from_resp_pred = self.decoder(resp_pred, data_key=data_key, neuron_coords=neuron_coords, pupil_center=pupil_center)\n",
    "            stim_pred_from_resp_gt = self.decoder(resp, data_key=data_key, neuron_coords=neuron_coords, pupil_center=pupil_center)\n",
    "            stim_loss = 5e-3 * self.stim_loss_fn(stim_pred_from_resp_gt, x_hat)\n",
    "\n",
    "            resp_loss.backward()\n",
    "\n",
    "            ### apply gaussian blur to gradients\n",
    "            if self.img_grad_gauss_blur is not None and step_i % self.img_grad_gauss_blur_freq == 0:\n",
    "                x_hat.grad = self.img_grad_gauss_blur(x_hat.grad)\n",
    "\n",
    "            ### update\n",
    "            opter.step()\n",
    "            if stim_target is not None:\n",
    "                stim_loss = self.stim_loss_fn(x_hat.detach(), stim_target)\n",
    "                history[\"stim_loss\"].append(stim_loss.item())\n",
    "                if stim_loss.item() < history[\"best\"][\"stim_loss\"]:\n",
    "                    history[\"best\"][\"stim_loss\"] = stim_loss.item()\n",
    "                    history[\"best\"][\"stim_pred\"] = x_hat.detach().clone()\n",
    "\n",
    "            ### apply gaussian blur to image\n",
    "            if self.img_gauss_blur is not None and step_i % self.img_gauss_blur_freq == 0:\n",
    "                with torch.no_grad():\n",
    "                    x_hat.data = self.img_gauss_blur(x_hat)\n",
    "\n",
    "            ### log\n",
    "            history[\"resp_loss\"].append(resp_loss.item())\n",
    "\n",
    "            ### ckpt\n",
    "            if ckpt_config is not None and step_i % ckpt_config[\"ckpt_freq\"] == 0:\n",
    "                curr_ckpt_dir = os.path.join(ckpt_config[\"ckpt_dir\"], str(step_i))\n",
    "                os.makedirs(curr_ckpt_dir)\n",
    "                torch.save({\n",
    "                    \"reconstruction\": x_hat,\n",
    "                    \"history\": history,\n",
    "                    \"opter_state\": opter.state_dict(),\n",
    "                }, os.path.join(curr_ckpt_dir, \"ckpt.pt\"), pickle_module=dill)\n",
    "                if ckpt_config.get(\"plot_fn\", None) is not None:\n",
    "                    ckpt_config[\"plot_fn\"](target=stim_target, pred=x_hat, save_to=os.path.join(curr_ckpt_dir, f\"stim_pred.png\"))\n",
    "\n",
    "        self.resp_pred = resp_pred.detach()\n",
    "        self.history = history\n",
    "        return x_hat.detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _lr in [5, 50, 150]:\n",
    "    for _n_steps in [100, 800, 2000]:\n",
    "        inv_enc_dec = InvertedEncoderDecoder(\n",
    "            encoder=encoder,\n",
    "            decoder=gan,\n",
    "            **{\n",
    "                \"img_dims\": (1, 36, 64),\n",
    "                \"stim_pred_init\": \"zeros\",\n",
    "                \"opter_config\": {\"lr\": _lr},\n",
    "                \"n_steps\": _n_steps,\n",
    "                \"img_grad_gauss_blur_config\": {\"kernel_size\": 13, \"sigma\": 1.},\n",
    "                \"device\": config[\"device\"],\n",
    "            },\n",
    "        )\n",
    "        stim_pred = inv_enc_dec(\n",
    "            resp.to(config[\"device\"]),\n",
    "            data_key=sample_data_key,\n",
    "            neuron_coords=neuron_coords[sample_dataset],\n",
    "            pupil_center=None,\n",
    "        ) # (batch, n_channels, h, w)\n",
    "\n",
    "        ### show comparison\n",
    "        print(f\"{_lr=}, {_n_steps=}\")\n",
    "        fig = plot_comparison(\n",
    "            target=crop(stim[:8], config[\"crop_wins\"][sample_dataset]).cpu(),\n",
    "            pred=crop(stim_pred[:8], config[\"crop_wins\"][sample_dataset]).cpu(),\n",
    "            show=True,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inv_enc_dec = InvertedEncoderDecoder(\n",
    "    encoder=encoder,\n",
    "    decoder=gan,\n",
    "    **{\n",
    "        \"img_dims\": (1, 36, 64),\n",
    "        \"stim_pred_init\": \"zeros\",\n",
    "        \"opter_config\": {\"lr\": 50},\n",
    "        \"n_steps\": 1000,\n",
    "        \"img_grad_gauss_blur_config\": {\"kernel_size\": 13, \"sigma\": 1},\n",
    "        \"device\": config[\"device\"],\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stim_pred = inv_enc_dec(\n",
    "    resp.to(config[\"device\"]),\n",
    "    data_key=sample_data_key,\n",
    "    neuron_coords=neuron_coords[sample_dataset],\n",
    "    pupil_center=None,\n",
    ") # (batch, n_channels, h, w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### show comparison\n",
    "fig = plot_comparison(\n",
    "    target=crop(stim[:8], config[\"crop_wins\"][sample_dataset]).cpu(),\n",
    "    pred=crop(stim_pred[:8], config[\"crop_wins\"][sample_dataset]).cpu(),\n",
    "    show=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### show comparison\n",
    "fig = plot_comparison(\n",
    "    target=crop(stim[:8], config[\"crop_wins\"][sample_dataset]).cpu(),\n",
    "    pred=crop(stim_pred[:8], config[\"crop_wins\"][sample_dataset]).cpu(),\n",
    "    show=True,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
