[NbConvertApp] Converting notebook csng/brainreader_mouse/resnet_inversion.ipynb to notebook
Traceback (most recent call last):
  File "/home/vanousek/miniconda3/envs/csng/bin/jupyter-nbconvert", line 11, in <module>
    sys.exit(main())
  File "/home/vanousek/miniconda3/envs/csng/lib/python3.10/site-packages/jupyter_core/application.py", line 283, in launch_instance
    super().launch_instance(argv=argv, **kwargs)
  File "/home/vanousek/miniconda3/envs/csng/lib/python3.10/site-packages/traitlets/config/application.py", line 1075, in launch_instance
    app.start()
  File "/home/vanousek/miniconda3/envs/csng/lib/python3.10/site-packages/nbconvert/nbconvertapp.py", line 420, in start
    self.convert_notebooks()
  File "/home/vanousek/miniconda3/envs/csng/lib/python3.10/site-packages/nbconvert/nbconvertapp.py", line 597, in convert_notebooks
    self.convert_single_notebook(notebook_filename)
  File "/home/vanousek/miniconda3/envs/csng/lib/python3.10/site-packages/nbconvert/nbconvertapp.py", line 563, in convert_single_notebook
    output, resources = self.export_single_notebook(
  File "/home/vanousek/miniconda3/envs/csng/lib/python3.10/site-packages/nbconvert/nbconvertapp.py", line 487, in export_single_notebook
    output, resources = self.exporter.from_filename(
  File "/home/vanousek/miniconda3/envs/csng/lib/python3.10/site-packages/nbconvert/exporters/exporter.py", line 201, in from_filename
    return self.from_file(f, resources=resources, **kw)
  File "/home/vanousek/miniconda3/envs/csng/lib/python3.10/site-packages/nbconvert/exporters/exporter.py", line 220, in from_file
    return self.from_notebook_node(
  File "/home/vanousek/miniconda3/envs/csng/lib/python3.10/site-packages/nbconvert/exporters/notebook.py", line 36, in from_notebook_node
    nb_copy, resources = super().from_notebook_node(nb, resources, **kw)
  File "/home/vanousek/miniconda3/envs/csng/lib/python3.10/site-packages/nbconvert/exporters/exporter.py", line 154, in from_notebook_node
    nb_copy, resources = self._preprocess(nb_copy, resources)
  File "/home/vanousek/miniconda3/envs/csng/lib/python3.10/site-packages/nbconvert/exporters/exporter.py", line 353, in _preprocess
    nbc, resc = preprocessor(nbc, resc)
  File "/home/vanousek/miniconda3/envs/csng/lib/python3.10/site-packages/nbconvert/preprocessors/base.py", line 48, in __call__
    return self.preprocess(nb, resources)
  File "/home/vanousek/miniconda3/envs/csng/lib/python3.10/site-packages/nbconvert/preprocessors/execute.py", line 103, in preprocess
    self.preprocess_cell(cell, resources, index)
  File "/home/vanousek/miniconda3/envs/csng/lib/python3.10/site-packages/nbconvert/preprocessors/execute.py", line 124, in preprocess_cell
    cell = self.execute_cell(cell, index, store_history=True)
  File "/home/vanousek/miniconda3/envs/csng/lib/python3.10/site-packages/jupyter_core/utils/__init__.py", line 165, in wrapped
    return loop.run_until_complete(inner)
  File "/home/vanousek/miniconda3/envs/csng/lib/python3.10/asyncio/base_events.py", line 649, in run_until_complete
    return future.result()
  File "/home/vanousek/miniconda3/envs/csng/lib/python3.10/site-packages/nbclient/client.py", line 1058, in async_execute_cell
    await self._check_raise_for_error(cell, cell_index, exec_reply)
  File "/home/vanousek/miniconda3/envs/csng/lib/python3.10/site-packages/nbclient/client.py", line 914, in _check_raise_for_error
    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)
nbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:
------------------

device = os.environ["DEVICE"]
utils = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_convnets_processing_utils', )

DATA_DIR = os.environ['DATA_PATH']
CACHE_DIR = join(DATA_DIR, 'imagenet_inversion')
RESNET_SIZE = 224
TARGET_CROP = torchvision.transforms.CenterCrop((36, 64))

class CachedImageNet(ImageNet):
    def __init__(self, root, split, transform=None, feature_extractor=None, version='0.1'):
        super().__init__(root=root, split=split, transform=transform)
        self.feature_extractor = feature_extractor  # Function to extract features
        self.cache_dir = os.path.join(CACHE_DIR, version, split)

        # Create cache directory if it doesn't exist
        os.makedirs(self.cache_dir, exist_ok=True)
        self.resnet50 = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_resnet50', pretrained=True)
        self.resnet50.eval().to(device)
        self.resnet_layer = self.resnet50.layers[2][0].downsample[0]


    def _get_cache_path(self, index):
        """Get the path for the cached feature."""
        return os.path.join(self.cache_dir, f'feature_{index}.pt')

    def __getitem__(self, index):
        # Load the image and label
        img, object_class = super().__getitem__(index)

        # Cache file path
        cache_path = self._get_cache_path(index)

        # Load feature from cache if it exists

        img = img.unsqueeze(0)  # Add batch dimension
        grayscale_img_rgb = F.rgb_to_grayscale(img, num_output_channels=3).to(device)
        features_path = os.path.join(self.cache_dir, f'feature_{index}.pt')

        if os.path.exists(cache_path):
            saved_features = torch.load(cache_path).to(device)
            if random() < 0.01: # check if the cache is correct
                features = None
                def assign_features(module, input, output):
                    nonlocal features
                    features = output
                hook = self.resnet_layer.register_forward_hook(assign_features)
                
                with torch.no_grad():
                    self.resnet50(grayscale_img_rgb)
                hook.remove()
                assert features is not None
                features = features.squeeze(0)

                assert torch.equal(saved_features, features)
            features = saved_features

        else:
            # Compute feature if not cached

            features = None
            def assign_features(module, input, output):
                nonlocal features
                features = output
            hook = self.resnet_layer.register_forward_hook(assign_features)
            
            with torch.no_grad():
                self.resnet50(grayscale_img_rgb)
            hook.remove()
            assert features is not None
            features = features.squeeze(0)

            torch.save(features, cache_path)  # Save to cache
        
        # center crop
        target = TARGET_CROP(F.rgb_to_grayscale(img, num_output_channels=1))
        return grayscale_img_rgb, features, target
# Image transformations
train_transforms = transforms.Compose([
    transforms.CenterCrop(224),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
])

# Example feature extractor: compute mean/std per channel

def feature_extractor(img):
    img_np = np.array(img)
    mean = np.mean(img_np, axis=(0, 1))
    std = np.std(img_np, axis=(0, 1))
    return torch.tensor(np.concatenate([mean, std]))
# Dataset path


# Set the start method to 'spawn'
mp.set_start_method('spawn', force=True)
# Initialize CachedImageNet
train_dataset = CachedImageNet(
    root=join(DATA_DIR, 'imagenet'),
    split='train',
    transform=train_transforms,
    feature_extractor=feature_extractor,
    version='0.6'
)

from torch.utils.data import random_split, DataLoader
# Define the image limit
IMG_LIMIT = 20_000  # Replace with your desired image limit

# Define the split sizes
train_size = int(0.95 * min(len(train_dataset), IMG_LIMIT))  # Limit train size to IMG_LIMIT
test_size = min(len(train_dataset), IMG_LIMIT) - train_size  # Limit test size accordingly

print("Train size:", train_size)
print("Test size:", test_size)

# Split the dataset within the limit
train_subset_indices = list(range(train_size))  # Indices for the training subset
test_subset_indices = list(range(train_size, train_size + test_size))  # Indices for the test subset

# Create the subsets
train_subset = Subset(train_dataset, train_subset_indices)
test_subset = Subset(train_dataset, test_subset_indices)

# Define the batch size
batch_size = 256

# Create DataLoaders for train and test
train_loader = DataLoader(
    dataset=train_subset,
    batch_size=batch_size,
    shuffle=False,  # Shuffle can be enabled based on your training needs
    num_workers=0
)

test_loader = DataLoader(
    dataset=test_subset,
    batch_size=batch_size,
    shuffle=False,  # No need to shuffle test data
    num_workers=0
)

print(f"Train loader contains {len(train_loader)} batches.")
print(f"Test loader contains {len(test_loader)} batches.")

------------------

----- stderr -----
Using cache found in /home/vanousek/.cache/torch/hub/NVIDIA_DeepLearningExamples_torchhub
/home/vanousek/.cache/torch/hub/NVIDIA_DeepLearningExamples_torchhub/PyTorch/Classification/ConvNets/image_classification/models/common.py:13: UserWarning: pytorch_quantization module not found, quantization will not be available
  warnings.warn(
/home/vanousek/.cache/torch/hub/NVIDIA_DeepLearningExamples_torchhub/PyTorch/Classification/ConvNets/image_classification/models/efficientnet.py:17: UserWarning: pytorch_quantization module not found, quantization will not be available
  warnings.warn(
------------------

[0;31m---------------------------------------------------------------------------[0m
[0;31mRuntimeError[0m                              Traceback (most recent call last)
Cell [0;32mIn[2], line 97[0m
[1;32m     95[0m mp[38;5;241m.[39mset_start_method([38;5;124m'[39m[38;5;124mspawn[39m[38;5;124m'[39m, force[38;5;241m=[39m[38;5;28;01mTrue[39;00m)
[1;32m     96[0m [38;5;66;03m# Initialize CachedImageNet[39;00m
[0;32m---> 97[0m train_dataset [38;5;241m=[39m [43mCachedImageNet[49m[43m([49m
[1;32m     98[0m [43m    [49m[43mroot[49m[38;5;241;43m=[39;49m[43mjoin[49m[43m([49m[43mDATA_DIR[49m[43m,[49m[43m [49m[38;5;124;43m'[39;49m[38;5;124;43mimagenet[39;49m[38;5;124;43m'[39;49m[43m)[49m[43m,[49m
[1;32m     99[0m [43m    [49m[43msplit[49m[38;5;241;43m=[39;49m[38;5;124;43m'[39;49m[38;5;124;43mtrain[39;49m[38;5;124;43m'[39;49m[43m,[49m
[1;32m    100[0m [43m    [49m[43mtransform[49m[38;5;241;43m=[39;49m[43mtrain_transforms[49m[43m,[49m
[1;32m    101[0m [43m    [49m[43mfeature_extractor[49m[38;5;241;43m=[39;49m[43mfeature_extractor[49m[43m,[49m
[1;32m    102[0m [43m    [49m[43mversion[49m[38;5;241;43m=[39;49m[38;5;124;43m'[39;49m[38;5;124;43m0.6[39;49m[38;5;124;43m'[39;49m
[1;32m    103[0m [43m)[49m
[1;32m    105[0m [38;5;28;01mfrom[39;00m [38;5;21;01mtorch[39;00m[38;5;21;01m.[39;00m[38;5;21;01mutils[39;00m[38;5;21;01m.[39;00m[38;5;21;01mdata[39;00m [38;5;28;01mimport[39;00m random_split, DataLoader
[1;32m    106[0m [38;5;66;03m# Define the image limit[39;00m

Cell [0;32mIn[2], line 11[0m, in [0;36mCachedImageNet.__init__[0;34m(self, root, split, transform, feature_extractor, version)[0m
[1;32m     10[0m [38;5;28;01mdef[39;00m [38;5;21m__init__[39m([38;5;28mself[39m, root, split, transform[38;5;241m=[39m[38;5;28;01mNone[39;00m, feature_extractor[38;5;241m=[39m[38;5;28;01mNone[39;00m, version[38;5;241m=[39m[38;5;124m'[39m[38;5;124m0.1[39m[38;5;124m'[39m):
[0;32m---> 11[0m     [38;5;28;43msuper[39;49m[43m([49m[43m)[49m[38;5;241;43m.[39;49m[38;5;21;43m__init__[39;49m[43m([49m[43mroot[49m[38;5;241;43m=[39;49m[43mroot[49m[43m,[49m[43m [49m[43msplit[49m[38;5;241;43m=[39;49m[43msplit[49m[43m,[49m[43m [49m[43mtransform[49m[38;5;241;43m=[39;49m[43mtransform[49m[43m)[49m
[1;32m     12[0m     [38;5;28mself[39m[38;5;241m.[39mfeature_extractor [38;5;241m=[39m feature_extractor  [38;5;66;03m# Function to extract features[39;00m
[1;32m     13[0m     [38;5;28mself[39m[38;5;241m.[39mcache_dir [38;5;241m=[39m os[38;5;241m.[39mpath[38;5;241m.[39mjoin(CACHE_DIR, version, split)

File [0;32m~/miniconda3/envs/csng/lib/python3.10/site-packages/torchvision/datasets/imagenet.py:52[0m, in [0;36mImageNet.__init__[0;34m(self, root, split, **kwargs)[0m
[1;32m     49[0m root [38;5;241m=[39m [38;5;28mself[39m[38;5;241m.[39mroot [38;5;241m=[39m os[38;5;241m.[39mpath[38;5;241m.[39mexpanduser(root)
[1;32m     50[0m [38;5;28mself[39m[38;5;241m.[39msplit [38;5;241m=[39m verify_str_arg(split, [38;5;124m"[39m[38;5;124msplit[39m[38;5;124m"[39m, ([38;5;124m"[39m[38;5;124mtrain[39m[38;5;124m"[39m, [38;5;124m"[39m[38;5;124mval[39m[38;5;124m"[39m))
[0;32m---> 52[0m [38;5;28;43mself[39;49m[38;5;241;43m.[39;49m[43mparse_archives[49m[43m([49m[43m)[49m
[1;32m     53[0m wnid_to_classes [38;5;241m=[39m load_meta_file([38;5;28mself[39m[38;5;241m.[39mroot)[[38;5;241m0[39m]
[1;32m     55[0m [38;5;28msuper[39m()[38;5;241m.[39m[38;5;21m__init__[39m([38;5;28mself[39m[38;5;241m.[39msplit_folder, [38;5;241m*[39m[38;5;241m*[39mkwargs)

File [0;32m~/miniconda3/envs/csng/lib/python3.10/site-packages/torchvision/datasets/imagenet.py:69[0m, in [0;36mImageNet.parse_archives[0;34m(self)[0m
[1;32m     67[0m [38;5;28;01mif[39;00m [38;5;129;01mnot[39;00m os[38;5;241m.[39mpath[38;5;241m.[39misdir([38;5;28mself[39m[38;5;241m.[39msplit_folder):
[1;32m     68[0m     [38;5;28;01mif[39;00m [38;5;28mself[39m[38;5;241m.[39msplit [38;5;241m==[39m [38;5;124m"[39m[38;5;124mtrain[39m[38;5;124m"[39m:
[0;32m---> 69[0m         [43mparse_train_archive[49m[43m([49m[38;5;28;43mself[39;49m[38;5;241;43m.[39;49m[43mroot[49m[43m)[49m
[1;32m     70[0m     [38;5;28;01melif[39;00m [38;5;28mself[39m[38;5;241m.[39msplit [38;5;241m==[39m [38;5;124m"[39m[38;5;124mval[39m[38;5;124m"[39m:
[1;32m     71[0m         parse_val_archive([38;5;28mself[39m[38;5;241m.[39mroot)

File [0;32m~/miniconda3/envs/csng/lib/python3.10/site-packages/torchvision/datasets/imagenet.py:175[0m, in [0;36mparse_train_archive[0;34m(root, file, folder)[0m
[1;32m    172[0m     file [38;5;241m=[39m archive_meta[[38;5;241m0[39m]
[1;32m    173[0m md5 [38;5;241m=[39m archive_meta[[38;5;241m1[39m]
[0;32m--> 175[0m [43m_verify_archive[49m[43m([49m[43mroot[49m[43m,[49m[43m [49m[43mfile[49m[43m,[49m[43m [49m[43mmd5[49m[43m)[49m
[1;32m    177[0m train_root [38;5;241m=[39m os[38;5;241m.[39mpath[38;5;241m.[39mjoin(root, folder)
[1;32m    178[0m extract_archive(os[38;5;241m.[39mpath[38;5;241m.[39mjoin(root, file), train_root)

File [0;32m~/miniconda3/envs/csng/lib/python3.10/site-packages/torchvision/datasets/imagenet.py:102[0m, in [0;36m_verify_archive[0;34m(root, file, md5)[0m
[1;32m     97[0m [38;5;28;01mif[39;00m [38;5;129;01mnot[39;00m check_integrity(os[38;5;241m.[39mpath[38;5;241m.[39mjoin(root, file), md5):
[1;32m     98[0m     msg [38;5;241m=[39m (
[1;32m     99[0m         [38;5;124m"[39m[38;5;124mThe archive [39m[38;5;132;01m{}[39;00m[38;5;124m is not present in the root directory or is corrupted. [39m[38;5;124m"[39m
[1;32m    100[0m         [38;5;124m"[39m[38;5;124mYou need to download it externally and place it in [39m[38;5;132;01m{}[39;00m[38;5;124m.[39m[38;5;124m"[39m
[1;32m    101[0m     )
[0;32m--> 102[0m     [38;5;28;01mraise[39;00m [38;5;167;01mRuntimeError[39;00m(msg[38;5;241m.[39mformat(file, root))

[0;31mRuntimeError[0m: The archive ILSVRC2012_img_train.tar is not present in the root directory or is corrupted. You need to download it externally and place it in /scratch/izar/vanousek/cs-433-project/data/imagenet.

