{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b0f0f4f3",
   "metadata": {},
   "source": [
    "# Import packages & functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5bad764b-45c1-45ce-a716-8d055e09821a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sobotka/miniconda3/envs/mindeye/lib/python3.11/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n",
      "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.layers\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATA_PATH_BRAINREADER='/scratch/izar/sobotka/csng/brainreader'\n",
      "DATA_PATH_MINDEYE='/scratch/izar/sobotka/csng/mindeye'\n",
      "DATA_PATH_MINDEYE_CACHE='/scratch/izar/sobotka/csng/mindeye/cache'\n",
      "Fri Feb 21 15:27:32 2025       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.154.05             Driver Version: 535.154.05   CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  Tesla V100-PCIE-32GB           On  | 00000000:D8:00.0 Off |                  Off |\n",
      "| N/A   34C    P0              23W / 250W |      0MiB / 32768MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|  No running processes found                                                           |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import argparse\n",
    "import numpy as np\n",
    "import math\n",
    "from einops import rearrange\n",
    "import time\n",
    "import random\n",
    "import string\n",
    "import h5py\n",
    "from tqdm import tqdm\n",
    "import webdataset as wds\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "from accelerate import Accelerator\n",
    "\n",
    "# SDXL unCLIP requires code from https://github.com/Stability-AI/generative-models/tree/main\n",
    "import sgm\n",
    "from pkgs.MindEyeV2.src.generative_models.sgm.modules.encoders.modules import FrozenOpenCLIPImageEmbedder # bigG embedder\n",
    "\n",
    "# tf32 data type is faster than standard float32\n",
    "torch.backends.cuda.matmul.allow_tf32 = True\n",
    "\n",
    "# custom functions #\n",
    "import pkgs.MindEyeV2.src.utils as utils\n",
    "\n",
    "import lovely_tensors as lt\n",
    "lt.monkey_patch()\n",
    "\n",
    "from csng.data import get_dataloaders\n",
    "from csng.utils.mix import seed_all\n",
    "\n",
    "DATA_PATH_BRAINREADER = os.path.join(os.environ[\"DATA_PATH\"], \"brainreader\")\n",
    "DATA_PATH_MINDEYE = os.path.join(os.environ[\"DATA_PATH\"], \"mindeye\")\n",
    "DATA_PATH_MINDEYE_CACHE = os.path.join(DATA_PATH_MINDEYE, \"cache\")\n",
    "print(f\"{DATA_PATH_BRAINREADER=}\\n{DATA_PATH_MINDEYE=}\\n{DATA_PATH_MINDEYE_CACHE=}\")\n",
    "\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9018b82b-c054-4463-9527-4b0c2a75bda6",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "00c0e47d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = {\n",
    "    \"device\": \"cuda\",\n",
    "    \"data_type\": torch.float32,\n",
    "    \"seed\": 0,\n",
    "    \"data\": {\"mixing_strategy\": \"parallel_min\", \"max_training_batches\": None},\n",
    "    \"wandb\": {\"project\": os.environ[\"WANDB_PROJECT\"], \"group\": \"mindeye\"},\n",
    "}\n",
    "\n",
    "### setup data config\n",
    "cfg[\"data\"][\"brainreader_mouse\"] = {\n",
    "    \"device\": cfg[\"device\"],\n",
    "    \"mixing_strategy\": cfg[\"data\"][\"mixing_strategy\"],\n",
    "    \"max_batches\": None,\n",
    "    \"data_dir\": os.path.join(DATA_PATH_BRAINREADER, \"data\"),\n",
    "    \"batch_size\": 1,\n",
    "    # \"sessions\": (subj_list := list(range(1, 23))),\n",
    "    \"sessions\": (subj_list := [1,2,3,4,5,6,7,8]),\n",
    "    \"resize_stim_to\": (36, 64),\n",
    "    \"normalize_stim\": True,\n",
    "    \"normalize_resp\": True,\n",
    "    \"div_resp_by_std\": True,\n",
    "    \"clamp_neg_resp\": False,\n",
    "    \"additional_keys\": None,\n",
    "    \"avg_test_resp\": True,\n",
    "    \"drop_last\": False,\n",
    "}\n",
    "\n",
    "### setup model config\n",
    "cfg[\"model\"] = {\n",
    "    \"model_name\": (model_name := \"csng_19-02-25_16-52\"),\n",
    "    \"cache_dir\": DATA_PATH_MINDEYE_CACHE,\n",
    "    \"data_path\": DATA_PATH_BRAINREADER,\n",
    "    \"outdir\": f'{DATA_PATH_MINDEYE}/train_logs/{model_name}',\n",
    "    \"evalsdir\": f'{DATA_PATH_MINDEYE}/evals/{model_name}',\n",
    "    \"ckpt_saving\": True,\n",
    "    \"ckpt_interval\": 1,\n",
    "\n",
    "    # \"subj_list\": [6], # list(range(1, 23))\n",
    "    # \"num_voxels_list\": [8587],\n",
    "    # \"num_voxels\": {\n",
    "    #     f'subj06': 8587,\n",
    "    # },\n",
    "\n",
    "    \"subj_list\": subj_list,\n",
    "    \"num_voxels_list\": (num_voxels_list := [dset.n_neurons for dset in get_dataloaders(config=cfg)[0][\"train\"][\"brainreader_mouse\"].datasets]),\n",
    "    \"num_voxels\": {\n",
    "        f\"subj{subj:02d}\": num_voxels\n",
    "        for subj, num_voxels in zip(subj_list, num_voxels_list)\n",
    "    },\n",
    "    \"hidden_dim\": 768,\n",
    "    \"n_blocks\": 4,\n",
    "    \"clip_scale\": 1.,\n",
    "    \"use_prior\": True,\n",
    "    \"prior_scale\": 30,\n",
    "    \"num_epochs\": 150,\n",
    "    \"num_iterations_per_epoch\": 500,\n",
    "    # \"mixup_pct\": 0.33,\n",
    "    \"mixup_pct\": 0.,\n",
    "    \"blurry_recon\": True,\n",
    "    \"blur_scale\": 0.54,\n",
    "    \"use_image_aug\": False,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c63fc3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/scratch/izar/sobotka/csng/mindeye/train_logs/csng_19-02-25_16-52\n"
     ]
    }
   ],
   "source": [
    "### create dirs\n",
    "os.makedirs(cfg[\"model\"][\"outdir\"], exist_ok=True)\n",
    "os.makedirs(cfg[\"model\"][\"cache_dir\"], exist_ok=True)\n",
    "print(cfg[\"model\"][\"outdir\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42d13c25-1369-4c49-81d4-83d713586096",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Prep data, models, and dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "37e3feac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'subj01': <torch.utils.data.dataloader.DataLoader at 0x7f521581d150>,\n",
       " 'subj02': <torch.utils.data.dataloader.DataLoader at 0x7f5215819b50>,\n",
       " 'subj03': <torch.utils.data.dataloader.DataLoader at 0x7f521581add0>,\n",
       " 'subj04': <torch.utils.data.dataloader.DataLoader at 0x7f523f636b90>,\n",
       " 'subj05': <torch.utils.data.dataloader.DataLoader at 0x7f5215820a10>,\n",
       " 'subj06': <torch.utils.data.dataloader.DataLoader at 0x7f5215820990>,\n",
       " 'subj07': <torch.utils.data.dataloader.DataLoader at 0x7f5215823050>,\n",
       " 'subj08': <torch.utils.data.dataloader.DataLoader at 0x7f5215825150>}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dividing batch size by subj_list, which will then be concatenated across subj during training...\n"
     ]
    }
   ],
   "source": [
    "seed_all(cfg[\"seed\"])\n",
    "dls, _ = get_dataloaders(config=cfg)\n",
    "train_dl, val_dl, test_dl = dls[\"train\"][\"brainreader_mouse\"], dls[\"val\"][\"brainreader_mouse\"], dls[\"test\"][\"brainreader_mouse\"]\n",
    "train_dls = {subj_name: dl for subj_name, dl in zip(cfg[\"model\"][\"num_voxels\"].keys(), train_dl.dataloaders)}\n",
    "display(train_dls)\n",
    "\n",
    "print(\"dividing batch size by subj_list, which will then be concatenated across subj during training...\") \n",
    "cfg[\"model\"][\"num_samples_per_epoch\"] = sum(len(dl) * dl.batch_size for dl in train_dls.values())\n",
    "cfg[\"model\"][\"num_iterations_per_epoch\"] = cfg[\"model\"][\"num_samples_per_epoch\"] // (cfg[\"data\"][\"brainreader_mouse\"][\"batch_size\"] * len(cfg[\"model\"][\"subj_list\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10ec4517-dbdf-4ece-98f6-4714d5de4e15",
   "metadata": {},
   "source": [
    "## Load models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48d6160e-1ee8-4da7-a755-9dbb452a6fa5",
   "metadata": {},
   "source": [
    "### CLIP image embeddings  model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b0420dc0-199e-4c1a-857d-b1747058b467",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FrozenOpenCLIPImageEmbedder(\n",
       "  (model): CLIP(\n",
       "    (visual): VisionTransformer(\n",
       "      (conv1): Conv2d(3, 1664, kernel_size=(14, 14), stride=(14, 14), bias=False)\n",
       "      (patch_dropout): Identity()\n",
       "      (ln_pre): LayerNorm((1664,), eps=1e-05, elementwise_affine=True)\n",
       "      (transformer): Transformer(\n",
       "        (resblocks): ModuleList(\n",
       "          (0-47): 48 x ResidualAttentionBlock(\n",
       "            (ln_1): LayerNorm((1664,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): MultiheadAttention(\n",
       "              (out_proj): NonDynamicallyQuantizableLinear(in_features=1664, out_features=1664, bias=True)\n",
       "            )\n",
       "            (ls_1): Identity()\n",
       "            (ln_2): LayerNorm((1664,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Sequential(\n",
       "              (c_fc): Linear(in_features=1664, out_features=8192, bias=True)\n",
       "              (gelu): GELU(approximate='none')\n",
       "              (c_proj): Linear(in_features=8192, out_features=1664, bias=True)\n",
       "            )\n",
       "            (ls_2): Identity()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (ln_post): LayerNorm((1664,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (token_embedding): Embedding(49408, 1280)\n",
       "    (ln_final): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg[\"model\"][\"clip_img_embedder_arch\"] = \"ViT-bigG-14\"\n",
    "cfg[\"model\"][\"clip_img_embedder_version\"] = \"laion2b_s39b_b160k\"\n",
    "cfg[\"model\"][\"clip_seq_dim\"] = 256\n",
    "cfg[\"model\"][\"clip_emb_dim\"] = 1664\n",
    "\n",
    "clip_img_embedder = FrozenOpenCLIPImageEmbedder(\n",
    "    arch=cfg[\"model\"][\"clip_img_embedder_arch\"],\n",
    "    version=cfg[\"model\"][\"clip_img_embedder_version\"],\n",
    "    output_tokens=True,\n",
    "    only_tokens=True,\n",
    "    cache_dir=cfg[\"model\"][\"cache_dir\"],\n",
    ")\n",
    "clip_img_embedder.to(cfg[\"device\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b79bd38-6990-4504-8d45-4a68d57d8885",
   "metadata": {},
   "source": [
    "### SD VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "01baff79-8114-482b-b115-6f05aa8ad691",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param counts:\n",
      "83,653,863 total\n",
      "0 trainable\n",
      "param counts:\n",
      "349,687,808 total\n",
      "0 trainable\n"
     ]
    }
   ],
   "source": [
    "if cfg[\"model\"][\"blurry_recon\"]:\n",
    "    ### SD VAE\n",
    "    from diffusers import AutoencoderKL\n",
    "    cfg[\"model\"][\"autoenc\"] = {\n",
    "        \"down_block_types\": ['DownEncoderBlock2D', 'DownEncoderBlock2D', 'DownEncoderBlock2D', 'DownEncoderBlock2D'],\n",
    "        \"up_block_types\": ['UpDecoderBlock2D', 'UpDecoderBlock2D', 'UpDecoderBlock2D', 'UpDecoderBlock2D'],\n",
    "        \"block_out_channels\": [128, 256, 512, 512],\n",
    "        \"layers_per_block\": 2,\n",
    "        \"sample_size\": 256,\n",
    "    }\n",
    "    autoenc = AutoencoderKL(**cfg[\"model\"][\"autoenc\"])\n",
    "    autoenc.load_state_dict(torch.load(f'{cfg[\"model\"][\"cache_dir\"]}/sd_image_var_autoenc.pth'))\n",
    "    autoenc.eval()\n",
    "    autoenc.requires_grad_(False)\n",
    "    autoenc.to(cfg[\"device\"])\n",
    "    utils.count_params(autoenc)\n",
    "\n",
    "    ### VICRegL ConvNext-XL\n",
    "    from pkgs.MindEyeV2.src.autoencoder.convnext import ConvnextXL\n",
    "    cnx = ConvnextXL(f'{cfg[\"model\"][\"cache_dir\"]}/convnext_xlarge_alpha0.75_fullckpt.pth')\n",
    "    cnx.requires_grad_(False)\n",
    "    cnx.eval()\n",
    "    cnx.to(cfg[\"device\"])\n",
    "    utils.count_params(cnx)\n",
    "\n",
    "    import kornia\n",
    "    from kornia.augmentation.container import AugmentationSequential\n",
    "    mean = torch.tensor([0.485, 0.456, 0.406]).to(cfg[\"device\"]).reshape(1,3,1,1)\n",
    "    std = torch.tensor([0.228, 0.224, 0.225]).to(cfg[\"device\"]).reshape(1,3,1,1)\n",
    "    blur_augs = AugmentationSequential(\n",
    "        kornia.augmentation.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.2, hue=0.1, p=0.8),\n",
    "        kornia.augmentation.RandomGrayscale(p=0.1),\n",
    "        kornia.augmentation.RandomSolarize(p=0.1),\n",
    "        kornia.augmentation.RandomResizedCrop((224,224), scale=(.9,.9), ratio=(1,1), p=1.0),\n",
    "        data_keys=[\"input\"],\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "260e5e4a-f697-4b2c-88fc-01f6a54886c0",
   "metadata": {},
   "source": [
    "### MindEye modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c44c271b-173f-472e-b059-a2eda0f4c4c5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MindEyeModule(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MindEyeModule, self).__init__()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return x\n",
    "\n",
    "class RidgeRegression(torch.nn.Module):\n",
    "    # make sure to add weight_decay when initializing optimizer to enable regularization\n",
    "    def __init__(self, input_sizes, out_features): \n",
    "        super(RidgeRegression, self).__init__()\n",
    "        self.out_features = out_features\n",
    "        self.linears = torch.nn.ModuleList([\n",
    "            torch.nn.Linear(input_size, out_features) for input_size in input_sizes\n",
    "        ])\n",
    "    \n",
    "    def forward(self, x, subj_idx):\n",
    "        out = self.linears[subj_idx](x[:,0]).unsqueeze(1)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "038a5d61-4769-40b9-a004-f4e7b5b38bb0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param counts:\n",
      "50,132,736 total\n",
      "50,132,736 trainable\n",
      "param counts:\n",
      "50,132,736 total\n",
      "50,132,736 trainable\n",
      "torch.Size([2, 1, 9395]) torch.Size([2, 1, 768])\n"
     ]
    }
   ],
   "source": [
    "### init model\n",
    "model = MindEyeModule()\n",
    "model.ridge = RidgeRegression(cfg[\"model\"][\"num_voxels_list\"], out_features=cfg[\"model\"][\"hidden_dim\"])\n",
    "utils.count_params(model.ridge)\n",
    "utils.count_params(model)\n",
    "\n",
    "# test on subject 1 with fake data\n",
    "b = torch.randn((2,1,cfg[\"model\"][\"num_voxels_list\"][0]))\n",
    "print(b.shape, model.ridge(b,0).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7b8de65a-6d3b-4248-bea9-9b6f4d562321",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param counts:\n",
      "345,356,284 total\n",
      "345,356,284 trainable\n",
      "param counts:\n",
      "395,489,020 total\n",
      "395,489,020 trainable\n",
      "b.shape torch.Size([2, 1, 768])\n",
      "torch.Size([2, 256, 1664]) torch.Size([2, 256, 1664]) torch.Size([2, 4, 28, 28]) torch.Size([2, 49, 512])\n"
     ]
    }
   ],
   "source": [
    "from pkgs.MindEyeV2.src.models import BrainNetwork\n",
    "\n",
    "### backbone\n",
    "cfg[\"model\"][\"brainnetwork\"] = {\n",
    "    \"h\": cfg[\"model\"][\"hidden_dim\"],\n",
    "    \"in_dim\": cfg[\"model\"][\"hidden_dim\"],\n",
    "    \"seq_len\": 1,\n",
    "    \"n_blocks\": cfg[\"model\"][\"n_blocks\"],\n",
    "    \"clip_size\": cfg[\"model\"][\"clip_emb_dim\"],\n",
    "    \"out_dim\": cfg[\"model\"][\"clip_emb_dim\"] * cfg[\"model\"][\"clip_seq_dim\"],\n",
    "    \"blurry_recon\": cfg[\"model\"][\"blurry_recon\"],\n",
    "    \"clip_scale\": cfg[\"model\"][\"clip_scale\"],\n",
    "}\n",
    "model.backbone = BrainNetwork(**cfg[\"model\"][\"brainnetwork\"])\n",
    "utils.count_params(model.backbone)\n",
    "utils.count_params(model)\n",
    "\n",
    "# test that the model works on some fake data\n",
    "b = torch.randn((2,1,cfg[\"model\"][\"hidden_dim\"]))\n",
    "print(\"b.shape\",b.shape)\n",
    "\n",
    "backbone_, clip_, blur_ = model.backbone(b)\n",
    "print(backbone_.shape, clip_.shape, blur_[0].shape, blur_[1].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b397c0d7-52a3-4153-823b-c27d2eb3eeba",
   "metadata": {},
   "source": [
    "### Adding diffusion prior + unCLIP if use_prior=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "69965344-9346-4592-9cc5-e537e31d5fce",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param counts:\n",
      "259,865,216 total\n",
      "259,865,200 trainable\n",
      "param counts:\n",
      "655,354,236 total\n",
      "655,354,220 trainable\n"
     ]
    }
   ],
   "source": [
    "if cfg[\"model\"][\"use_prior\"]:\n",
    "    from pkgs.MindEyeV2.src.models import *\n",
    "\n",
    "    ### setup diffusion prior network\n",
    "    cfg[\"model\"][\"out_dim\"] = cfg[\"model\"][\"clip_emb_dim\"]\n",
    "    cfg[\"model\"][\"depth\"] = 6\n",
    "    cfg[\"model\"][\"dim_head\"] = 52\n",
    "    cfg[\"model\"][\"heads\"] = cfg[\"model\"][\"clip_emb_dim\"] // cfg[\"model\"][\"dim_head\"]\n",
    "    cfg[\"model\"][\"timesteps\"] = 100\n",
    "    cfg[\"model\"][\"prior_network\"] = {\n",
    "        \"dim\": cfg[\"model\"][\"out_dim\"],\n",
    "        \"depth\": cfg[\"model\"][\"depth\"],\n",
    "        \"dim_head\": cfg[\"model\"][\"dim_head\"],\n",
    "        \"heads\": cfg[\"model\"][\"heads\"],\n",
    "        \"causal\": False,\n",
    "        \"num_tokens\": cfg[\"model\"][\"clip_seq_dim\"],\n",
    "        \"learned_query_mode\": \"pos_emb\",\n",
    "    }\n",
    "    cfg[\"model\"][\"brain_diffusion_prior\"] = {\n",
    "        \"image_embed_dim\": cfg[\"model\"][\"out_dim\"],\n",
    "        \"condition_on_text_encodings\": False,\n",
    "        \"timesteps\": cfg[\"model\"][\"timesteps\"],\n",
    "        \"cond_drop_prob\": 0.2,\n",
    "        \"image_embed_scale\": None,\n",
    "    }\n",
    "\n",
    "    prior_network = PriorNetwork(**cfg[\"model\"][\"prior_network\"])\n",
    "    model.diffusion_prior = BrainDiffusionPrior(net=prior_network, **cfg[\"model\"][\"brain_diffusion_prior\"])\n",
    "    utils.count_params(model.diffusion_prior)\n",
    "    utils.count_params(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec25271a-2209-400c-8026-df3b8ddc1eef",
   "metadata": {},
   "source": [
    "### Setup optimizer / lr / ckpt saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e14d0482-dc42-43b9-9ce1-953c32f2c9c1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_steps 675000\n",
      "\n",
      "Done with model preparations!\n",
      "param counts:\n",
      "655,354,236 total\n",
      "655,354,220 trainable\n"
     ]
    }
   ],
   "source": [
    "cfg[\"model\"][\"optimization\"] = {\n",
    "    \"no_decay\": ['bias', 'LayerNorm.bias', 'LayerNorm.weight'],\n",
    "    \"max_lr\": 3e-4,\n",
    "    \"lr_scheduler_type\": 'cycle',\n",
    "}\n",
    "\n",
    "opt_grouped_parameters = [\n",
    "    {'params': [p for n, p in model.ridge.named_parameters()], 'weight_decay': 1e-2},\n",
    "    {'params': [p for n, p in model.backbone.named_parameters() if not any(nd in n for nd in cfg[\"model\"][\"optimization\"][\"no_decay\"])], 'weight_decay': 1e-2},\n",
    "    {'params': [p for n, p in model.backbone.named_parameters() if any(nd in n for nd in cfg[\"model\"][\"optimization\"][\"no_decay\"])], 'weight_decay': 0.0},\n",
    "]\n",
    "if cfg[\"model\"][\"use_prior\"]:\n",
    "    opt_grouped_parameters.extend([\n",
    "        {'params': [p for n, p in model.diffusion_prior.named_parameters() if not any(nd in n for nd in cfg[\"model\"][\"optimization\"][\"no_decay\"])], 'weight_decay': 1e-2},\n",
    "        {'params': [p for n, p in model.diffusion_prior.named_parameters() if any(nd in n for nd in cfg[\"model\"][\"optimization\"][\"no_decay\"])], 'weight_decay': 0.0}\n",
    "    ])\n",
    "\n",
    "optimizer = torch.optim.AdamW(opt_grouped_parameters, lr=cfg[\"model\"][\"optimization\"][\"max_lr\"])\n",
    "\n",
    "if cfg[\"model\"][\"optimization\"][\"lr_scheduler_type\"] == 'linear':\n",
    "    lr_scheduler = torch.optim.lr_scheduler.LinearLR(\n",
    "        optimizer,\n",
    "        total_iters=cfg[\"model\"][\"num_epochs\"]*cfg[\"model\"][\"num_iterations_per_epoch\"],\n",
    "        last_epoch=-1\n",
    "    )\n",
    "elif cfg[\"model\"][\"optimization\"][\"lr_scheduler_type\"] == 'cycle':\n",
    "    cfg[\"model\"][\"optimization\"][\"total_steps\"] = int(np.floor(cfg[\"model\"][\"num_epochs\"]*cfg[\"model\"][\"num_iterations_per_epoch\"]))\n",
    "    lr_scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
    "        optimizer, \n",
    "        max_lr=cfg[\"model\"][\"optimization\"][\"max_lr\"],\n",
    "        total_steps=cfg[\"model\"][\"optimization\"][\"total_steps\"],\n",
    "        final_div_factor=1000,\n",
    "        last_epoch=-1, pct_start=2/cfg[\"model\"][\"num_epochs\"],\n",
    "    )\n",
    "    print(\"total_steps\", cfg[\"model\"][\"optimization\"][\"total_steps\"])\n",
    "\n",
    "def save_ckpt(tag):\n",
    "    ckpt_path = cfg[\"model\"][\"outdir\"]+f'/{tag}.pth'\n",
    "    torch.save({\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'lr_scheduler': lr_scheduler.state_dict(),\n",
    "        'train_losses': losses,\n",
    "        'test_losses': test_losses,\n",
    "        'lrs': lrs,\n",
    "        \"cfg\": cfg,\n",
    "        \"best\": best,\n",
    "    }, ckpt_path)\n",
    "    print(f\"\\n---saved {cfg['model']['outdir']}/{tag} ckpt!---\\n\")\n",
    "\n",
    "def load_ckpt(tag):\n",
    "    ckpt_path = cfg[\"model\"][\"outdir\"]+f'/{tag}.pth'\n",
    "    checkpoint = torch.load(ckpt_path)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    lr_scheduler.load_state_dict(checkpoint['lr_scheduler'])\n",
    "    epoch = checkpoint['epoch']\n",
    "    losses = checkpoint['train_losses']\n",
    "    test_losses = checkpoint['test_losses']\n",
    "    lrs = checkpoint['lrs']\n",
    "    best = checkpoint['best']\n",
    "    optimizer.zero_grad()\n",
    "    print(f\"\\n---loaded {cfg['model']['outdir']}/{tag} ckpt!---\\n\")\n",
    "    return epoch, losses, test_losses, lrs, checkpoint[\"cfg\"], best\n",
    "\n",
    "print(\"\\nDone with model preparations!\")\n",
    "num_params = utils.count_params(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7ab915f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MindEyeModule(\n",
       "  (ridge): RidgeRegression(\n",
       "    (linears): ModuleList(\n",
       "      (0): Linear(in_features=9395, out_features=768, bias=True)\n",
       "      (1): Linear(in_features=6721, out_features=768, bias=True)\n",
       "      (2): Linear(in_features=6864, out_features=768, bias=True)\n",
       "      (3): Linear(in_features=8784, out_features=768, bias=True)\n",
       "      (4): Linear(in_features=8739, out_features=768, bias=True)\n",
       "      (5): Linear(in_features=8587, out_features=768, bias=True)\n",
       "      (6): Linear(in_features=8890, out_features=768, bias=True)\n",
       "      (7): Linear(in_features=7289, out_features=768, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (backbone): BrainNetwork(\n",
       "    (mixer_blocks1): ModuleList(\n",
       "      (0-3): 4 x Sequential(\n",
       "        (0): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (1): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.15, inplace=False)\n",
       "          (3): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (mixer_blocks2): ModuleList(\n",
       "      (0-3): 4 x Sequential(\n",
       "        (0): LayerNorm((1,), eps=1e-05, elementwise_affine=True)\n",
       "        (1): Sequential(\n",
       "          (0): Linear(in_features=1, out_features=1, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.15, inplace=False)\n",
       "          (3): Linear(in_features=1, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (backbone_linear): Linear(in_features=768, out_features=425984, bias=True)\n",
       "    (clip_proj): Sequential(\n",
       "      (0): LayerNorm((1664,), eps=1e-05, elementwise_affine=True)\n",
       "      (1): GELU(approximate='none')\n",
       "      (2): Linear(in_features=1664, out_features=1664, bias=True)\n",
       "      (3): LayerNorm((1664,), eps=1e-05, elementwise_affine=True)\n",
       "      (4): GELU(approximate='none')\n",
       "      (5): Linear(in_features=1664, out_features=1664, bias=True)\n",
       "      (6): LayerNorm((1664,), eps=1e-05, elementwise_affine=True)\n",
       "      (7): GELU(approximate='none')\n",
       "      (8): Linear(in_features=1664, out_features=1664, bias=True)\n",
       "    )\n",
       "    (blin1): Linear(in_features=768, out_features=3136, bias=True)\n",
       "    (bdropout): Dropout(p=0.3, inplace=False)\n",
       "    (bnorm): GroupNorm(1, 64, eps=1e-05, affine=True)\n",
       "    (bupsampler): Decoder(\n",
       "      (conv_in): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (up_blocks): ModuleList(\n",
       "        (0): UpDecoderBlock2D(\n",
       "          (resnets): ModuleList(\n",
       "            (0-1): 2 x ResnetBlock2D(\n",
       "              (norm1): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
       "              (conv1): LoRACompatibleConv(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (norm2): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (conv2): LoRACompatibleConv(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (nonlinearity): SiLU()\n",
       "            )\n",
       "          )\n",
       "          (upsamplers): ModuleList(\n",
       "            (0): Upsample2D(\n",
       "              (conv): LoRACompatibleConv(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1): UpDecoderBlock2D(\n",
       "          (resnets): ModuleList(\n",
       "            (0): ResnetBlock2D(\n",
       "              (norm1): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
       "              (conv1): LoRACompatibleConv(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (norm2): GroupNorm(32, 64, eps=1e-06, affine=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (conv2): LoRACompatibleConv(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (nonlinearity): SiLU()\n",
       "              (conv_shortcut): LoRACompatibleConv(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "            (1): ResnetBlock2D(\n",
       "              (norm1): GroupNorm(32, 64, eps=1e-06, affine=True)\n",
       "              (conv1): LoRACompatibleConv(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (norm2): GroupNorm(32, 64, eps=1e-06, affine=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (conv2): LoRACompatibleConv(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (nonlinearity): SiLU()\n",
       "            )\n",
       "          )\n",
       "          (upsamplers): ModuleList(\n",
       "            (0): Upsample2D(\n",
       "              (conv): LoRACompatibleConv(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (2): UpDecoderBlock2D(\n",
       "          (resnets): ModuleList(\n",
       "            (0): ResnetBlock2D(\n",
       "              (norm1): GroupNorm(32, 64, eps=1e-06, affine=True)\n",
       "              (conv1): LoRACompatibleConv(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (norm2): GroupNorm(32, 32, eps=1e-06, affine=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (conv2): LoRACompatibleConv(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (nonlinearity): SiLU()\n",
       "              (conv_shortcut): LoRACompatibleConv(64, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "            (1): ResnetBlock2D(\n",
       "              (norm1): GroupNorm(32, 32, eps=1e-06, affine=True)\n",
       "              (conv1): LoRACompatibleConv(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (norm2): GroupNorm(32, 32, eps=1e-06, affine=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (conv2): LoRACompatibleConv(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (nonlinearity): SiLU()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (mid_block): UNetMidBlock2D(\n",
       "        (attentions): ModuleList(\n",
       "          (0): Attention(\n",
       "            (group_norm): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
       "            (to_q): LoRACompatibleLinear(in_features=128, out_features=128, bias=True)\n",
       "            (to_k): LoRACompatibleLinear(in_features=128, out_features=128, bias=True)\n",
       "            (to_v): LoRACompatibleLinear(in_features=128, out_features=128, bias=True)\n",
       "            (to_out): ModuleList(\n",
       "              (0): LoRACompatibleLinear(in_features=128, out_features=128, bias=True)\n",
       "              (1): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (resnets): ModuleList(\n",
       "          (0-1): 2 x ResnetBlock2D(\n",
       "            (norm1): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
       "            (conv1): LoRACompatibleConv(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (norm2): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (conv2): LoRACompatibleConv(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (nonlinearity): SiLU()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (conv_norm_out): GroupNorm(32, 32, eps=1e-06, affine=True)\n",
       "      (conv_act): SiLU()\n",
       "      (conv_out): Conv2d(32, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "    (b_maps_projector): Sequential(\n",
       "      (0): Conv2d(64, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): GroupNorm(1, 512, eps=1e-05, affine=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (4): GroupNorm(1, 512, eps=1e-05, affine=True)\n",
       "      (5): ReLU(inplace=True)\n",
       "      (6): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "  )\n",
       "  (diffusion_prior): BrainDiffusionPrior(\n",
       "    (noise_scheduler): NoiseScheduler()\n",
       "    (net): PriorNetwork(\n",
       "      (to_time_embeds): Sequential(\n",
       "        (0): Sequential(\n",
       "          (0): SinusoidalPosEmb()\n",
       "          (1): MLP(\n",
       "            (net): Sequential(\n",
       "              (0): Sequential(\n",
       "                (0): Linear(in_features=1664, out_features=3328, bias=True)\n",
       "                (1): SiLU()\n",
       "                (2): Identity()\n",
       "              )\n",
       "              (1): Sequential(\n",
       "                (0): Linear(in_features=3328, out_features=3328, bias=True)\n",
       "                (1): SiLU()\n",
       "                (2): Identity()\n",
       "              )\n",
       "              (2): Linear(in_features=3328, out_features=1664, bias=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1): Rearrange('b (n d) -> b n d', n=1)\n",
       "      )\n",
       "      (causal_transformer): FlaggedCausalTransformer(\n",
       "        (init_norm): Identity()\n",
       "        (rel_pos_bias): RelPosBias(\n",
       "          (relative_attention_bias): Embedding(32, 32)\n",
       "        )\n",
       "        (layers): ModuleList(\n",
       "          (0-5): 6 x ModuleList(\n",
       "            (0): Attention(\n",
       "              (norm): LayerNorm()\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (to_q): Linear(in_features=1664, out_features=1664, bias=False)\n",
       "              (to_kv): Linear(in_features=1664, out_features=104, bias=False)\n",
       "              (rotary_emb): RotaryEmbedding()\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=1664, out_features=1664, bias=False)\n",
       "                (1): LayerNorm()\n",
       "              )\n",
       "            )\n",
       "            (1): Sequential(\n",
       "              (0): LayerNorm()\n",
       "              (1): Linear(in_features=1664, out_features=13312, bias=False)\n",
       "              (2): SwiGLU()\n",
       "              (3): Identity()\n",
       "              (4): Dropout(p=0.0, inplace=False)\n",
       "              (5): Linear(in_features=6656, out_features=1664, bias=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (norm): LayerNorm()\n",
       "        (project_out): Linear(in_features=1664, out_features=1664, bias=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0b8aa168",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---loaded /scratch/izar/sobotka/csng/mindeye/train_logs/csng_19-02-25_16-52/last ckpt!---\n",
      "\n"
     ]
    }
   ],
   "source": [
    "epoch, losses, test_losses, lrs, cfg, best = load_ckpt(\"last\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "983f458b-35b8-49f2-b6db-80296cece730",
   "metadata": {},
   "source": [
    "# Weights and Biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0a25a662-daa8-4de9-9233-8364800fcb6b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mjohnny1188\u001b[0m to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/sobotka/decoding-brain-activity/pkgs/MindEyeV2/wandb/run-20250221_152851-csng_19-02-25_16-52</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Resuming run <strong><a href='https://wandb.ai/johnny1188/MindEye/runs/csng_19-02-25_16-52' target=\"_blank\">csng_19-02-25_16-52</a></strong> to <a href='https://wandb.ai/johnny1188/MindEye' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/johnny1188/MindEye' target=\"_blank\">https://wandb.ai/johnny1188/MindEye</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/johnny1188/MindEye/runs/csng_19-02-25_16-52' target=\"_blank\">https://wandb.ai/johnny1188/MindEye/runs/csng_19-02-25_16-52</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if cfg.get(\"wandb\", None) is not None: # only use main process for wandb logging\n",
    "    import wandb\n",
    "    wandb_log = wandb.init(\n",
    "        id=cfg[\"model\"][\"model_name\"],\n",
    "        name=cfg[\"model\"][\"model_name\"],\n",
    "        config=cfg,\n",
    "        resume=\"allow\",\n",
    "        **cfg[\"wandb\"],\n",
    "    )\n",
    "else:\n",
    "    wandb_log = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5690151-2131-4918-b750-e869cbd1a8a8",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4cdbfdec",
   "metadata": {},
   "outputs": [],
   "source": [
    "### img transform (1x36x64 -> 3x224x224)\n",
    "img_tform = transforms.Compose([\n",
    "    transforms.Resize((224, 224), antialias=True),\n",
    "    transforms.Lambda(lambda x: x.repeat(1, 3, 1, 1)),\n",
    "    # transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "if cfg[\"model\"][\"use_image_aug\"]:\n",
    "    img_augment = AugmentationSequential(\n",
    "        kornia.augmentation.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.4, hue=0.1, p=0.3),\n",
    "        same_on_batch=False,\n",
    "        data_keys=[\"input\"],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60be0d5f-3e94-4612-9373-61b53d836393",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   | 0/133 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[E17/150 I0/4500]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sobotka/miniconda3/envs/mindeye/lib/python3.11/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Loss 7.374719142913818\n",
      "tensor grad AddBackward0 cuda:0 7.375\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-0.452, 0.715] μ=1.733e-09 σ=0.001 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 14.555\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-0.454, 0.719] μ=-1.089e-09 σ=0.001 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.995\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-0.449, 0.711] μ=-4.563e-09 σ=0.001 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 11.644\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-0.444, 0.704] μ=-9.139e-09 σ=0.001 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.501\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-0.444, 0.704] μ=-8.042e-09 σ=0.001 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 11.625\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-0.393, 0.628] μ=-5.113e-08 σ=0.001 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.505\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-0.388, 0.620] μ=-5.908e-08 σ=0.001 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 11.852\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-0.293, 0.480] μ=-6.507e-08 σ=0.001 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.924\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-0.293, 0.480] μ=-7.014e-08 σ=0.001 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.312\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-0.313, 0.398] μ=-1.355e-07 σ=0.001 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.673\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-0.313, 0.398] μ=-1.372e-07 σ=0.001 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.558\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-0.320, 0.398] μ=-1.433e-07 σ=0.001 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 13.566\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-0.468, 0.447] μ=-1.889e-07 σ=0.001 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.296\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-0.479, 0.447] μ=-1.944e-07 σ=0.001 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.760\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-0.483, 0.447] μ=-1.982e-07 σ=0.001 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.188\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-0.581, 0.447] μ=-2.609e-07 σ=0.001 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 4.988\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-0.585, 0.447] μ=-2.637e-07 σ=0.001 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 11.202\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-0.596, 0.447] μ=-2.711e-07 σ=0.001 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 13.215\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-0.852, 0.608] μ=-3.495e-07 σ=0.001 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.413\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-0.860, 0.613] μ=-3.534e-07 σ=0.001 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.510\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-0.863, 0.616] μ=-3.530e-07 σ=0.001 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 6.493\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-0.863, 0.616] μ=-3.526e-07 σ=0.001 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.605\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-0.879, 0.626] μ=-3.600e-07 σ=0.001 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.822\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-0.992, 0.707] μ=-4.508e-07 σ=0.001 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 13.647\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-1.161, 0.802] μ=-5.542e-07 σ=0.001 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.739\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-1.169, 0.807] μ=-5.561e-07 σ=0.001 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 5.946\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-1.169, 0.807] μ=-5.566e-07 σ=0.001 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.591\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-1.169, 0.807] μ=-5.554e-07 σ=0.001 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.279\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-1.169, 0.807] μ=-5.571e-07 σ=0.001 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.212\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-1.173, 0.810] μ=-5.592e-07 σ=0.001 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 6.860\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-1.180, 0.815] μ=-5.615e-07 σ=0.001 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.884\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-1.192, 0.824] μ=-5.646e-07 σ=0.001 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 5.621\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-1.192, 0.824] μ=-5.646e-07 σ=0.001 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.559\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-1.328, 0.921] μ=-5.775e-07 σ=0.001 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.081\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-1.328, 0.921] μ=-5.775e-07 σ=0.001 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.029\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-1.328, 0.921] μ=-5.779e-07 σ=0.001 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.504\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-1.420, 0.986] μ=-5.784e-07 σ=0.001 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.355\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-1.420, 0.986] μ=-5.772e-07 σ=0.001 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 13.106\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-1.431, 0.994] μ=-5.851e-07 σ=0.001 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 12.237\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-1.507, 1.048] μ=-6.026e-07 σ=0.001 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.773\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-1.644, 1.146] μ=-6.954e-07 σ=0.001 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.318\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-1.587, 1.105] μ=-6.984e-07 σ=0.002 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 3.801\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-1.587, 1.105] μ=-6.985e-07 σ=0.002 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.493\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-1.587, 1.105] μ=-7.001e-07 σ=0.002 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 4.893\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-1.587, 1.105] μ=-7.001e-07 σ=0.002 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.022\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-1.625, 1.132] μ=-7.381e-07 σ=0.002 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.232\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-1.689, 1.179] μ=-7.985e-07 σ=0.002 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 14.617\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-1.746, 1.223] μ=-8.596e-07 σ=0.002 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.306\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-1.750, 1.226] μ=-8.635e-07 σ=0.002 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.901\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-1.835, 1.297] μ=-8.923e-07 σ=0.002 cuda:0\n",
      "[E17/150 I50/4500]\n",
      "  Loss 8.483463287353516\n",
      "tensor grad AddBackward0 cuda:0 8.483\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-1.839, 1.299] μ=-8.917e-07 σ=0.002 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.394\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-1.842, 1.303] μ=-8.969e-07 σ=0.002 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 13.839\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-1.854, 1.310] μ=-8.971e-07 σ=0.002 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 5.431\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-1.854, 1.310] μ=-8.972e-07 σ=0.002 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 12.436\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-1.960, 1.387] μ=-8.876e-07 σ=0.002 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.868\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-1.964, 1.389] μ=-8.860e-07 σ=0.002 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 12.704\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-2.132, 1.511] μ=-9.211e-07 σ=0.002 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 5.449\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-2.139, 1.517] μ=-9.215e-07 σ=0.002 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 5.628\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-2.139, 1.517] μ=-9.214e-07 σ=0.002 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 6.484\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-2.139, 1.517] μ=-9.212e-07 σ=0.002 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 5.849\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-2.139, 1.517] μ=-9.211e-07 σ=0.002 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.739\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-2.139, 1.517] μ=-9.205e-07 σ=0.002 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 11.611\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-2.147, 1.522] μ=-9.198e-07 σ=0.002 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 20.034\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-2.188, 1.552] μ=-9.554e-07 σ=0.002 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.220\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-2.192, 1.555] μ=-9.555e-07 σ=0.002 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.700\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-2.192, 1.555] μ=-9.577e-07 σ=0.002 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 6.376\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-2.192, 1.555] μ=-9.572e-07 σ=0.002 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 12.559\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-2.459, 1.751] μ=-1.003e-06 σ=0.002 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 6.128\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-2.459, 1.751] μ=-1.003e-06 σ=0.002 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.407\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-2.585, 1.843] μ=-9.992e-07 σ=0.002 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.209\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-2.615, 1.865] μ=-1.004e-06 σ=0.002 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 6.855\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-2.611, 1.862] μ=-1.002e-06 σ=0.002 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.827\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-2.737, 1.955] μ=-1.060e-06 σ=0.002 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 5.703\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-2.745, 1.960] μ=-1.061e-06 σ=0.002 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.692\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-2.752, 1.966] μ=-1.061e-06 σ=0.002 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.547\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-2.752, 1.966] μ=-1.061e-06 σ=0.002 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.366\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-2.764, 1.974] μ=-1.061e-06 σ=0.002 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 12.973\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-2.775, 1.983] μ=-1.065e-06 σ=0.002 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.883\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-2.783, 1.989] μ=-1.065e-06 σ=0.002 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 5.751\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-2.787, 1.991] μ=-1.064e-06 σ=0.002 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 11.244\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-3.017, 2.161] μ=-1.086e-06 σ=0.002 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 5.386\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-3.017, 2.161] μ=-1.086e-06 σ=0.002 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 11.104\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-3.170, 2.275] μ=-1.083e-06 σ=0.002 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 5.785\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-3.170, 2.275] μ=-1.084e-06 σ=0.002 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.695\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-3.277, 2.354] μ=-1.098e-06 σ=0.003 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 11.817\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-3.277, 2.354] μ=-1.103e-06 σ=0.003 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 5.976\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-3.277, 2.354] μ=-1.103e-06 σ=0.003 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 12.616\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-3.250, 2.334] μ=-1.021e-06 σ=0.003 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.082\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-3.254, 2.337] μ=-1.021e-06 σ=0.003 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 6.524\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-3.262, 2.342] μ=-1.023e-06 σ=0.003 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 14.057\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-3.369, 2.422] μ=-1.048e-06 σ=0.003 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 6.836\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-3.369, 2.422] μ=-1.048e-06 σ=0.003 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 12.047\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-3.372, 2.425] μ=-1.046e-06 σ=0.003 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.197\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-3.372, 2.425] μ=-1.048e-06 σ=0.003 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.874\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-3.380, 2.430] μ=-1.047e-06 σ=0.003 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 12.795\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-3.602, 2.596] μ=-1.139e-06 σ=0.003 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.954\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-3.656, 2.636] μ=-1.196e-06 σ=0.003 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.671\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-3.664, 2.642] μ=-1.197e-06 σ=0.003 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.236\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-3.664, 2.642] μ=-1.202e-06 σ=0.003 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.178\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-3.670, 2.646] μ=-1.202e-06 σ=0.003 cuda:0\n",
      "[E17/150 I100/4500]\n",
      "  Loss 14.73376750946045\n",
      "tensor grad AddBackward0 cuda:0 14.734\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-3.735, 2.695] μ=-1.262e-06 σ=0.003 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.294\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-3.735, 2.695] μ=-1.262e-06 σ=0.003 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.593\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-3.735, 2.695] μ=-1.262e-06 σ=0.003 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.930\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-3.884, 2.806] μ=-1.265e-06 σ=0.003 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 16.726\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-3.881, 2.803] μ=-1.266e-06 σ=0.003 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 12.498\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-3.896, 2.815] μ=-1.268e-06 σ=0.003 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.346\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-3.900, 2.818] μ=-1.270e-06 σ=0.003 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 6.426\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-3.900, 2.818] μ=-1.270e-06 σ=0.003 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.846\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-3.907, 2.823] μ=-1.272e-06 σ=0.003 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 6.962\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-3.907, 2.823] μ=-1.272e-06 σ=0.003 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.016\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-3.915, 2.829] μ=-1.274e-06 σ=0.003 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 6.948\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-3.915, 2.829] μ=-1.276e-06 σ=0.003 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 6.431\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-3.930, 2.841] μ=-1.279e-06 σ=0.003 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.394\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-3.946, 2.852] μ=-1.283e-06 σ=0.003 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 6.402\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-3.953, 2.858] μ=-1.284e-06 σ=0.003 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 4.724\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-3.953, 2.858] μ=-1.284e-06 σ=0.003 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 5.003\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-3.953, 2.858] μ=-1.284e-06 σ=0.003 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.055\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-3.957, 2.861] μ=-1.290e-06 σ=0.003 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 14.038\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-4.168, 3.019] μ=-1.357e-06 σ=0.003 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.355\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-4.171, 3.021] μ=-1.357e-06 σ=0.003 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 11.389\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-4.294, 3.113] μ=-1.411e-06 σ=0.003 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.076\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-4.294, 3.113] μ=-1.411e-06 σ=0.003 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.668\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-4.297, 3.116] μ=-1.414e-06 σ=0.003 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 11.296\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-4.301, 3.119] μ=-1.435e-06 σ=0.003 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.383\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-4.301, 3.119] μ=-1.435e-06 σ=0.003 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 11.229\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-4.412, 3.202] μ=-1.489e-06 σ=0.003 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 6.004\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-4.412, 3.202] μ=-1.489e-06 σ=0.003 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 5.649\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-4.412, 3.202] μ=-1.489e-06 σ=0.003 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.939\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-4.408, 3.200] μ=-1.488e-06 σ=0.003 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.514\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-4.539, 3.298] μ=-1.565e-06 σ=0.004 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 6.969\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-4.539, 3.298] μ=-1.565e-06 σ=0.004 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.851\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-4.592, 3.338] μ=-1.606e-06 σ=0.004 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 4.379\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-4.592, 3.338] μ=-1.606e-06 σ=0.004 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 6.187\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-4.592, 3.338] μ=-1.606e-06 σ=0.004 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 6.906\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-4.592, 3.338] μ=-1.606e-06 σ=0.004 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.090\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-4.592, 3.338] μ=-1.606e-06 σ=0.004 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.810\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-4.600, 3.344] μ=-1.609e-06 σ=0.004 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 5.927\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-4.600, 3.344] μ=-1.609e-06 σ=0.004 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.724\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-4.600, 3.344] μ=-1.609e-06 σ=0.004 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.001\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-4.608, 3.350] μ=-1.612e-06 σ=0.004 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 12.541\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-4.631, 3.368] μ=-1.619e-06 σ=0.004 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.336\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-4.629, 3.366] μ=-1.622e-06 σ=0.004 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.238\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-4.629, 3.366] μ=-1.622e-06 σ=0.004 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.050\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-4.639, 3.374] μ=-1.628e-06 σ=0.004 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 11.467\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-4.649, 3.381] μ=-1.629e-06 σ=0.004 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 5.379\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-4.649, 3.381] μ=-1.629e-06 σ=0.004 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 6.976\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-4.648, 3.380] μ=-1.629e-06 σ=0.004 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.785\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-4.656, 3.386] μ=-1.630e-06 σ=0.004 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.720\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-4.652, 3.383] μ=-1.628e-06 σ=0.004 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 13.656\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-4.748, 3.456] μ=-1.685e-06 σ=0.004 cuda:0\n",
      "[E17/150 I150/4500]\n",
      "  Loss 9.301496505737305\n",
      "tensor grad AddBackward0 cuda:0 9.301\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-4.748, 3.456] μ=-1.684e-06 σ=0.004 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 14.655\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-4.904, 3.574] μ=-1.743e-06 σ=0.004 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 4.486\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-4.904, 3.574] μ=-1.743e-06 σ=0.004 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 11.590\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-4.996, 3.644] μ=-1.771e-06 σ=0.004 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 12.107\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-5.061, 3.694] μ=-1.794e-06 σ=0.004 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.612\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-5.065, 3.697] μ=-1.799e-06 σ=0.004 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.524\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-5.065, 3.697] μ=-1.804e-06 σ=0.004 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 11.772\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-5.081, 3.708] μ=-1.808e-06 σ=0.004 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.954\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-5.264, 3.849] μ=-1.863e-06 σ=0.004 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.421\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-5.268, 3.852] μ=-1.865e-06 σ=0.004 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.825\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-5.344, 3.910] μ=-1.835e-06 σ=0.004 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.026\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-5.410, 3.960] μ=-1.824e-06 σ=0.004 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 16.068\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-5.425, 3.972] μ=-1.828e-06 σ=0.004 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.030\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-5.475, 4.010] μ=-1.849e-06 σ=0.004 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 13.008\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-5.482, 4.016] μ=-1.848e-06 σ=0.004 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.895\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-5.494, 4.024] μ=-1.852e-06 σ=0.004 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 12.248\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-5.697, 4.180] μ=-1.898e-06 σ=0.004 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.060\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-5.697, 4.180] μ=-1.899e-06 σ=0.004 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.621\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-5.720, 4.198] μ=-1.909e-06 σ=0.004 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.848\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-5.727, 4.203] μ=-1.911e-06 σ=0.004 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 6.535\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-5.731, 4.206] μ=-1.910e-06 σ=0.004 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 3.628\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-5.731, 4.206] μ=-1.910e-06 σ=0.004 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 5.241\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-5.731, 4.206] μ=-1.910e-06 σ=0.004 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.423\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-5.812, 4.268] μ=-1.905e-06 σ=0.004 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.155\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-5.915, 4.347] μ=-1.913e-06 σ=0.004 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 5.351\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-5.915, 4.347] μ=-1.913e-06 σ=0.004 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.891\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-5.938, 4.365] μ=-1.920e-06 σ=0.004 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.769\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-6.080, 4.474] μ=-1.971e-06 σ=0.005 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.285\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-6.091, 4.483] μ=-1.973e-06 σ=0.005 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 6.516\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-6.099, 4.488] μ=-1.975e-06 σ=0.005 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 6.782\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-6.095, 4.485] μ=-1.975e-06 σ=0.005 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.663\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-6.095, 4.486] μ=-1.983e-06 σ=0.005 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 5.922\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-6.091, 4.483] μ=-1.984e-06 σ=0.005 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.007\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-6.091, 4.483] μ=-1.984e-06 σ=0.005 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.000\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-6.087, 4.480] μ=-1.985e-06 σ=0.005 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 13.724\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-6.087, 4.479] μ=-1.986e-06 σ=0.005 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 13.506\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-6.087, 4.479] μ=-1.985e-06 σ=0.005 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.465\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-6.090, 4.482] μ=-1.986e-06 σ=0.005 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.954\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-6.094, 4.485] μ=-1.988e-06 σ=0.005 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 11.206\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-6.102, 4.491] μ=-1.992e-06 σ=0.005 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 13.233\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-6.106, 4.494] μ=-2.037e-06 σ=0.005 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 11.556\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-6.109, 4.496] μ=-2.036e-06 σ=0.005 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 5.096\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-6.109, 4.496] μ=-2.036e-06 σ=0.005 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 13.851\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-6.250, 4.606] μ=-2.126e-06 σ=0.005 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.994\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-6.254, 4.609] μ=-2.127e-06 σ=0.005 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 4.790\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-6.254, 4.609] μ=-2.128e-06 σ=0.005 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.130\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-6.262, 4.615] μ=-2.133e-06 σ=0.005 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.191\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-6.262, 4.615] μ=-2.134e-06 σ=0.005 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.496\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-6.260, 4.613] μ=-2.134e-06 σ=0.005 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.849\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-6.260, 4.613] μ=-2.137e-06 σ=0.005 cuda:0\n",
      "[E17/150 I200/4500]\n",
      "  Loss 9.204548835754395\n",
      "tensor grad AddBackward0 cuda:0 9.205\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-6.333, 4.670] μ=-2.146e-06 σ=0.005 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 6.550\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-6.333, 4.670] μ=-2.144e-06 σ=0.005 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 11.346\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-6.393, 4.716] μ=-2.154e-06 σ=0.005 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 12.218\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-6.393, 4.716] μ=-2.156e-06 σ=0.005 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.275\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-6.397, 4.719] μ=-2.160e-06 σ=0.005 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 12.139\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-6.519, 4.814] μ=-2.178e-06 σ=0.005 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.470\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-6.527, 4.820] μ=-2.179e-06 σ=0.005 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.462\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-6.527, 4.820] μ=-2.179e-06 σ=0.005 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 11.799\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-6.617, 4.890] μ=-2.181e-06 σ=0.005 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.953\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-6.617, 4.890] μ=-2.180e-06 σ=0.005 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.463\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-6.628, 4.899] μ=-2.181e-06 σ=0.005 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.911\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-6.636, 4.904] μ=-2.185e-06 σ=0.005 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.296\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-6.753, 4.996] μ=-2.209e-06 σ=0.005 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 12.644\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-6.860, 5.079] μ=-2.223e-06 σ=0.005 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 12.450\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-6.967, 5.162] μ=-2.247e-06 σ=0.005 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 11.369\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-6.975, 5.168] μ=-2.250e-06 σ=0.005 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 5.831\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-6.975, 5.168] μ=-2.250e-06 σ=0.005 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.341\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-6.983, 5.174] μ=-2.251e-06 σ=0.005 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 11.958\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-7.059, 5.233] μ=-2.257e-06 σ=0.005 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.294\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-7.059, 5.233] μ=-2.256e-06 σ=0.005 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.851\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-7.128, 5.287] μ=-2.279e-06 σ=0.005 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 12.462\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-7.217, 5.356] μ=-2.314e-06 σ=0.005 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 6.953\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-7.217, 5.356] μ=-2.314e-06 σ=0.005 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 11.387\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-7.217, 5.356] μ=-2.312e-06 σ=0.005 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.905\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-7.224, 5.362] μ=-2.314e-06 σ=0.005 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 12.304\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-7.232, 5.368] μ=-2.321e-06 σ=0.005 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 6.290\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-7.232, 5.368] μ=-2.319e-06 σ=0.005 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.774\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-7.255, 5.386] μ=-2.370e-06 σ=0.005 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 13.177\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-7.258, 5.388] μ=-2.373e-06 σ=0.005 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.568\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-7.254, 5.385] μ=-2.371e-06 σ=0.005 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.117\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-7.250, 5.382] μ=-2.370e-06 σ=0.005 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 11.225\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-7.334, 5.448] μ=-2.395e-06 σ=0.006 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 4.410\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-7.334, 5.448] μ=-2.395e-06 σ=0.006 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 6.883\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-7.338, 5.451] μ=-2.395e-06 σ=0.006 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 15.142\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-7.344, 5.455] μ=-2.399e-06 σ=0.006 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 12.517\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-7.362, 5.470] μ=-2.411e-06 σ=0.006 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 12.176\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-7.420, 5.514] μ=-2.427e-06 σ=0.006 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.787\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-7.424, 5.517] μ=-2.427e-06 σ=0.006 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.428\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-7.431, 5.523] μ=-2.429e-06 σ=0.006 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.407\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-7.443, 5.532] μ=-2.436e-06 σ=0.006 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.918\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-7.443, 5.532] μ=-2.437e-06 σ=0.006 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 5.984\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-7.443, 5.532] μ=-2.437e-06 σ=0.006 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.637\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-7.527, 5.598] μ=-2.451e-06 σ=0.006 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 15.201\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-7.546, 5.613] μ=-2.458e-06 σ=0.006 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.953\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-7.592, 5.649] μ=-2.477e-06 σ=0.006 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.830\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-7.592, 5.649] μ=-2.476e-06 σ=0.006 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.523\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-7.592, 5.649] μ=-2.476e-06 σ=0.006 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 5.082\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-7.592, 5.649] μ=-2.475e-06 σ=0.006 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.771\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-7.592, 5.649] μ=-2.476e-06 σ=0.006 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.962\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-7.592, 5.649] μ=-2.477e-06 σ=0.006 cuda:0\n",
      "[E17/150 I250/4500]\n",
      "  Loss 8.14299201965332\n",
      "tensor grad AddBackward0 cuda:0 8.143\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-7.604, 5.658] μ=-2.481e-06 σ=0.006 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 12.599\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-7.604, 5.658] μ=-2.480e-06 σ=0.006 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.426\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-7.615, 5.667] μ=-2.480e-06 σ=0.006 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.037\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-7.615, 5.667] μ=-2.481e-06 σ=0.006 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 11.836\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-7.627, 5.676] μ=-2.482e-06 σ=0.006 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.470\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-7.631, 5.679] μ=-2.484e-06 σ=0.006 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.847\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-7.631, 5.679] μ=-2.487e-06 σ=0.006 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 12.185\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-7.777, 5.794] μ=-2.496e-06 σ=0.006 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.699\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-7.777, 5.794] μ=-2.496e-06 σ=0.006 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 11.573\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-7.780, 5.797] μ=-2.495e-06 σ=0.006 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 14.611\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-7.800, 5.812] μ=-2.499e-06 σ=0.006 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 12.192\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-7.803, 5.815] μ=-2.506e-06 σ=0.006 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 11.228\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-7.872, 5.869] μ=-2.562e-06 σ=0.006 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.331\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-7.872, 5.869] μ=-2.569e-06 σ=0.006 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.359\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-7.872, 5.869] μ=-2.569e-06 σ=0.006 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 11.677\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-7.972, 5.948] μ=-2.588e-06 σ=0.006 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 4.667\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-7.972, 5.948] μ=-2.588e-06 σ=0.006 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.581\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-8.087, 6.038] μ=-2.611e-06 σ=0.006 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.171\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-8.152, 6.089] μ=-2.625e-06 σ=0.006 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 12.793\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-8.167, 6.101] μ=-2.626e-06 σ=0.006 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 18.754\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-8.340, 6.237] μ=-2.698e-06 σ=0.006 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.896\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-8.342, 6.239] μ=-2.699e-06 σ=0.006 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.881\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-8.342, 6.239] μ=-2.701e-06 σ=0.006 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.053\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-8.451, 6.325] μ=-2.728e-06 σ=0.006 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.861\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-8.459, 6.331] μ=-2.734e-06 σ=0.006 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 12.818\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-8.463, 6.334] μ=-2.733e-06 σ=0.006 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 11.951\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-8.567, 6.415] μ=-2.723e-06 σ=0.006 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.041\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-8.567, 6.415] μ=-2.723e-06 σ=0.006 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.203\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-8.647, 6.479] μ=-2.695e-06 σ=0.006 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 11.697\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-8.674, 6.500] μ=-2.687e-06 σ=0.006 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.627\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-8.681, 6.506] μ=-2.687e-06 σ=0.006 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.195\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-8.677, 6.503] μ=-2.688e-06 σ=0.006 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 6.235\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-8.685, 6.509] μ=-2.687e-06 σ=0.006 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 5.009\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-8.685, 6.509] μ=-2.687e-06 σ=0.006 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 12.466\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-8.730, 6.545] μ=-2.715e-06 σ=0.006 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 12.437\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-8.915, 6.690] μ=-2.772e-06 σ=0.007 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.430\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-8.915, 6.690] μ=-2.775e-06 σ=0.007 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.123\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-8.915, 6.690] μ=-2.774e-06 σ=0.007 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.891\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-8.918, 6.693] μ=-2.772e-06 σ=0.007 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.118\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-8.918, 6.693] μ=-2.772e-06 σ=0.007 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 3.691\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-8.918, 6.693] μ=-2.772e-06 σ=0.007 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 5.879\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-8.918, 6.693] μ=-2.774e-06 σ=0.007 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.245\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-8.934, 6.705] μ=-2.775e-06 σ=0.007 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 17.854\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-9.232, 6.940] μ=-2.866e-06 σ=0.007 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 4.758\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-9.232, 6.940] μ=-2.866e-06 σ=0.007 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.597\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-9.236, 6.943] μ=-2.869e-06 σ=0.007 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 6.695\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-9.239, 6.946] μ=-2.870e-06 σ=0.007 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 14.021\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-9.247, 6.952] μ=-2.872e-06 σ=0.007 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.757\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-9.258, 6.962] μ=-2.875e-06 σ=0.007 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.013\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-9.293, 6.989] μ=-2.899e-06 σ=0.007 cuda:0\n",
      "[E17/150 I300/4500]\n",
      "  Loss 8.612948417663574\n",
      "tensor grad AddBackward0 cuda:0 8.613\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-9.293, 6.989] μ=-2.900e-06 σ=0.007 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 11.273\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-9.339, 7.025] μ=-2.906e-06 σ=0.007 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.074\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-9.342, 7.028] μ=-2.906e-06 σ=0.007 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 11.193\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-9.388, 7.064] μ=-2.911e-06 σ=0.007 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 11.689\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-9.549, 7.191] μ=-2.947e-06 σ=0.007 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.320\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-9.598, 7.231] μ=-2.949e-06 σ=0.007 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.434\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-9.686, 7.300] μ=-2.917e-06 σ=0.007 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.629\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-9.713, 7.322] μ=-2.925e-06 σ=0.007 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.565\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-9.717, 7.325] μ=-2.926e-06 σ=0.007 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.518\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-9.717, 7.325] μ=-2.927e-06 σ=0.007 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.787\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-9.720, 7.328] μ=-2.928e-06 σ=0.007 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.956\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-9.724, 7.331] μ=-2.927e-06 σ=0.007 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 11.833\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-9.743, 7.346] μ=-2.935e-06 σ=0.007 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.967\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-9.743, 7.346] μ=-2.935e-06 σ=0.007 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.231\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-9.816, 7.404] μ=-2.909e-06 σ=0.007 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.635\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-9.888, 7.462] μ=-2.954e-06 σ=0.007 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 11.716\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-10.019, 7.566] μ=-2.964e-06 σ=0.007 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 5.145\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-10.019, 7.566] μ=-2.964e-06 σ=0.007 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.597\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-10.019, 7.566] μ=-2.962e-06 σ=0.007 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.766\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-10.019, 7.566] μ=-2.960e-06 σ=0.007 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.845\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-10.022, 7.569] μ=-2.964e-06 σ=0.007 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.208\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-10.030, 7.575] μ=-2.971e-06 σ=0.007 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 13.611\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-10.114, 7.643] μ=-3.016e-06 σ=0.007 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.259\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-10.114, 7.643] μ=-3.016e-06 σ=0.007 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.119\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-10.129, 7.655] μ=-3.023e-06 σ=0.007 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 11.514\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-10.248, 7.750] μ=-3.086e-06 σ=0.008 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 11.690\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-10.248, 7.750] μ=-3.085e-06 σ=0.008 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 5.473\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-10.248, 7.750] μ=-3.086e-06 σ=0.008 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 14.296\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-10.367, 7.845] μ=-3.111e-06 σ=0.008 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.137\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-10.382, 7.857] μ=-3.112e-06 σ=0.008 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.438\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-10.382, 7.857] μ=-3.112e-06 σ=0.008 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.400\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-10.489, 7.943] μ=-3.111e-06 σ=0.008 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 6.607\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-10.489, 7.944] μ=-3.111e-06 σ=0.008 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 11.988\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-10.489, 7.943] μ=-3.110e-06 σ=0.008 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 15.366\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-10.658, 8.079] μ=-3.155e-06 σ=0.008 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 12.310\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-10.734, 8.140] μ=-3.169e-06 σ=0.008 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 6.921\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-10.738, 8.144] μ=-3.173e-06 σ=0.008 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 13.138\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-10.746, 8.150] μ=-3.177e-06 σ=0.008 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 14.550\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-10.765, 8.165] μ=-3.183e-06 σ=0.008 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.095\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-10.765, 8.165] μ=-3.181e-06 σ=0.008 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 11.031\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-10.773, 8.171] μ=-3.187e-06 σ=0.008 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.453\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-10.776, 8.174] μ=-3.189e-06 σ=0.008 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.180\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-10.788, 8.184] μ=-3.190e-06 σ=0.008 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 11.699\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-10.788, 8.184] μ=-3.190e-06 σ=0.008 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.238\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-10.807, 8.199] μ=-3.196e-06 σ=0.008 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 15.137\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-10.819, 8.208] μ=-3.199e-06 σ=0.008 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.520\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-10.819, 8.208] μ=-3.201e-06 σ=0.008 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.496\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-10.826, 8.214] μ=-3.202e-06 σ=0.008 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 4.898\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-10.826, 8.215] μ=-3.202e-06 σ=0.008 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 6.491\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-10.826, 8.215] μ=-3.200e-06 σ=0.008 cuda:0\n",
      "[E17/150 I350/4500]\n",
      "  Loss 7.925163745880127\n",
      "tensor grad AddBackward0 cuda:0 7.925\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-10.826, 8.215] μ=-3.199e-06 σ=0.008 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 6.106\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-10.826, 8.215] μ=-3.199e-06 σ=0.008 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 5.625\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-10.826, 8.215] μ=-3.199e-06 σ=0.008 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 5.567\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-10.826, 8.215] μ=-3.199e-06 σ=0.008 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.649\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-10.834, 8.221] μ=-3.202e-06 σ=0.008 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.200\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-10.834, 8.221] μ=-3.202e-06 σ=0.008 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 12.012\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-10.834, 8.221] μ=-3.206e-06 σ=0.008 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.226\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-10.838, 8.224] μ=-3.206e-06 σ=0.008 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.485\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-10.872, 8.252] μ=-3.209e-06 σ=0.008 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.831\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-10.903, 8.276] μ=-3.145e-06 σ=0.008 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.905\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-10.903, 8.276] μ=-3.145e-06 σ=0.008 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.492\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-10.933, 8.301] μ=-3.162e-06 σ=0.008 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.426\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-10.933, 8.301] μ=-3.161e-06 σ=0.008 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 5.805\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-10.933, 8.301] μ=-3.161e-06 σ=0.008 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 6.690\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-11.025, 8.375] μ=-3.231e-06 σ=0.008 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.459\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-11.036, 8.384] μ=-3.236e-06 σ=0.008 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 11.928\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-11.036, 8.384] μ=-3.237e-06 σ=0.008 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 12.035\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-11.070, 8.412] μ=-3.254e-06 σ=0.008 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 12.264\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-11.082, 8.421] μ=-3.288e-06 σ=0.008 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.007\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-11.090, 8.428] μ=-3.291e-06 σ=0.008 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.699\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-11.093, 8.431] μ=-3.293e-06 σ=0.008 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.585\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-11.101, 8.437] μ=-3.294e-06 σ=0.008 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.405\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-11.196, 8.514] μ=-3.319e-06 σ=0.008 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.828\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-11.200, 8.517] μ=-3.319e-06 σ=0.008 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.122\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-11.231, 8.542] μ=-3.328e-06 σ=0.008 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.178\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-11.242, 8.552] μ=-3.336e-06 σ=0.008 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 4.238\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-11.242, 8.552] μ=-3.337e-06 σ=0.008 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.516\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-11.250, 8.558] μ=-3.339e-06 σ=0.008 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 17.040\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-11.449, 8.720] μ=-3.376e-06 σ=0.008 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.668\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-11.460, 8.729] μ=-3.385e-06 σ=0.008 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 15.690\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-11.472, 8.738] μ=-3.387e-06 σ=0.008 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 12.238\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-11.664, 8.894] μ=-3.436e-06 σ=0.009 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 4.373\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-11.664, 8.894] μ=-3.436e-06 σ=0.009 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 12.201\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-11.790, 8.997] μ=-3.493e-06 σ=0.009 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.407\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-11.790, 8.997] μ=-3.493e-06 σ=0.009 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 6.101\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-11.790, 8.997] μ=-3.492e-06 σ=0.009 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 6.397\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-11.790, 8.997] μ=-3.492e-06 σ=0.009 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.051\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-11.790, 8.997] μ=-3.492e-06 σ=0.009 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.640\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-11.794, 9.000] μ=-3.493e-06 σ=0.009 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.699\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-11.878, 9.069] μ=-3.501e-06 σ=0.009 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.896\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-11.886, 9.075] μ=-3.506e-06 σ=0.009 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.671\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-11.886, 9.075] μ=-3.506e-06 σ=0.009 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 12.371\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-11.997, 9.166] μ=-3.554e-06 σ=0.009 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 4.352\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-11.997, 9.166] μ=-3.554e-06 σ=0.009 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.408\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-11.997, 9.166] μ=-3.554e-06 σ=0.009 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 11.627\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-12.004, 9.172] μ=-3.554e-06 σ=0.009 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 6.585\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-12.008, 9.175] μ=-3.555e-06 σ=0.009 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.195\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-12.023, 9.188] μ=-3.559e-06 σ=0.009 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.978\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-12.027, 9.191] μ=-3.558e-06 σ=0.009 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.895\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-12.027, 9.191] μ=-3.558e-06 σ=0.009 cuda:0\n",
      "[E17/150 I400/4500]\n",
      "  Loss 7.2730021476745605\n",
      "tensor grad AddBackward0 cuda:0 7.273\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-12.035, 9.197] μ=-3.560e-06 σ=0.009 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 5.133\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-12.035, 9.197] μ=-3.560e-06 σ=0.009 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 14.979\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-12.169, 9.307] μ=-3.600e-06 σ=0.009 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.036\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-12.180, 9.316] μ=-3.601e-06 σ=0.009 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.665\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-12.180, 9.316] μ=-3.601e-06 σ=0.009 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 11.459\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-12.218, 9.347] μ=-3.579e-06 σ=0.009 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 11.185\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-12.299, 9.413] μ=-3.606e-06 σ=0.009 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.794\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-12.322, 9.432] μ=-3.613e-06 σ=0.009 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.215\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-12.333, 9.441] μ=-3.616e-06 σ=0.009 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.388\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-12.406, 9.501] μ=-3.655e-06 σ=0.009 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 6.834\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-12.406, 9.501] μ=-3.655e-06 σ=0.009 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.351\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-12.406, 9.501] μ=-3.655e-06 σ=0.009 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 4.648\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-12.406, 9.501] μ=-3.655e-06 σ=0.009 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.644\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-12.418, 9.511] μ=-3.662e-06 σ=0.009 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 13.935\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-12.433, 9.523] μ=-3.668e-06 σ=0.009 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.209\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-12.437, 9.526] μ=-3.670e-06 σ=0.009 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 4.636\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-12.437, 9.526] μ=-3.670e-06 σ=0.009 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.436\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-12.437, 9.526] μ=-3.669e-06 σ=0.009 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 4.505\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-12.437, 9.526] μ=-3.669e-06 σ=0.009 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.236\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-12.445, 9.533] μ=-3.669e-06 σ=0.009 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.766\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-12.610, 9.668] μ=-3.708e-06 σ=0.009 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 4.978\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-12.610, 9.668] μ=-3.708e-06 σ=0.009 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.331\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-12.606, 9.665] μ=-3.708e-06 σ=0.009 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.573\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-12.614, 9.672] μ=-3.711e-06 σ=0.009 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.493\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-12.618, 9.675] μ=-3.713e-06 σ=0.009 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.427\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-12.618, 9.675] μ=-3.713e-06 σ=0.009 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 6.867\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-12.618, 9.675] μ=-3.713e-06 σ=0.009 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.739\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-12.740, 9.776] μ=-3.699e-06 σ=0.009 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 5.271\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-12.740, 9.776] μ=-3.699e-06 σ=0.009 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.780\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-12.744, 9.779] μ=-3.701e-06 σ=0.009 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.623\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-12.760, 9.791] μ=-3.703e-06 σ=0.009 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.123\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-12.775, 9.804] μ=-3.707e-06 σ=0.009 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.512\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-12.779, 9.807] μ=-3.707e-06 σ=0.009 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.796\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-12.783, 9.810] μ=-3.704e-06 σ=0.009 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.810\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-12.790, 9.816] μ=-3.703e-06 σ=0.009 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.417\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-12.790, 9.816] μ=-3.703e-06 σ=0.009 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.177\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-12.794, 9.820] μ=-3.706e-06 σ=0.009 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 13.171\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-12.898, 9.905] μ=-3.760e-06 σ=0.009 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 13.249\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-13.116, 10.084] μ=-3.833e-06 σ=0.010 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.326\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-13.116, 10.084] μ=-3.836e-06 σ=0.010 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.351\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-13.120, 10.087] μ=-3.835e-06 σ=0.010 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.841\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-13.120, 10.087] μ=-3.835e-06 σ=0.010 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 6.790\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-13.120, 10.087] μ=-3.834e-06 σ=0.010 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.790\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-13.124, 10.090] μ=-3.835e-06 σ=0.010 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.636\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-13.127, 10.093] μ=-3.835e-06 σ=0.010 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.147\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-13.135, 10.099] μ=-3.836e-06 σ=0.010 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.789\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-13.131, 10.096] μ=-3.835e-06 σ=0.010 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.849\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-13.131, 10.096] μ=-3.837e-06 σ=0.010 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.160\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-13.223, 10.172] μ=-3.832e-06 σ=0.010 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 12.152\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-13.231, 10.178] μ=-3.836e-06 σ=0.010 cuda:0\n",
      "[E17/150 I450/4500]\n",
      "  Loss 9.650907516479492\n",
      "tensor grad AddBackward0 cuda:0 9.651\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-13.299, 10.235] μ=-3.852e-06 σ=0.010 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.438\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-13.303, 10.238] μ=-3.853e-06 σ=0.010 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.973\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-13.319, 10.250] μ=-3.857e-06 σ=0.010 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.875\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-13.334, 10.263] μ=-3.900e-06 σ=0.010 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.980\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-13.338, 10.266] μ=-3.899e-06 σ=0.010 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.552\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-13.345, 10.272] μ=-3.899e-06 σ=0.010 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.581\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-13.349, 10.276] μ=-3.898e-06 σ=0.010 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.383\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-13.349, 10.276] μ=-3.898e-06 σ=0.010 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.530\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-13.361, 10.285] μ=-3.902e-06 σ=0.010 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 6.089\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-13.361, 10.285] μ=-3.904e-06 σ=0.010 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 13.743\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-13.433, 10.345] μ=-3.889e-06 σ=0.010 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 6.726\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-13.433, 10.345] μ=-3.889e-06 σ=0.010 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.792\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-13.445, 10.354] μ=-3.892e-06 σ=0.010 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 11.485\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-13.510, 10.408] μ=-3.891e-06 σ=0.010 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.209\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-13.510, 10.408] μ=-3.889e-06 σ=0.010 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 5.449\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-13.510, 10.408] μ=-3.889e-06 σ=0.010 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.616\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-13.556, 10.446] μ=-3.883e-06 σ=0.010 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.521\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-13.571, 10.459] μ=-3.883e-06 σ=0.010 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.910\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-13.579, 10.465] μ=-3.883e-06 σ=0.010 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 5.798\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-13.579, 10.465] μ=-3.883e-06 σ=0.010 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.906\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-13.579, 10.465] μ=-3.886e-06 σ=0.010 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 4.791\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-13.586, 10.471] μ=-3.888e-06 σ=0.010 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 6.038\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-13.586, 10.471] μ=-3.888e-06 σ=0.010 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.928\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-13.586, 10.471] μ=-3.887e-06 σ=0.010 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.078\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-13.648, 10.522] μ=-3.905e-06 σ=0.010 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.210\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-13.728, 10.588] μ=-3.947e-06 σ=0.010 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.489\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-13.843, 10.683] μ=-3.981e-06 σ=0.010 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.390\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-13.847, 10.686] μ=-3.981e-06 σ=0.010 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 14.469\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-14.069, 10.870] μ=-4.057e-06 σ=0.010 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.541\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-14.077, 10.877] μ=-4.056e-06 σ=0.010 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.151\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-14.084, 10.883] μ=-4.058e-06 σ=0.010 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.181\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-14.096, 10.892] μ=-4.058e-06 σ=0.010 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 6.730\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-14.096, 10.892] μ=-4.058e-06 σ=0.010 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 6.725\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-14.096, 10.892] μ=-4.056e-06 σ=0.010 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 11.262\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-14.103, 10.899] μ=-4.056e-06 σ=0.010 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.435\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-14.107, 10.902] μ=-4.056e-06 σ=0.010 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 12.249\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-14.199, 10.978] μ=-4.075e-06 σ=0.010 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 4.448\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-14.199, 10.978] μ=-4.075e-06 σ=0.010 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.186\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-14.203, 10.981] μ=-4.075e-06 σ=0.010 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.851\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-14.207, 10.984] μ=-4.077e-06 σ=0.010 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.223\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-14.218, 10.994] μ=-4.082e-06 σ=0.010 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.779\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-14.218, 10.994] μ=-4.082e-06 σ=0.010 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 5.984\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-14.218, 10.994] μ=-4.082e-06 σ=0.010 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.544\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-14.222, 10.997] μ=-4.084e-06 σ=0.010 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.765\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-14.352, 11.105] μ=-4.122e-06 σ=0.010 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.693\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-14.452, 11.188] μ=-4.105e-06 σ=0.010 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 6.698\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-14.460, 11.194] μ=-4.106e-06 σ=0.010 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.317\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-14.460, 11.194] μ=-4.106e-06 σ=0.010 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 13.018\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-14.517, 11.242] μ=-4.142e-06 σ=0.011 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 6.407\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-14.517, 11.242] μ=-4.142e-06 σ=0.011 cuda:0\n",
      "[E17/150 I500/4500]\n",
      "  Loss 5.065629959106445\n",
      "tensor grad AddBackward0 cuda:0 5.066\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-14.521, 11.245] μ=-4.142e-06 σ=0.011 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.212\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-14.528, 11.251] μ=-4.145e-06 σ=0.011 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.626\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-14.536, 11.258] μ=-4.148e-06 σ=0.011 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.028\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-14.536, 11.258] μ=-4.149e-06 σ=0.011 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 11.552\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-14.670, 11.369] μ=-4.161e-06 σ=0.011 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.052\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-14.670, 11.369] μ=-4.164e-06 σ=0.011 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 12.158\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-14.770, 11.452] μ=-4.183e-06 σ=0.011 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.620\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-14.770, 11.452] μ=-4.183e-06 σ=0.011 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.851\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-14.770, 11.452] μ=-4.183e-06 σ=0.011 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.967\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-14.770, 11.452] μ=-4.182e-06 σ=0.011 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 5.310\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-14.770, 11.452] μ=-4.182e-06 σ=0.011 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.334\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-14.770, 11.452] μ=-4.184e-06 σ=0.011 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 6.483\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-14.904, 11.563] μ=-4.220e-06 σ=0.011 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 4.948\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-14.904, 11.563] μ=-4.220e-06 σ=0.011 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.674\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-14.900, 11.560] μ=-4.220e-06 σ=0.011 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 3.889\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-14.900, 11.560] μ=-4.220e-06 σ=0.011 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 15.596\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-15.026, 11.665] μ=-4.278e-06 σ=0.011 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 14.629\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-15.026, 11.665] μ=-4.279e-06 σ=0.011 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.983\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-15.038, 11.675] μ=-4.282e-06 σ=0.011 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.782\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-15.038, 11.675] μ=-4.282e-06 σ=0.011 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 13.539\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-15.187, 11.799] μ=-4.339e-06 σ=0.011 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.464\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-15.294, 11.889] μ=-4.345e-06 σ=0.011 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.436\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-15.298, 11.892] μ=-4.345e-06 σ=0.011 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 6.648\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-15.313, 11.905] μ=-4.345e-06 σ=0.011 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 11.180\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-15.542, 12.096] μ=-4.408e-06 σ=0.011 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 6.759\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-15.542, 12.096] μ=-4.408e-06 σ=0.011 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.164\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-15.554, 12.105] μ=-4.411e-06 σ=0.011 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.831\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-15.565, 12.115] μ=-4.416e-06 σ=0.011 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 6.820\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-15.569, 12.118] μ=-4.419e-06 σ=0.011 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 11.999\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-15.596, 12.140] μ=-4.434e-06 σ=0.011 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 11.138\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-15.603, 12.147] μ=-4.436e-06 σ=0.011 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.539\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-15.615, 12.156] μ=-4.442e-06 σ=0.011 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.166\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-15.622, 12.163] μ=-4.445e-06 σ=0.011 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.659\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-15.622, 12.163] μ=-4.444e-06 σ=0.011 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 11.580\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-15.687, 12.217] μ=-4.488e-06 σ=0.011 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.983\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-15.691, 12.220] μ=-4.488e-06 σ=0.011 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.422\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-15.695, 12.224] μ=-4.489e-06 σ=0.011 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.147\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-15.695, 12.224] μ=-4.489e-06 σ=0.011 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 11.041\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-15.817, 12.326] μ=-4.565e-06 σ=0.011 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.893\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-15.821, 12.329] μ=-4.565e-06 σ=0.011 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 12.396\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-15.836, 12.342] μ=-4.588e-06 σ=0.011 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 6.570\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-15.848, 12.351] μ=-4.590e-06 σ=0.011 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.320\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-15.855, 12.358] μ=-4.592e-06 σ=0.011 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.995\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-15.859, 12.361] μ=-4.594e-06 σ=0.011 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 12.019\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-15.855, 12.358] μ=-4.593e-06 σ=0.011 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 5.270\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-15.855, 12.358] μ=-4.593e-06 σ=0.011 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 6.396\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-15.855, 12.358] μ=-4.592e-06 σ=0.011 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 11.220\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-15.857, 12.360] μ=-4.592e-06 σ=0.011 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.961\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-15.857, 12.360] μ=-4.592e-06 σ=0.011 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.562\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-15.861, 12.363] μ=-4.595e-06 σ=0.012 cuda:0\n",
      "[E17/150 I550/4500]\n",
      "  Loss 9.12363338470459\n",
      "tensor grad AddBackward0 cuda:0 9.124\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-15.930, 12.421] μ=-4.636e-06 σ=0.012 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.624\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-15.934, 12.424] μ=-4.638e-06 σ=0.012 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.972\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-15.953, 12.440] μ=-4.640e-06 σ=0.012 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.857\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-16.056, 12.526] μ=-4.673e-06 σ=0.012 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 6.798\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-16.056, 12.526] μ=-4.673e-06 σ=0.012 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 11.299\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-16.067, 12.536] μ=-4.675e-06 σ=0.012 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.193\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-16.071, 12.539] μ=-4.675e-06 σ=0.012 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.745\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-16.079, 12.546] μ=-4.677e-06 σ=0.012 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 6.486\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-16.079, 12.546] μ=-4.677e-06 σ=0.012 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 12.916\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-16.202, 12.649] μ=-4.693e-06 σ=0.012 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.280\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-16.206, 12.653] μ=-4.695e-06 σ=0.012 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 15.840\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-16.378, 12.797] μ=-4.718e-06 σ=0.012 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.004\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-16.393, 12.810] μ=-4.720e-06 σ=0.012 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.880\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-16.401, 12.817] μ=-4.720e-06 σ=0.012 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.269\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-16.412, 12.826] μ=-4.729e-06 σ=0.012 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.334\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-16.423, 12.836] μ=-4.734e-06 σ=0.012 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.166\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-16.439, 12.849] μ=-4.738e-06 σ=0.012 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.157\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-16.526, 12.923] μ=-4.743e-06 σ=0.012 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.891\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-16.641, 13.019] μ=-4.768e-06 σ=0.012 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 11.144\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-16.656, 13.032] μ=-4.771e-06 σ=0.012 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 11.081\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-16.744, 13.106] μ=-4.799e-06 σ=0.012 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.076\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-16.752, 13.113] μ=-4.800e-06 σ=0.012 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 5.875\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-16.752, 13.113] μ=-4.800e-06 σ=0.012 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.871\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-16.763, 13.122] μ=-4.801e-06 σ=0.012 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.807\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-16.778, 13.135] μ=-4.804e-06 σ=0.012 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 4.414\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-16.778, 13.135] μ=-4.804e-06 σ=0.012 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 5.816\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-16.782, 13.138] μ=-4.804e-06 σ=0.012 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.476\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-16.839, 13.186] μ=-4.810e-06 σ=0.012 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 11.297\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-16.847, 13.193] μ=-4.814e-06 σ=0.012 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.740\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-16.843, 13.190] μ=-4.817e-06 σ=0.012 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.627\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-16.851, 13.196] μ=-4.817e-06 σ=0.012 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 12.343\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-16.862, 13.206] μ=-4.823e-06 σ=0.012 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 6.920\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-16.988, 13.312] μ=-4.827e-06 σ=0.012 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.060\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-16.988, 13.312] μ=-4.827e-06 σ=0.012 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 12.932\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-17.002, 13.323] μ=-4.833e-06 σ=0.012 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.378\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-17.036, 13.352] μ=-4.856e-06 σ=0.012 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.956\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-17.127, 13.430] μ=-4.875e-06 σ=0.012 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 5.891\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-17.123, 13.426] μ=-4.874e-06 σ=0.012 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 3.785\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-17.123, 13.426] μ=-4.874e-06 σ=0.012 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.491\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-17.123, 13.426] μ=-4.873e-06 σ=0.012 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.398\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-17.123, 13.426] μ=-4.877e-06 σ=0.012 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.646\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-17.127, 13.430] μ=-4.881e-06 σ=0.012 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.142\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-17.127, 13.430] μ=-4.883e-06 σ=0.012 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.640\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-17.131, 13.433] μ=-4.887e-06 σ=0.012 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 12.000\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-17.131, 13.433] μ=-4.889e-06 σ=0.012 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.387\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-17.230, 13.517] μ=-4.900e-06 σ=0.013 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.611\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-17.226, 13.513] μ=-4.898e-06 σ=0.013 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 13.010\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-17.287, 13.565] μ=-4.935e-06 σ=0.013 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 11.236\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-17.299, 13.574] μ=-4.938e-06 σ=0.013 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.051\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-17.298, 13.574] μ=-4.946e-06 σ=0.013 cuda:0\n",
      "[E17/150 I600/4500]\n",
      "  Loss 7.905006408691406\n",
      "tensor grad AddBackward0 cuda:0 7.905\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-17.306, 13.581] μ=-4.946e-06 σ=0.013 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 12.786\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-17.321, 13.594] μ=-4.949e-06 σ=0.013 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.725\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-17.320, 13.592] μ=-4.947e-06 σ=0.013 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.820\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-17.361, 13.627] μ=-4.945e-06 σ=0.013 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 11.495\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-17.426, 13.682] μ=-4.968e-06 σ=0.013 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 14.147\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-17.422, 13.679] μ=-4.968e-06 σ=0.013 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.472\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-17.429, 13.686] μ=-4.970e-06 σ=0.013 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.485\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-17.445, 13.698] μ=-4.975e-06 σ=0.013 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 6.074\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-17.445, 13.698] μ=-4.976e-06 σ=0.013 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 5.955\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-17.445, 13.698] μ=-4.975e-06 σ=0.013 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.077\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-17.448, 13.702] μ=-4.977e-06 σ=0.013 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 6.473\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-17.460, 13.711] μ=-4.981e-06 σ=0.013 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 14.273\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-17.475, 13.724] μ=-4.984e-06 σ=0.013 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.379\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-17.475, 13.724] μ=-4.984e-06 σ=0.013 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.220\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-17.472, 13.722] μ=-4.984e-06 σ=0.013 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.239\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-17.472, 13.722] μ=-4.984e-06 σ=0.013 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.860\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-17.473, 13.722] μ=-4.984e-06 σ=0.013 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.342\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-17.480, 13.728] μ=-4.987e-06 σ=0.013 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 5.913\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-17.480, 13.728] μ=-4.984e-06 σ=0.013 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 6.095\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-17.480, 13.728] μ=-4.984e-06 σ=0.013 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.461\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-17.488, 13.735] μ=-4.986e-06 σ=0.013 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.921\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-17.613, 13.841] μ=-5.026e-06 σ=0.013 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 14.069\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-17.651, 13.874] μ=-5.048e-06 σ=0.013 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.166\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-17.659, 13.880] μ=-5.050e-06 σ=0.013 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 12.020\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-17.659, 13.880] μ=-5.052e-06 σ=0.013 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.925\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-17.727, 13.938] μ=-5.083e-06 σ=0.013 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.723\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-17.844, 14.038] μ=-5.125e-06 σ=0.013 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 12.990\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-17.920, 14.103] μ=-5.181e-06 σ=0.013 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.569\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-17.920, 14.103] μ=-5.184e-06 σ=0.013 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.578\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-18.041, 14.206] μ=-5.216e-06 σ=0.013 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.340\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-18.053, 14.215] μ=-5.217e-06 σ=0.013 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.931\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-18.057, 14.219] μ=-5.220e-06 σ=0.013 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.679\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-18.060, 14.222] μ=-5.222e-06 σ=0.013 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 6.265\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-18.060, 14.222] μ=-5.222e-06 σ=0.013 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.379\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-18.064, 14.225] μ=-5.223e-06 σ=0.013 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 5.356\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-18.064, 14.225] μ=-5.223e-06 σ=0.013 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.449\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-18.064, 14.225] μ=-5.220e-06 σ=0.013 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 13.630\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-18.121, 14.274] μ=-5.250e-06 σ=0.013 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 14.585\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-18.125, 14.277] μ=-5.252e-06 σ=0.013 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 6.371\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-18.125, 14.277] μ=-5.252e-06 σ=0.013 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.923\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-18.137, 14.287] μ=-5.253e-06 σ=0.013 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 11.949\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-18.140, 14.290] μ=-5.257e-06 σ=0.013 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 6.765\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-18.140, 14.290] μ=-5.257e-06 σ=0.013 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 16.853\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-18.193, 14.335] μ=-5.291e-06 σ=0.013 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.334\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-18.197, 14.338] μ=-5.294e-06 σ=0.013 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.195\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-18.201, 14.342] μ=-5.296e-06 σ=0.013 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 14.144\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-18.330, 14.452] μ=-5.341e-06 σ=0.013 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.413\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-18.326, 14.448] μ=-5.344e-06 σ=0.013 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.265\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-18.326, 14.448] μ=-5.343e-06 σ=0.013 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.541\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-18.334, 14.455] μ=-5.342e-06 σ=0.013 cuda:0\n",
      "[E17/150 I650/4500]\n",
      "  Loss 10.983295440673828\n",
      "tensor grad AddBackward0 cuda:0 10.983\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-18.391, 14.503] μ=-5.335e-06 σ=0.013 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.695\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-18.398, 14.510] μ=-5.338e-06 σ=0.013 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.218\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-18.402, 14.513] μ=-5.341e-06 σ=0.013 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.171\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-18.630, 14.707] μ=-5.379e-06 σ=0.014 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.836\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-18.633, 14.711] μ=-5.379e-06 σ=0.014 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.594\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-18.637, 14.714] μ=-5.380e-06 σ=0.014 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 6.749\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-18.641, 14.717] μ=-5.380e-06 σ=0.014 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.397\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-18.720, 14.785] μ=-5.412e-06 σ=0.014 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.337\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-18.720, 14.785] μ=-5.415e-06 σ=0.014 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 4.461\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-18.720, 14.785] μ=-5.415e-06 σ=0.014 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.430\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-18.720, 14.785] μ=-5.416e-06 σ=0.014 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.380\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-18.724, 14.788] μ=-5.418e-06 σ=0.014 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.518\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-18.811, 14.863] μ=-5.426e-06 σ=0.014 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 12.524\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-18.815, 14.866] μ=-5.432e-06 σ=0.014 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 11.988\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-18.846, 14.892] μ=-5.463e-06 σ=0.014 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 5.861\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-18.846, 14.892] μ=-5.463e-06 σ=0.014 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 5.615\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-18.846, 14.892] μ=-5.463e-06 σ=0.014 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.808\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-18.849, 14.895] μ=-5.465e-06 σ=0.014 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 11.262\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-18.856, 14.902] μ=-5.471e-06 σ=0.014 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 14.483\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-18.856, 14.902] μ=-5.470e-06 σ=0.014 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.466\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-18.856, 14.902] μ=-5.470e-06 σ=0.014 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.206\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-18.860, 14.905] μ=-5.477e-06 σ=0.014 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 11.834\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-18.929, 14.964] μ=-5.512e-06 σ=0.014 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.668\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-18.932, 14.967] μ=-5.517e-06 σ=0.014 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 15.142\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-19.024, 15.045] μ=-5.552e-06 σ=0.014 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 6.192\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-19.024, 15.045] μ=-5.552e-06 σ=0.014 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 5.010\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-19.024, 15.045] μ=-5.552e-06 σ=0.014 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.756\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-19.024, 15.045] μ=-5.551e-06 σ=0.014 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.136\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-19.031, 15.052] μ=-5.552e-06 σ=0.014 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.155\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-19.077, 15.091] μ=-5.562e-06 σ=0.014 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 6.514\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-19.077, 15.091] μ=-5.562e-06 σ=0.014 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 6.031\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-19.077, 15.091] μ=-5.564e-06 σ=0.014 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.516\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-19.103, 15.114] μ=-5.583e-06 σ=0.014 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 12.272\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-19.111, 15.120] μ=-5.586e-06 σ=0.014 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.411\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-19.255, 15.244] μ=-5.609e-06 σ=0.014 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 4.540\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-19.255, 15.244] μ=-5.609e-06 σ=0.014 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 6.722\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-19.259, 15.248] μ=-5.611e-06 σ=0.014 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 13.037\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-19.259, 15.248] μ=-5.612e-06 σ=0.014 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 6.874\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-19.259, 15.248] μ=-5.612e-06 σ=0.014 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.175\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-19.308, 15.290] μ=-5.645e-06 σ=0.014 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 5.596\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-19.308, 15.290] μ=-5.645e-06 σ=0.014 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.417\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-19.323, 15.303] μ=-5.648e-06 σ=0.014 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.973\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-19.331, 15.309] μ=-5.651e-06 σ=0.014 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 13.102\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-19.414, 15.381] μ=-5.679e-06 σ=0.014 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.819\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-19.456, 15.417] μ=-5.708e-06 σ=0.014 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 6.079\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-19.456, 15.417] μ=-5.708e-06 σ=0.014 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 6.332\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-19.456, 15.417] μ=-5.708e-06 σ=0.014 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.425\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-19.486, 15.443] μ=-5.718e-06 σ=0.014 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.491\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-19.501, 15.456] μ=-5.725e-06 σ=0.014 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.247\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-19.501, 15.456] μ=-5.725e-06 σ=0.014 cuda:0\n",
      "[E17/150 I700/4500]\n",
      "  Loss 8.33784008026123\n",
      "tensor grad AddBackward0 cuda:0 8.338\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-19.637, 15.574] μ=-5.772e-06 σ=0.014 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.227\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-19.637, 15.574] μ=-5.773e-06 σ=0.014 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.217\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-19.645, 15.581] μ=-5.777e-06 σ=0.014 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.034\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-19.656, 15.590] μ=-5.779e-06 σ=0.014 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 12.704\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-19.690, 15.620] μ=-5.813e-06 σ=0.015 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 16.657\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-19.766, 15.685] μ=-5.845e-06 σ=0.015 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 13.480\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-19.774, 15.692] μ=-5.846e-06 σ=0.015 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 13.054\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-19.876, 15.780] μ=-5.882e-06 σ=0.015 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.200\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-19.872, 15.777] μ=-5.883e-06 σ=0.015 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 5.888\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-19.869, 15.774] μ=-5.885e-06 σ=0.015 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.374\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-19.869, 15.774] μ=-5.885e-06 σ=0.015 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 17.347\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-20.146, 16.014] μ=-5.912e-06 σ=0.015 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.784\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-20.146, 16.014] μ=-5.911e-06 σ=0.015 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 6.934\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-20.149, 16.018] μ=-5.913e-06 σ=0.015 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.469\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-20.153, 16.021] μ=-5.913e-06 σ=0.015 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.762\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-20.233, 16.090] μ=-5.929e-06 σ=0.015 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.871\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-20.408, 16.242] μ=-5.986e-06 σ=0.015 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.476\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-20.408, 16.242] μ=-5.988e-06 σ=0.015 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.295\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-20.442, 16.272] μ=-5.984e-06 σ=0.015 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 11.261\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-20.450, 16.279] μ=-5.986e-06 σ=0.015 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.587\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-20.453, 16.282] μ=-5.986e-06 σ=0.015 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.840\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-20.461, 16.289] μ=-5.986e-06 σ=0.015 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 18.175\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-20.537, 16.355] μ=-6.027e-06 σ=0.015 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 5.908\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-20.537, 16.355] μ=-6.027e-06 σ=0.015 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.482\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-20.537, 16.355] μ=-6.027e-06 σ=0.015 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.111\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-20.540, 16.358] μ=-6.031e-06 σ=0.015 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.118\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-20.594, 16.404] μ=-6.025e-06 σ=0.015 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.170\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-20.594, 16.404] μ=-6.025e-06 σ=0.015 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 11.388\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-20.620, 16.427] μ=-6.007e-06 σ=0.015 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.469\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-20.647, 16.451] μ=-6.022e-06 σ=0.015 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.292\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-20.757, 16.547] μ=-6.056e-06 σ=0.015 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 6.567\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-20.757, 16.547] μ=-6.056e-06 σ=0.015 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.109\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-20.757, 16.547] μ=-6.056e-06 σ=0.015 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.099\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-20.761, 16.550] μ=-6.059e-06 σ=0.015 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 11.065\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-20.795, 16.580] μ=-6.105e-06 σ=0.015 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 6.154\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-20.795, 16.580] μ=-6.106e-06 σ=0.015 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 6.465\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-20.795, 16.580] μ=-6.106e-06 σ=0.015 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.084\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-20.856, 16.633] μ=-6.147e-06 σ=0.015 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 15.183\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-20.916, 16.686] μ=-6.204e-06 σ=0.015 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 12.610\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-20.981, 16.742] μ=-6.238e-06 σ=0.016 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 5.402\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-20.985, 16.746] μ=-6.238e-06 σ=0.016 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 11.250\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-20.958, 16.723] μ=-6.293e-06 σ=0.016 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.323\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-20.958, 16.723] μ=-6.294e-06 σ=0.016 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.710\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-20.969, 16.732] μ=-6.297e-06 σ=0.016 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.865\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-21.110, 16.856] μ=-6.323e-06 σ=0.016 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.192\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-21.110, 16.856] μ=-6.322e-06 σ=0.016 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 11.166\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-21.114, 16.859] μ=-6.328e-06 σ=0.016 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 4.834\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-21.114, 16.859] μ=-6.328e-06 σ=0.016 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.249\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-21.118, 16.862] μ=-6.331e-06 σ=0.016 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 15.329\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-21.319, 17.039] μ=-6.380e-06 σ=0.016 cuda:0\n",
      "[E17/150 I750/4500]\n",
      "  Loss 8.235313415527344\n",
      "tensor grad AddBackward0 cuda:0 8.235\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-21.323, 17.042] μ=-6.382e-06 σ=0.016 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.200\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-21.415, 17.123] μ=-6.366e-06 σ=0.016 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.179\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-21.574, 17.263] μ=-6.384e-06 σ=0.016 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.168\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-21.574, 17.263] μ=-6.387e-06 σ=0.016 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 11.196\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-21.677, 17.353] μ=-6.459e-06 σ=0.016 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.067\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-21.677, 17.353] μ=-6.460e-06 σ=0.016 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.326\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-21.677, 17.353] μ=-6.459e-06 σ=0.016 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 6.265\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-21.685, 17.359] μ=-6.459e-06 σ=0.016 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.566\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-21.685, 17.359] μ=-6.459e-06 σ=0.016 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 5.466\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-21.685, 17.359] μ=-6.459e-06 σ=0.016 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.443\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-21.688, 17.363] μ=-6.460e-06 σ=0.016 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.490\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-21.696, 17.369] μ=-6.461e-06 σ=0.016 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 11.106\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-21.780, 17.443] μ=-6.478e-06 σ=0.016 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 4.986\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-21.780, 17.443] μ=-6.478e-06 σ=0.016 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.987\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-21.783, 17.446] μ=-6.478e-06 σ=0.016 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.882\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-21.791, 17.453] μ=-6.480e-06 σ=0.016 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.411\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-21.795, 17.456] μ=-6.480e-06 σ=0.016 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 12.529\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-21.886, 17.536] μ=-6.516e-06 σ=0.016 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 13.088\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-21.901, 17.549] μ=-6.515e-06 σ=0.016 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.055\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-21.905, 17.553] μ=-6.521e-06 σ=0.016 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.894\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-21.905, 17.553] μ=-6.522e-06 σ=0.016 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 4.680\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-21.905, 17.553] μ=-6.522e-06 σ=0.016 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 11.675\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-21.901, 17.549] μ=-6.521e-06 σ=0.016 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 6.625\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-21.901, 17.549] μ=-6.521e-06 σ=0.016 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 13.505\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-21.947, 17.589] μ=-6.556e-06 σ=0.016 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 11.251\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-21.947, 17.589] μ=-6.559e-06 σ=0.016 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.758\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-22.053, 17.683] μ=-6.642e-06 σ=0.016 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 11.251\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-22.065, 17.693] μ=-6.645e-06 σ=0.016 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.452\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-22.080, 17.706] μ=-6.645e-06 σ=0.016 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 12.685\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-22.095, 17.719] μ=-6.653e-06 σ=0.016 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 5.460\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-22.095, 17.719] μ=-6.654e-06 σ=0.016 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 4.303\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-22.095, 17.719] μ=-6.654e-06 σ=0.016 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 11.888\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-22.141, 17.759] μ=-6.680e-06 σ=0.016 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 11.969\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-22.255, 17.859] μ=-6.730e-06 σ=0.017 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.414\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-22.255, 17.859] μ=-6.730e-06 σ=0.017 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.697\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-22.285, 17.886] μ=-6.749e-06 σ=0.017 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 6.554\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-22.285, 17.886] μ=-6.749e-06 σ=0.017 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.660\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-22.285, 17.886] μ=-6.749e-06 σ=0.017 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.355\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-22.293, 17.893] μ=-6.750e-06 σ=0.017 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 4.040\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-22.293, 17.893] μ=-6.750e-06 σ=0.017 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.952\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-22.293, 17.893] μ=-6.750e-06 σ=0.017 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 12.107\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-22.300, 17.899] μ=-6.752e-06 σ=0.017 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 13.178\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-22.312, 17.909] μ=-6.757e-06 σ=0.017 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.565\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-22.315, 17.913] μ=-6.760e-06 σ=0.017 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 6.126\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-22.315, 17.913] μ=-6.759e-06 σ=0.017 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.282\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-22.312, 17.909] μ=-6.761e-06 σ=0.017 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 12.091\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-22.312, 17.909] μ=-6.761e-06 σ=0.017 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.422\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-22.315, 17.913] μ=-6.763e-06 σ=0.017 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 4.455\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-22.315, 17.913] μ=-6.763e-06 σ=0.017 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 13.948\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-22.327, 17.923] μ=-6.765e-06 σ=0.017 cuda:0\n",
      "[E17/150 I800/4500]\n",
      "  Loss 7.974077224731445\n",
      "tensor grad AddBackward0 cuda:0 7.974\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-22.323, 17.919] μ=-6.762e-06 σ=0.017 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.843\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-22.448, 18.030] μ=-6.807e-06 σ=0.017 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.534\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-22.558, 18.126] μ=-6.805e-06 σ=0.017 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.311\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-22.562, 18.130] μ=-6.806e-06 σ=0.017 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 6.980\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-22.573, 18.140] μ=-6.807e-06 σ=0.017 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 4.806\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-22.573, 18.140] μ=-6.807e-06 σ=0.017 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 4.645\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-22.573, 18.140] μ=-6.807e-06 σ=0.017 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 12.348\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-22.585, 18.150] μ=-6.811e-06 σ=0.017 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 11.348\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-22.592, 18.156] μ=-6.814e-06 σ=0.017 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 11.635\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-22.596, 18.160] μ=-6.812e-06 σ=0.017 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.642\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-22.596, 18.160] μ=-6.812e-06 σ=0.017 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 11.976\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-22.607, 18.170] μ=-6.821e-06 σ=0.017 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 4.799\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-22.607, 18.170] μ=-6.821e-06 σ=0.017 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.044\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-22.611, 18.173] μ=-6.822e-06 σ=0.017 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 6.879\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-22.611, 18.173] μ=-6.822e-06 σ=0.017 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.134\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-22.611, 18.173] μ=-6.822e-06 σ=0.017 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 12.432\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-22.713, 18.263] μ=-6.846e-06 σ=0.017 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.526\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-22.717, 18.266] μ=-6.847e-06 σ=0.017 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 6.961\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-22.717, 18.266] μ=-6.846e-06 σ=0.017 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.596\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-22.717, 18.266] μ=-6.846e-06 σ=0.017 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.761\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-22.717, 18.266] μ=-6.846e-06 σ=0.017 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.676\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-22.717, 18.266] μ=-6.845e-06 σ=0.017 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.342\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-22.721, 18.270] μ=-6.847e-06 σ=0.017 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 6.908\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-22.721, 18.270] μ=-6.845e-06 σ=0.017 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.548\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-22.729, 18.276] μ=-6.846e-06 σ=0.017 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.146\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-22.729, 18.276] μ=-6.846e-06 σ=0.017 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.844\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-22.736, 18.283] μ=-6.848e-06 σ=0.017 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.025\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-22.740, 18.286] μ=-6.845e-06 σ=0.017 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 5.432\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-22.740, 18.286] μ=-6.844e-06 σ=0.017 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 5.667\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-22.744, 18.290] μ=-6.844e-06 σ=0.017 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 4.061\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-22.744, 18.290] μ=-6.843e-06 σ=0.017 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.834\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-22.785, 18.326] μ=-6.885e-06 σ=0.017 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.224\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-22.789, 18.330] μ=-6.886e-06 σ=0.017 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.784\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-22.815, 18.353] μ=-6.901e-06 σ=0.017 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 12.105\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-22.951, 18.473] μ=-6.920e-06 σ=0.017 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 6.051\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-22.963, 18.483] μ=-6.924e-06 σ=0.017 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.480\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-23.027, 18.540] μ=-6.947e-06 σ=0.017 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 13.973\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-23.031, 18.543] μ=-6.947e-06 σ=0.017 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 5.855\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-23.031, 18.543] μ=-6.947e-06 σ=0.017 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 11.967\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-23.099, 18.603] μ=-6.979e-06 σ=0.017 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 6.735\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-23.099, 18.603] μ=-6.978e-06 σ=0.017 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.435\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-23.276, 18.760] μ=-7.013e-06 σ=0.017 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 11.545\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-23.276, 18.760] μ=-7.013e-06 σ=0.017 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 4.696\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-23.276, 18.760] μ=-7.013e-06 σ=0.017 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.588\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-23.280, 18.763] μ=-7.013e-06 σ=0.017 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 5.957\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-23.280, 18.763] μ=-7.013e-06 σ=0.017 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 6.363\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-23.284, 18.766] μ=-7.015e-06 σ=0.017 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.448\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-23.288, 18.770] μ=-7.015e-06 σ=0.017 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.708\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-23.359, 18.833] μ=-7.027e-06 σ=0.017 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.842\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-23.374, 18.847] μ=-7.031e-06 σ=0.017 cuda:0\n",
      "[E17/150 I850/4500]\n",
      "  Loss 11.860372543334961\n",
      "tensor grad AddBackward0 cuda:0 11.860\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-23.435, 18.900] μ=-6.981e-06 σ=0.018 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.407\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-23.552, 19.004] μ=-7.023e-06 σ=0.018 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 6.791\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-23.579, 19.027] μ=-7.040e-06 σ=0.018 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 14.358\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-23.881, 19.296] μ=-7.125e-06 σ=0.018 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 5.578\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-23.881, 19.296] μ=-7.125e-06 σ=0.018 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 11.193\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-23.995, 19.397] μ=-7.164e-06 σ=0.018 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.677\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-24.002, 19.403] μ=-7.168e-06 σ=0.018 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 5.082\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-24.002, 19.403] μ=-7.168e-06 σ=0.018 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 12.991\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-24.142, 19.527] μ=-7.209e-06 σ=0.018 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 6.883\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-24.142, 19.527] μ=-7.208e-06 σ=0.018 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 6.346\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-24.142, 19.527] μ=-7.208e-06 σ=0.018 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.038\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-24.146, 19.531] μ=-7.211e-06 σ=0.018 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.675\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-24.146, 19.531] μ=-7.213e-06 σ=0.018 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.395\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-24.248, 19.621] μ=-7.194e-06 σ=0.018 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.807\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-24.271, 19.641] μ=-7.199e-06 σ=0.018 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.370\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-24.286, 19.655] μ=-7.201e-06 σ=0.018 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 6.039\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-24.286, 19.655] μ=-7.201e-06 σ=0.018 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.695\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-24.286, 19.655] μ=-7.201e-06 σ=0.018 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 5.464\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-24.286, 19.655] μ=-7.201e-06 σ=0.018 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 4.273\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-24.286, 19.655] μ=-7.201e-06 σ=0.018 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 5.389\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-24.286, 19.655] μ=-7.200e-06 σ=0.018 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 6.786\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-24.286, 19.655] μ=-7.201e-06 σ=0.018 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 4.359\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-24.286, 19.655] μ=-7.201e-06 σ=0.018 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.750\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-24.297, 19.665] μ=-7.202e-06 σ=0.018 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 11.266\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-24.293, 19.662] μ=-7.203e-06 σ=0.018 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 5.183\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-24.293, 19.662] μ=-7.203e-06 σ=0.018 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 6.777\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-24.293, 19.662] μ=-7.203e-06 σ=0.018 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.700\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-24.305, 19.672] μ=-7.205e-06 σ=0.018 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.672\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-24.309, 19.675] μ=-7.206e-06 σ=0.018 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.171\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-24.426, 19.779] μ=-7.238e-06 σ=0.018 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 6.557\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-24.494, 19.840] μ=-7.272e-06 σ=0.018 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 11.302\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-24.565, 19.903] μ=-7.326e-06 σ=0.018 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.858\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-24.633, 19.964] μ=-7.369e-06 σ=0.018 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.146\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-24.750, 20.068] μ=-7.422e-06 σ=0.018 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.642\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-24.754, 20.072] μ=-7.427e-06 σ=0.018 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 5.401\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-24.754, 20.072] μ=-7.427e-06 σ=0.018 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 11.613\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-24.843, 20.151] μ=-7.445e-06 σ=0.018 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 4.960\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-24.843, 20.151] μ=-7.444e-06 σ=0.018 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.743\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-24.843, 20.151] μ=-7.444e-06 σ=0.018 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 13.817\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-24.960, 20.256] μ=-7.455e-06 σ=0.019 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.718\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-24.960, 20.256] μ=-7.455e-06 σ=0.019 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.097\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-25.035, 20.324] μ=-7.476e-06 σ=0.019 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 15.041\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-25.227, 20.496] μ=-7.595e-06 σ=0.019 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 12.733\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-25.333, 20.591] μ=-7.617e-06 σ=0.019 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 4.564\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-25.333, 20.591] μ=-7.617e-06 σ=0.019 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 5.056\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-25.337, 20.595] μ=-7.622e-06 σ=0.019 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.060\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-25.334, 20.592] μ=-7.622e-06 σ=0.019 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 15.814\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-25.338, 20.596] μ=-7.622e-06 σ=0.019 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.294\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-25.406, 20.657] μ=-7.655e-06 σ=0.019 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.231\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-25.406, 20.657] μ=-7.654e-06 σ=0.019 cuda:0\n",
      "[E17/150 I900/4500]\n",
      "  Loss 7.848704814910889\n",
      "tensor grad AddBackward0 cuda:0 7.849\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-25.410, 20.660] μ=-7.654e-06 σ=0.019 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.891\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-25.413, 20.664] μ=-7.654e-06 σ=0.019 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.307\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-25.421, 20.671] μ=-7.658e-06 σ=0.019 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 11.049\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-25.469, 20.714] μ=-7.680e-06 σ=0.019 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.959\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-25.621, 20.852] μ=-7.721e-06 σ=0.019 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.469\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-25.625, 20.855] μ=-7.720e-06 σ=0.019 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.272\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-25.651, 20.879] μ=-7.770e-06 σ=0.019 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 11.150\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-25.655, 20.883] μ=-7.770e-06 σ=0.019 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.391\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-25.659, 20.886] μ=-7.772e-06 σ=0.019 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 12.143\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-25.716, 20.938] μ=-7.762e-06 σ=0.019 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 5.170\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-25.716, 20.938] μ=-7.762e-06 σ=0.019 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 11.190\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-25.719, 20.941] μ=-7.765e-06 σ=0.019 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.122\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-25.722, 20.944] μ=-7.766e-06 σ=0.019 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 5.806\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-25.722, 20.944] μ=-7.766e-06 σ=0.019 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.131\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-25.730, 20.951] μ=-7.767e-06 σ=0.019 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.068\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-25.734, 20.954] μ=-7.767e-06 σ=0.019 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.846\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-25.741, 20.961] μ=-7.769e-06 σ=0.019 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.083\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-25.741, 20.961] μ=-7.770e-06 σ=0.019 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 6.530\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-25.794, 21.009] μ=-7.792e-06 σ=0.019 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.691\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-25.896, 21.102] μ=-7.839e-06 σ=0.019 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.119\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-25.900, 21.106] μ=-7.839e-06 σ=0.019 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.460\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-25.912, 21.116] μ=-7.842e-06 σ=0.019 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.524\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-25.915, 21.120] μ=-7.841e-06 σ=0.019 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 6.424\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-25.919, 21.123] μ=-7.843e-06 σ=0.019 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 5.472\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-25.919, 21.123] μ=-7.843e-06 σ=0.019 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.445\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-25.923, 21.127] μ=-7.847e-06 σ=0.019 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.874\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-25.923, 21.127] μ=-7.849e-06 σ=0.019 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.488\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-25.931, 21.133] μ=-7.855e-06 σ=0.019 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 12.880\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-25.968, 21.168] μ=-7.874e-06 σ=0.019 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.488\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-25.968, 21.168] μ=-7.875e-06 σ=0.019 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 11.057\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-25.968, 21.168] μ=-7.872e-06 σ=0.019 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 6.763\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-26.048, 21.240] μ=-7.863e-06 σ=0.019 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 13.262\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-26.113, 21.299] μ=-7.847e-06 σ=0.019 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 6.333\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-26.124, 21.310] μ=-7.867e-06 σ=0.019 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.770\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-26.128, 21.313] μ=-7.870e-06 σ=0.019 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.106\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-26.128, 21.313] μ=-7.870e-06 σ=0.019 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.919\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-26.154, 21.337] μ=-7.874e-06 σ=0.019 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 6.375\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-26.162, 21.344] μ=-7.874e-06 σ=0.019 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 6.567\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-26.162, 21.344] μ=-7.874e-06 σ=0.019 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.863\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-26.162, 21.344] μ=-7.874e-06 σ=0.019 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.240\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-26.162, 21.344] μ=-7.874e-06 σ=0.019 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 11.332\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-26.170, 21.351] μ=-7.875e-06 σ=0.019 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.452\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-26.177, 21.358] μ=-7.877e-06 σ=0.019 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.028\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-26.181, 21.361] μ=-7.879e-06 σ=0.019 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 11.988\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-26.185, 21.365] μ=-7.879e-06 σ=0.019 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 6.728\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-26.188, 21.368] μ=-7.880e-06 σ=0.019 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.730\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-26.188, 21.368] μ=-7.879e-06 σ=0.019 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 4.810\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-26.188, 21.368] μ=-7.879e-06 σ=0.019 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 13.186\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-26.226, 21.403] μ=-7.889e-06 σ=0.019 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.772\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-26.226, 21.403] μ=-7.888e-06 σ=0.019 cuda:0\n",
      "[E17/150 I950/4500]\n",
      "  Loss 13.371125221252441\n",
      "tensor grad AddBackward0 cuda:0 13.371\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-26.295, 21.465] μ=-7.908e-06 σ=0.020 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.473\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-26.424, 21.582] μ=-7.938e-06 σ=0.020 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.690\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-26.431, 21.589] μ=-7.938e-06 σ=0.020 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.739\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-26.564, 21.710] μ=-8.003e-06 σ=0.020 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.087\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-26.568, 21.714] μ=-8.004e-06 σ=0.020 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.050\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-26.571, 21.717] μ=-8.005e-06 σ=0.020 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.580\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-26.586, 21.731] μ=-8.008e-06 σ=0.020 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.232\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-26.586, 21.731] μ=-8.009e-06 σ=0.020 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.644\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-26.598, 21.741] μ=-8.010e-06 σ=0.020 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.029\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-26.598, 21.741] μ=-8.009e-06 σ=0.020 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.746\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-26.605, 21.748] μ=-8.011e-06 σ=0.020 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.492\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-26.605, 21.748] μ=-8.011e-06 σ=0.020 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.814\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-26.609, 21.751] μ=-8.012e-06 σ=0.020 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.010\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-26.609, 21.751] μ=-8.012e-06 σ=0.020 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 12.527\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-26.617, 21.758] μ=-8.021e-06 σ=0.020 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.517\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-26.651, 21.789] μ=-8.043e-06 σ=0.020 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 4.065\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-26.651, 21.789] μ=-8.043e-06 σ=0.020 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.285\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-26.647, 21.786] μ=-8.043e-06 σ=0.020 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.707\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-26.654, 21.792] μ=-8.045e-06 σ=0.020 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.123\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-26.662, 21.799] μ=-8.046e-06 σ=0.020 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.025\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-26.669, 21.806] μ=-8.048e-06 σ=0.020 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 12.043\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-26.863, 21.982] μ=-8.109e-06 σ=0.020 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 12.885\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-26.866, 21.986] μ=-8.109e-06 σ=0.020 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 13.306\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-26.870, 21.989] μ=-8.105e-06 σ=0.020 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.939\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-26.980, 22.089] μ=-8.099e-06 σ=0.020 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 6.512\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-26.984, 22.092] μ=-8.100e-06 σ=0.020 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.712\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-26.984, 22.092] μ=-8.102e-06 σ=0.020 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.982\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-26.984, 22.092] μ=-8.102e-06 σ=0.020 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.558\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-26.980, 22.089] μ=-8.102e-06 σ=0.020 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 4.950\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-26.980, 22.089] μ=-8.102e-06 σ=0.020 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.404\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-26.976, 22.086] μ=-8.102e-06 σ=0.020 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 6.371\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-26.980, 22.089] μ=-8.103e-06 σ=0.020 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.503\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-26.980, 22.089] μ=-8.104e-06 σ=0.020 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.905\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-27.108, 22.206] μ=-8.134e-06 σ=0.020 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 6.561\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-27.116, 22.213] μ=-8.134e-06 σ=0.020 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.143\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-27.120, 22.217] μ=-8.137e-06 σ=0.020 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 6.523\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-27.120, 22.217] μ=-8.137e-06 σ=0.020 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.006\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-27.124, 22.220] μ=-8.137e-06 σ=0.020 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 3.701\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-27.124, 22.220] μ=-8.137e-06 σ=0.020 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 6.622\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-27.124, 22.220] μ=-8.135e-06 σ=0.020 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.590\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-27.192, 22.282] μ=-8.153e-06 σ=0.020 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.454\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-27.203, 22.292] μ=-8.155e-06 σ=0.020 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 5.847\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-27.203, 22.292] μ=-8.155e-06 σ=0.020 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 11.510\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-27.207, 22.296] μ=-8.156e-06 σ=0.020 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.749\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-27.207, 22.296] μ=-8.155e-06 σ=0.020 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.340\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-27.211, 22.299] μ=-8.155e-06 σ=0.020 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 5.634\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-27.218, 22.306] μ=-8.156e-06 σ=0.020 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 6.838\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-27.218, 22.306] μ=-8.158e-06 σ=0.020 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.759\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-27.282, 22.365] μ=-8.172e-06 σ=0.020 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.301\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-27.282, 22.365] μ=-8.171e-06 σ=0.020 cuda:0\n",
      "[E17/150 I1000/4500]\n",
      "  Loss 7.053870677947998\n",
      "tensor grad AddBackward0 cuda:0 7.054\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-27.286, 22.368] μ=-8.174e-06 σ=0.020 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.603\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-27.286, 22.368] μ=-8.174e-06 σ=0.020 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.247\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-27.286, 22.368] μ=-8.174e-06 σ=0.020 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 11.749\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-27.290, 22.371] μ=-8.175e-06 σ=0.020 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.589\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-27.305, 22.385] μ=-8.180e-06 σ=0.020 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 6.226\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-27.305, 22.385] μ=-8.180e-06 σ=0.020 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 6.748\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-27.305, 22.385] μ=-8.179e-06 σ=0.020 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 6.667\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-27.316, 22.395] μ=-8.181e-06 σ=0.020 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 6.504\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-27.312, 22.392] μ=-8.183e-06 σ=0.020 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 6.072\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-27.312, 22.392] μ=-8.183e-06 σ=0.020 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 11.001\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-27.456, 22.523] μ=-8.199e-06 σ=0.020 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 16.245\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-27.607, 22.661] μ=-8.236e-06 σ=0.020 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 13.488\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-27.659, 22.708] μ=-8.241e-06 σ=0.021 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 6.038\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-27.659, 22.708] μ=-8.239e-06 σ=0.021 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 5.298\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-27.659, 22.708] μ=-8.239e-06 σ=0.021 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 6.935\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-27.666, 22.715] μ=-8.241e-06 σ=0.021 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.039\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-27.666, 22.715] μ=-8.243e-06 σ=0.021 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 5.598\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-27.666, 22.715] μ=-8.243e-06 σ=0.021 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 5.768\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-27.666, 22.715] μ=-8.243e-06 σ=0.021 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.743\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-27.734, 22.777] μ=-8.288e-06 σ=0.021 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.277\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-27.749, 22.791] μ=-8.292e-06 σ=0.021 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.797\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-27.798, 22.835] μ=-8.309e-06 σ=0.021 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 6.414\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-27.798, 22.835] μ=-8.309e-06 σ=0.021 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 15.197\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-27.843, 22.876] μ=-8.370e-06 σ=0.021 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.199\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-27.843, 22.876] μ=-8.370e-06 σ=0.021 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 13.930\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-27.854, 22.887] μ=-8.371e-06 σ=0.021 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 11.787\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-27.865, 22.897] μ=-8.375e-06 σ=0.021 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.653\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-27.873, 22.904] μ=-8.377e-06 σ=0.021 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.146\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-27.877, 22.907] μ=-8.381e-06 σ=0.021 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 12.150\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-27.967, 22.990] μ=-8.423e-06 σ=0.021 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 5.393\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-27.967, 22.990] μ=-8.423e-06 σ=0.021 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.425\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-28.072, 23.087] μ=-8.469e-06 σ=0.021 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 12.414\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-28.166, 23.173] μ=-8.516e-06 σ=0.021 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.716\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-28.178, 23.183] μ=-8.517e-06 σ=0.021 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.332\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-28.178, 23.183] μ=-8.514e-06 σ=0.021 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.571\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-28.185, 23.190] μ=-8.512e-06 σ=0.021 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.355\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-28.193, 23.197] μ=-8.514e-06 σ=0.021 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 11.721\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-28.208, 23.211] μ=-8.520e-06 σ=0.021 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 5.493\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-28.208, 23.211] μ=-8.520e-06 σ=0.021 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.215\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-28.268, 23.266] μ=-8.458e-06 σ=0.021 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.336\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-28.272, 23.270] μ=-8.461e-06 σ=0.021 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 5.676\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-28.272, 23.270] μ=-8.462e-06 σ=0.021 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 4.871\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-28.272, 23.270] μ=-8.462e-06 σ=0.021 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.451\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-28.276, 23.273] μ=-8.461e-06 σ=0.021 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.399\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-28.276, 23.273] μ=-8.461e-06 σ=0.021 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.192\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-28.302, 23.297] μ=-8.482e-06 σ=0.021 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.967\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-28.369, 23.359] μ=-8.502e-06 σ=0.021 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 11.150\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-28.373, 23.362] μ=-8.502e-06 σ=0.021 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.854\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-28.384, 23.373] μ=-8.504e-06 σ=0.021 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.395\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-28.384, 23.373] μ=-8.502e-06 σ=0.021 cuda:0\n",
      "[E17/150 I1050/4500]\n",
      "  Loss 12.669888496398926\n",
      "tensor grad AddBackward0 cuda:0 12.670\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-28.433, 23.418] μ=-8.529e-06 σ=0.021 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 14.001\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-28.501, 23.480] μ=-8.565e-06 σ=0.021 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 6.434\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-28.505, 23.483] μ=-8.566e-06 σ=0.021 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.621\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-28.508, 23.487] μ=-8.566e-06 σ=0.021 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.999\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-28.508, 23.487] μ=-8.567e-06 σ=0.021 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 11.806\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-28.527, 23.504] μ=-8.570e-06 σ=0.021 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 6.022\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-28.527, 23.504] μ=-8.570e-06 σ=0.021 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 5.946\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-28.527, 23.504] μ=-8.570e-06 σ=0.021 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.282\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-28.527, 23.504] μ=-8.570e-06 σ=0.021 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 11.221\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-28.531, 23.507] μ=-8.571e-06 σ=0.021 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 15.350\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-28.606, 23.576] μ=-8.625e-06 σ=0.021 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.865\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-28.621, 23.590] μ=-8.629e-06 σ=0.021 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.868\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-28.632, 23.600] μ=-8.641e-06 σ=0.021 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.362\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-28.636, 23.604] μ=-8.642e-06 σ=0.021 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.809\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-28.640, 23.607] μ=-8.644e-06 σ=0.021 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.479\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-28.745, 23.704] μ=-8.659e-06 σ=0.022 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 13.940\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-28.921, 23.866] μ=-8.743e-06 σ=0.022 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 12.438\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-28.959, 23.901] μ=-8.767e-06 σ=0.022 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 6.523\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-29.027, 23.963] μ=-8.814e-06 σ=0.022 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.237\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-29.038, 23.973] μ=-8.818e-06 σ=0.022 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 6.623\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-29.038, 23.973] μ=-8.818e-06 σ=0.022 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.073\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-29.042, 23.977] μ=-8.819e-06 σ=0.022 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 5.283\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-29.042, 23.977] μ=-8.819e-06 σ=0.022 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.201\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-29.053, 23.987] μ=-8.822e-06 σ=0.022 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.974\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-29.053, 23.987] μ=-8.827e-06 σ=0.022 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.971\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-29.057, 23.990] μ=-8.828e-06 σ=0.022 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 11.387\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-29.319, 24.232] μ=-8.903e-06 σ=0.022 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.516\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-29.481, 24.381] μ=-8.945e-06 σ=0.022 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.468\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-29.544, 24.440] μ=-8.964e-06 σ=0.022 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 13.374\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-29.544, 24.440] μ=-8.968e-06 σ=0.022 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.234\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-29.706, 24.589] μ=-8.990e-06 σ=0.022 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 11.051\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-29.709, 24.592] μ=-8.992e-06 σ=0.022 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 11.232\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-29.709, 24.592] μ=-8.991e-06 σ=0.022 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.356\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-29.709, 24.592] μ=-8.990e-06 σ=0.022 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.822\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-29.938, 24.803] μ=-8.983e-06 σ=0.022 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.658\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-29.938, 24.803] μ=-8.985e-06 σ=0.022 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.840\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-29.938, 24.803] μ=-8.985e-06 σ=0.022 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.010\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-29.938, 24.803] μ=-8.985e-06 σ=0.022 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 6.596\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-29.938, 24.803] μ=-8.985e-06 σ=0.022 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 5.344\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-29.938, 24.803] μ=-8.984e-06 σ=0.022 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.665\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-29.938, 24.803] μ=-8.986e-06 σ=0.022 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 11.878\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-29.946, 24.810] μ=-8.989e-06 σ=0.022 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.948\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-30.058, 24.913] μ=-8.999e-06 σ=0.022 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 6.720\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-30.058, 24.913] μ=-8.998e-06 σ=0.022 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 6.153\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-30.065, 24.920] μ=-8.999e-06 σ=0.022 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.858\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-30.170, 25.017] μ=-9.055e-06 σ=0.023 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 11.105\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-30.170, 25.017] μ=-9.057e-06 σ=0.023 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 11.128\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-30.170, 25.017] μ=-9.052e-06 σ=0.023 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.691\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-30.178, 25.024] μ=-9.053e-06 σ=0.023 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 6.422\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-30.181, 25.028] μ=-9.056e-06 σ=0.023 cuda:0\n",
      "[E17/150 I1100/4500]\n",
      "  Loss 7.190793037414551\n",
      "tensor grad AddBackward0 cuda:0 7.191\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-30.181, 25.028] μ=-9.055e-06 σ=0.023 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.732\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-30.181, 25.028] μ=-9.055e-06 σ=0.023 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.299\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-30.181, 25.028] μ=-9.056e-06 σ=0.023 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.024\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-30.181, 25.028] μ=-9.056e-06 σ=0.023 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.472\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-30.185, 25.031] μ=-9.057e-06 σ=0.023 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.685\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-30.185, 25.031] μ=-9.058e-06 σ=0.023 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 14.833\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-30.189, 25.034] μ=-9.062e-06 σ=0.023 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 11.426\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-30.196, 25.041] μ=-9.062e-06 σ=0.023 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.551\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-30.196, 25.041] μ=-9.062e-06 σ=0.023 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 13.473\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-30.211, 25.055] μ=-9.051e-06 σ=0.023 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.434\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-30.211, 25.055] μ=-9.050e-06 σ=0.023 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 12.526\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-30.245, 25.086] μ=-9.050e-06 σ=0.023 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 6.951\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-30.245, 25.086] μ=-9.050e-06 σ=0.023 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 11.260\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-30.357, 25.190] μ=-9.064e-06 σ=0.023 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 4.840\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-30.357, 25.190] μ=-9.063e-06 σ=0.023 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 6.034\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-30.357, 25.190] μ=-9.064e-06 σ=0.023 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 4.596\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-30.357, 25.190] μ=-9.064e-06 σ=0.023 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.117\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-30.361, 25.194] μ=-9.066e-06 σ=0.023 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.110\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-30.361, 25.194] μ=-9.068e-06 σ=0.023 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 12.744\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-30.514, 25.335] μ=-9.103e-06 σ=0.023 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 12.581\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-30.522, 25.342] μ=-9.108e-06 σ=0.023 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.098\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-30.525, 25.346] μ=-9.109e-06 σ=0.023 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.467\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-30.537, 25.356] μ=-9.152e-06 σ=0.023 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 16.100\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-30.738, 25.543] μ=-9.220e-06 σ=0.023 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.887\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-30.753, 25.557] μ=-9.223e-06 σ=0.023 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 5.539\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-30.753, 25.557] μ=-9.222e-06 σ=0.023 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.186\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-30.757, 25.560] μ=-9.223e-06 σ=0.023 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.999\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-30.895, 25.688] μ=-9.252e-06 σ=0.023 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 3.997\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-30.895, 25.688] μ=-9.252e-06 σ=0.023 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.061\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-30.895, 25.688] μ=-9.252e-06 σ=0.023 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.624\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-30.895, 25.688] μ=-9.249e-06 σ=0.023 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.834\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-30.955, 25.744] μ=-9.297e-06 σ=0.023 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 11.599\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-30.959, 25.747] μ=-9.298e-06 σ=0.023 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.129\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-30.959, 25.747] μ=-9.298e-06 σ=0.023 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 13.929\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-30.992, 25.778] μ=-9.297e-06 σ=0.023 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.208\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-31.022, 25.806] μ=-9.331e-06 σ=0.023 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.082\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-31.022, 25.806] μ=-9.333e-06 σ=0.023 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.777\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-31.022, 25.806] μ=-9.333e-06 σ=0.023 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.328\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-31.022, 25.806] μ=-9.333e-06 σ=0.023 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 6.866\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-31.026, 25.809] μ=-9.336e-06 σ=0.023 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 5.634\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-31.029, 25.813] μ=-9.339e-06 σ=0.023 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 12.507\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-31.033, 25.816] μ=-9.341e-06 σ=0.023 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 12.058\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-31.182, 25.955] μ=-9.343e-06 σ=0.023 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.400\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-31.267, 26.035] μ=-9.366e-06 σ=0.023 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.161\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-31.267, 26.035] μ=-9.364e-06 σ=0.023 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 6.298\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-31.267, 26.035] μ=-9.364e-06 σ=0.023 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 11.009\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-31.368, 26.129] μ=-9.387e-06 σ=0.023 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.286\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-31.376, 26.137] μ=-9.387e-06 σ=0.023 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 14.226\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-31.507, 26.258] μ=-9.437e-06 σ=0.024 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.371\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-31.522, 26.272] μ=-9.439e-06 σ=0.024 cuda:0\n",
      "[E17/150 I1150/4500]\n",
      "  Loss 7.712960243225098\n",
      "tensor grad AddBackward0 cuda:0 7.713\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-31.563, 26.311] μ=-9.440e-06 σ=0.024 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.549\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-31.647, 26.389] μ=-9.462e-06 σ=0.024 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.588\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-31.662, 26.403] μ=-9.464e-06 σ=0.024 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 5.650\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-31.662, 26.403] μ=-9.464e-06 σ=0.024 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 11.985\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-31.778, 26.512] μ=-9.475e-06 σ=0.024 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 12.750\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-31.781, 26.515] μ=-9.477e-06 σ=0.024 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 12.900\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-31.888, 26.615] μ=-9.478e-06 σ=0.024 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.114\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-31.903, 26.629] μ=-9.484e-06 σ=0.024 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.972\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-31.914, 26.640] μ=-9.488e-06 σ=0.024 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 12.175\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-31.914, 26.640] μ=-9.488e-06 σ=0.024 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 6.317\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-31.914, 26.640] μ=-9.488e-06 σ=0.024 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 14.264\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-32.061, 26.778] μ=-9.513e-06 σ=0.024 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 11.092\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-32.174, 26.883] μ=-9.556e-06 σ=0.024 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.936\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-32.196, 26.904] μ=-9.560e-06 σ=0.024 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.124\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-32.289, 26.991] μ=-9.580e-06 σ=0.024 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 5.364\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-32.289, 26.991] μ=-9.580e-06 σ=0.024 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.722\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-32.286, 26.988] μ=-9.579e-06 σ=0.024 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 12.711\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-32.289, 26.991] μ=-9.580e-06 σ=0.024 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 6.359\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-32.289, 26.991] μ=-9.580e-06 σ=0.024 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.755\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-32.293, 26.995] μ=-9.581e-06 σ=0.024 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.950\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-32.293, 26.995] μ=-9.580e-06 σ=0.024 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.582\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-32.484, 27.174] μ=-9.643e-06 σ=0.024 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 14.229\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-32.581, 27.265] μ=-9.690e-06 σ=0.024 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 12.707\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-32.588, 27.272] μ=-9.691e-06 σ=0.024 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.736\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-32.599, 27.282] μ=-9.693e-06 σ=0.024 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 11.180\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-32.610, 27.293] μ=-9.695e-06 σ=0.024 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.557\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-32.614, 27.296] μ=-9.694e-06 σ=0.024 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 5.158\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-32.614, 27.296] μ=-9.694e-06 σ=0.024 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 3.905\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-32.614, 27.296] μ=-9.694e-06 σ=0.024 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 5.512\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-32.618, 27.300] μ=-9.694e-06 σ=0.024 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 11.547\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-32.640, 27.321] μ=-9.673e-06 σ=0.024 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 6.154\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-32.640, 27.321] μ=-9.673e-06 σ=0.024 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.179\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-32.711, 27.387] μ=-9.740e-06 σ=0.024 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.140\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-32.711, 27.387] μ=-9.741e-06 σ=0.024 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.773\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-32.715, 27.391] μ=-9.743e-06 σ=0.024 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.612\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-32.719, 27.394] μ=-9.744e-06 σ=0.024 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 6.055\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-32.722, 27.398] μ=-9.745e-06 σ=0.024 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.597\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-32.730, 27.405] μ=-9.745e-06 σ=0.024 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 12.925\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-32.760, 27.433] μ=-9.775e-06 σ=0.024 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 5.919\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-32.760, 27.433] μ=-9.775e-06 σ=0.024 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.610\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-32.767, 27.440] μ=-9.779e-06 σ=0.024 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 12.866\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-32.834, 27.503] μ=-9.808e-06 σ=0.025 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.904\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-32.872, 27.538] μ=-9.835e-06 σ=0.025 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.685\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-32.872, 27.538] μ=-9.835e-06 σ=0.025 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.409\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-32.879, 27.545] μ=-9.836e-06 σ=0.025 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.936\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-32.950, 27.611] μ=-9.829e-06 σ=0.025 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.836\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-32.957, 27.618] μ=-9.833e-06 σ=0.025 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 4.030\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-32.957, 27.618] μ=-9.832e-06 σ=0.025 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 13.623\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-33.050, 27.706] μ=-9.876e-06 σ=0.025 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 12.907\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-33.054, 27.709] μ=-9.879e-06 σ=0.025 cuda:0\n",
      "[E17/150 I1200/4500]\n",
      "  Loss 14.331045150756836\n",
      "tensor grad AddBackward0 cuda:0 14.331\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-33.061, 27.716] μ=-9.883e-06 σ=0.025 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.421\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-33.061, 27.716] μ=-9.886e-06 σ=0.025 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 4.979\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-33.061, 27.716] μ=-9.886e-06 σ=0.025 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 5.069\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-33.061, 27.716] μ=-9.886e-06 σ=0.025 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 4.786\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-33.061, 27.716] μ=-9.886e-06 σ=0.025 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 5.173\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-33.061, 27.716] μ=-9.886e-06 σ=0.025 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 5.469\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-33.061, 27.716] μ=-9.886e-06 σ=0.025 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.902\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-33.069, 27.723] μ=-9.889e-06 σ=0.025 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.511\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-33.176, 27.824] μ=-9.914e-06 σ=0.025 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 16.482\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-33.284, 27.925] μ=-9.930e-06 σ=0.025 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.681\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-33.284, 27.925] μ=-9.928e-06 σ=0.025 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.964\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-33.295, 27.936] μ=-9.933e-06 σ=0.025 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.769\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-33.299, 27.939] μ=-9.933e-06 σ=0.025 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.073\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-33.366, 28.002] μ=-9.974e-06 σ=0.025 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 11.985\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-33.448, 28.079] μ=-9.994e-06 σ=0.025 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 6.628\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-33.452, 28.083] μ=-9.994e-06 σ=0.025 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 6.705\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-33.496, 28.125] μ=-9.998e-06 σ=0.025 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.454\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-33.567, 28.191] μ=-1.000e-05 σ=0.025 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.403\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-33.567, 28.191] μ=-1.000e-05 σ=0.025 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.022\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-33.597, 28.219] μ=-1.003e-05 σ=0.025 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 3.936\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-33.597, 28.219] μ=-1.003e-05 σ=0.025 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 6.849\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-33.604, 28.226] μ=-1.003e-05 σ=0.025 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 6.167\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-33.612, 28.233] μ=-1.003e-05 σ=0.025 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 13.939\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-33.634, 28.254] μ=-1.001e-05 σ=0.025 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.062\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-33.638, 28.258] μ=-1.001e-05 σ=0.025 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 6.456\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-33.638, 28.258] μ=-1.001e-05 σ=0.025 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 12.173\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-33.716, 28.331] μ=-1.002e-05 σ=0.025 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 11.631\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-33.864, 28.471] μ=-1.006e-05 σ=0.025 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 15.426\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-33.864, 28.471] μ=-1.006e-05 σ=0.025 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 6.171\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-33.864, 28.471] μ=-1.007e-05 σ=0.025 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.139\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-33.868, 28.474] μ=-1.007e-05 σ=0.025 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.011\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-33.867, 28.473] μ=-1.007e-05 σ=0.025 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.846\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-33.867, 28.473] μ=-1.007e-05 σ=0.025 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 6.301\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-33.871, 28.477] μ=-1.007e-05 σ=0.025 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.250\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-33.874, 28.480] μ=-1.007e-05 σ=0.025 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.211\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-33.889, 28.494] μ=-1.007e-05 σ=0.025 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 12.963\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-34.064, 28.659] μ=-1.011e-05 σ=0.025 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.043\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-34.145, 28.735] μ=-1.016e-05 σ=0.026 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 5.746\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-34.145, 28.735] μ=-1.016e-05 σ=0.026 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.210\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-34.153, 28.742] μ=-1.016e-05 σ=0.026 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.428\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-34.156, 28.746] μ=-1.016e-05 σ=0.026 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 12.031\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-34.282, 28.865] μ=-1.019e-05 σ=0.026 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 13.087\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-34.279, 28.861] μ=-1.019e-05 σ=0.026 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 13.895\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-34.423, 28.997] μ=-1.023e-05 σ=0.026 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 3.882\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-34.423, 28.997] μ=-1.023e-05 σ=0.026 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 5.858\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-34.434, 29.008] μ=-1.023e-05 σ=0.026 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.502\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-34.557, 29.123] μ=-1.027e-05 σ=0.026 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 12.253\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-34.627, 29.189] μ=-1.031e-05 σ=0.026 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.037\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-34.634, 29.196] μ=-1.031e-05 σ=0.026 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.882\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-34.638, 29.200] μ=-1.031e-05 σ=0.026 cuda:0\n",
      "[E17/150 I1250/4500]\n",
      "  Loss 5.479242324829102\n",
      "tensor grad AddBackward0 cuda:0 5.479\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-34.653, 29.214] μ=-1.031e-05 σ=0.026 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 12.690\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-34.660, 29.221] μ=-1.031e-05 σ=0.026 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 11.813\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-34.775, 29.329] μ=-1.033e-05 σ=0.026 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.884\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-34.779, 29.332] μ=-1.033e-05 σ=0.026 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.599\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-34.782, 29.336] μ=-1.033e-05 σ=0.026 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 12.133\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-34.782, 29.336] μ=-1.033e-05 σ=0.026 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.216\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-34.782, 29.336] μ=-1.033e-05 σ=0.026 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 5.427\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-34.782, 29.336] μ=-1.033e-05 σ=0.026 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 14.080\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-34.786, 29.339] μ=-1.033e-05 σ=0.026 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.685\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-34.790, 29.343] μ=-1.033e-05 σ=0.026 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.265\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-34.793, 29.346] μ=-1.033e-05 σ=0.026 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 13.190\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-34.793, 29.346] μ=-1.033e-05 σ=0.026 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 12.744\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-34.808, 29.360] μ=-1.034e-05 σ=0.026 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.741\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-34.808, 29.360] μ=-1.034e-05 σ=0.026 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 11.147\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-34.816, 29.367] μ=-1.034e-05 σ=0.026 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.943\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-34.978, 29.521] μ=-1.037e-05 σ=0.026 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 14.269\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-34.978, 29.521] μ=-1.039e-05 σ=0.026 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 6.515\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-34.978, 29.521] μ=-1.039e-05 σ=0.026 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 13.212\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-34.989, 29.532] μ=-1.038e-05 σ=0.026 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.103\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-34.989, 29.531] μ=-1.039e-05 σ=0.026 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.921\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-34.989, 29.531] μ=-1.038e-05 σ=0.026 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 13.693\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-35.144, 29.678] μ=-1.040e-05 σ=0.026 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 11.325\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-35.458, 29.976] μ=-1.042e-05 σ=0.027 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 5.614\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-35.458, 29.976] μ=-1.042e-05 σ=0.027 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.038\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-35.466, 29.983] μ=-1.042e-05 σ=0.027 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.889\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-35.466, 29.983] μ=-1.042e-05 σ=0.027 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.191\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-35.503, 30.018] μ=-1.044e-05 σ=0.027 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.190\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-35.503, 30.018] μ=-1.044e-05 σ=0.027 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 11.956\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-35.562, 30.074] μ=-1.046e-05 σ=0.027 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.752\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-35.562, 30.074] μ=-1.046e-05 σ=0.027 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.017\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-35.569, 30.081] μ=-1.046e-05 σ=0.027 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.983\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-35.580, 30.091] μ=-1.047e-05 σ=0.027 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 12.186\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-35.636, 30.144] μ=-1.042e-05 σ=0.027 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.530\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-35.695, 30.200] μ=-1.044e-05 σ=0.027 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 12.122\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-35.706, 30.210] μ=-1.044e-05 σ=0.027 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.453\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-35.739, 30.242] μ=-1.043e-05 σ=0.027 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.065\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-35.739, 30.242] μ=-1.043e-05 σ=0.027 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.250\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-35.746, 30.249] μ=-1.043e-05 σ=0.027 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.527\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-35.746, 30.249] μ=-1.043e-05 σ=0.027 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.755\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-35.757, 30.260] μ=-1.044e-05 σ=0.027 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 14.494\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-35.805, 30.306] μ=-1.046e-05 σ=0.027 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 12.535\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-35.813, 30.313] μ=-1.046e-05 σ=0.027 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.077\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-35.813, 30.313] μ=-1.046e-05 σ=0.027 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 6.787\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-35.813, 30.313] μ=-1.046e-05 σ=0.027 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 6.863\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-35.816, 30.316] μ=-1.046e-05 σ=0.027 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 4.685\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-35.816, 30.316] μ=-1.046e-05 σ=0.027 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 13.454\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-35.916, 30.412] μ=-1.047e-05 σ=0.027 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.512\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-35.920, 30.415] μ=-1.047e-05 σ=0.027 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.792\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-35.927, 30.422] μ=-1.047e-05 σ=0.027 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 5.331\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-35.927, 30.422] μ=-1.047e-05 σ=0.027 cuda:0\n",
      "[E17/150 I1300/4500]\n",
      "  Loss 9.803698539733887\n",
      "tensor grad AddBackward0 cuda:0 9.804\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-35.935, 30.429] μ=-1.047e-05 σ=0.027 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 12.106\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-36.053, 30.543] μ=-1.050e-05 σ=0.027 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 5.164\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-36.053, 30.543] μ=-1.050e-05 σ=0.027 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.057\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-36.057, 30.546] μ=-1.050e-05 σ=0.027 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 15.979\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-36.286, 30.766] μ=-1.057e-05 σ=0.027 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.823\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-36.371, 30.848] μ=-1.061e-05 σ=0.027 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.870\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-36.371, 30.848] μ=-1.061e-05 σ=0.027 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 13.523\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-36.460, 30.933] μ=-1.064e-05 σ=0.027 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 5.171\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-36.460, 30.933] μ=-1.063e-05 σ=0.027 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 6.676\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-36.464, 30.936] μ=-1.064e-05 σ=0.027 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 6.430\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-36.471, 30.944] μ=-1.064e-05 σ=0.027 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.725\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-36.478, 30.951] μ=-1.064e-05 σ=0.027 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 13.934\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-36.571, 31.039] μ=-1.066e-05 σ=0.027 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 13.777\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-36.574, 31.043] μ=-1.066e-05 σ=0.027 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.255\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-36.578, 31.046] μ=-1.067e-05 σ=0.027 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 13.852\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-36.667, 31.131] μ=-1.067e-05 σ=0.027 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.806\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-36.670, 31.135] μ=-1.068e-05 σ=0.027 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.403\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-36.707, 31.170] μ=-1.070e-05 σ=0.027 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.826\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-36.741, 31.202] μ=-1.071e-05 σ=0.028 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.567\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-36.748, 31.210] μ=-1.071e-05 σ=0.028 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 14.106\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-36.759, 31.220] μ=-1.073e-05 σ=0.028 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.265\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-36.770, 31.231] μ=-1.073e-05 σ=0.028 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.524\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-36.770, 31.231] μ=-1.073e-05 σ=0.028 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 13.586\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-36.770, 31.231] μ=-1.073e-05 σ=0.028 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 14.393\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-36.948, 31.401] μ=-1.081e-05 σ=0.028 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.355\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-36.948, 31.401] μ=-1.081e-05 σ=0.028 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 6.847\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-36.951, 31.404] μ=-1.081e-05 σ=0.028 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 5.928\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-36.951, 31.405] μ=-1.081e-05 σ=0.028 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 13.206\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-36.992, 31.443] μ=-1.084e-05 σ=0.028 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 11.400\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-36.999, 31.451] μ=-1.085e-05 σ=0.028 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.724\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-37.007, 31.458] μ=-1.085e-05 σ=0.028 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.051\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-37.158, 31.603] μ=-1.091e-05 σ=0.028 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.586\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-37.158, 31.603] μ=-1.092e-05 σ=0.028 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 5.433\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-37.158, 31.603] μ=-1.092e-05 σ=0.028 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.759\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-37.173, 31.617] μ=-1.094e-05 σ=0.028 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 6.626\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-37.180, 31.624] μ=-1.094e-05 σ=0.028 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.100\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-37.368, 31.805] μ=-1.099e-05 σ=0.028 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 11.591\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-37.372, 31.808] μ=-1.099e-05 σ=0.028 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 6.914\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-37.372, 31.808] μ=-1.099e-05 σ=0.028 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.638\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-37.379, 31.815] μ=-1.099e-05 σ=0.028 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.624\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-37.379, 31.815] μ=-1.099e-05 σ=0.028 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.322\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-37.390, 31.826] μ=-1.100e-05 σ=0.028 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 14.107\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-37.408, 31.843] μ=-1.100e-05 σ=0.028 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 5.038\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-37.408, 31.843] μ=-1.100e-05 σ=0.028 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 13.679\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-37.405, 31.840] μ=-1.100e-05 σ=0.028 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.318\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-37.405, 31.840] μ=-1.100e-05 σ=0.028 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 11.693\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-37.405, 31.840] μ=-1.100e-05 σ=0.028 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.111\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-37.408, 31.843] μ=-1.100e-05 σ=0.028 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 12.693\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-37.467, 31.900] μ=-1.096e-05 σ=0.028 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.747\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-37.467, 31.900] μ=-1.096e-05 σ=0.028 cuda:0\n",
      "[E17/150 I1350/4500]\n",
      "  Loss 8.754204750061035\n",
      "tensor grad AddBackward0 cuda:0 8.754\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-37.471, 31.904] μ=-1.096e-05 σ=0.028 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.348\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-37.471, 31.904] μ=-1.096e-05 σ=0.028 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.939\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-37.481, 31.913] μ=-1.097e-05 σ=0.028 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.352\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-37.481, 31.913] μ=-1.097e-05 σ=0.028 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 13.353\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-37.500, 31.931] μ=-1.094e-05 σ=0.028 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 11.144\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-37.546, 31.976] μ=-1.095e-05 σ=0.028 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 4.826\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-37.546, 31.976] μ=-1.095e-05 σ=0.028 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 15.058\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-37.708, 32.132] μ=-1.105e-05 σ=0.028 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.965\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-37.881, 32.298] μ=-1.109e-05 σ=0.028 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 4.998\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-37.881, 32.298] μ=-1.109e-05 σ=0.028 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 11.969\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-37.889, 32.305] μ=-1.109e-05 σ=0.028 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.353\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-38.029, 32.440] μ=-1.111e-05 σ=0.029 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.772\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-38.124, 32.532] μ=-1.116e-05 σ=0.029 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 12.635\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-38.135, 32.543] μ=-1.118e-05 σ=0.029 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.873\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-38.139, 32.546] μ=-1.118e-05 σ=0.029 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.050\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-38.139, 32.546] μ=-1.118e-05 σ=0.029 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.023\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-38.150, 32.557] μ=-1.118e-05 σ=0.029 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 15.081\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-38.250, 32.653] μ=-1.120e-05 σ=0.029 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 5.467\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-38.250, 32.653] μ=-1.120e-05 σ=0.029 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.241\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-38.250, 32.653] μ=-1.120e-05 σ=0.029 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.889\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-38.316, 32.718] μ=-1.121e-05 σ=0.029 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.363\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-38.331, 32.732] μ=-1.121e-05 σ=0.029 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.482\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-38.364, 32.764] μ=-1.122e-05 σ=0.029 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.085\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-38.379, 32.779] μ=-1.122e-05 σ=0.029 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.942\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-38.379, 32.779] μ=-1.122e-05 σ=0.029 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.228\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-38.379, 32.779] μ=-1.122e-05 σ=0.029 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.560\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-38.379, 32.779] μ=-1.122e-05 σ=0.029 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 5.357\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-38.379, 32.779] μ=-1.122e-05 σ=0.029 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.601\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-38.386, 32.786] μ=-1.122e-05 σ=0.029 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.470\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-38.394, 32.793] μ=-1.122e-05 σ=0.029 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.761\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-38.401, 32.800] μ=-1.122e-05 σ=0.029 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 15.451\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-38.408, 32.808] μ=-1.122e-05 σ=0.029 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.865\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-38.412, 32.811] μ=-1.122e-05 σ=0.029 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 4.485\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-38.412, 32.811] μ=-1.122e-05 σ=0.029 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.344\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-38.416, 32.815] μ=-1.122e-05 σ=0.029 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.608\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-38.416, 32.815] μ=-1.124e-05 σ=0.029 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.162\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-38.419, 32.818] μ=-1.124e-05 σ=0.029 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 12.479\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-38.471, 32.869] μ=-1.129e-05 σ=0.029 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.309\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-38.479, 32.876] μ=-1.129e-05 σ=0.029 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.368\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-38.479, 32.876] μ=-1.129e-05 σ=0.029 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 5.627\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-38.479, 32.876] μ=-1.129e-05 σ=0.029 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 6.010\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-38.479, 32.876] μ=-1.129e-05 σ=0.029 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.607\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-38.482, 32.879] μ=-1.129e-05 σ=0.029 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 13.744\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-38.497, 32.894] μ=-1.129e-05 σ=0.029 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.006\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-38.504, 32.901] μ=-1.129e-05 σ=0.029 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 12.328\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-38.559, 32.955] μ=-1.131e-05 σ=0.029 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.839\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-38.563, 32.958] μ=-1.132e-05 σ=0.029 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 11.393\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-38.672, 33.064] μ=-1.137e-05 σ=0.029 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.962\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-38.676, 33.068] μ=-1.137e-05 σ=0.029 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 5.286\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-38.676, 33.068] μ=-1.137e-05 σ=0.029 cuda:0\n",
      "[E17/150 I1400/4500]\n",
      "  Loss 11.03902530670166\n",
      "tensor grad AddBackward0 cuda:0 11.039\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-38.812, 33.201] μ=-1.140e-05 σ=0.029 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.056\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-38.815, 33.205] μ=-1.140e-05 σ=0.029 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.733\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-38.819, 33.208] μ=-1.140e-05 σ=0.029 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.063\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-38.826, 33.215] μ=-1.141e-05 σ=0.029 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 4.665\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-38.826, 33.215] μ=-1.141e-05 σ=0.029 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 11.785\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-38.830, 33.219] μ=-1.141e-05 σ=0.029 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 13.419\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-38.849, 33.237] μ=-1.142e-05 σ=0.029 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 4.502\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-38.849, 33.237] μ=-1.142e-05 σ=0.029 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 15.466\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-38.856, 33.244] μ=-1.142e-05 σ=0.029 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.961\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-38.865, 33.253] μ=-1.142e-05 σ=0.029 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 6.779\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-38.869, 33.257] μ=-1.142e-05 σ=0.029 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 6.211\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-38.869, 33.257] μ=-1.142e-05 σ=0.029 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.299\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-38.923, 33.310] μ=-1.142e-05 σ=0.029 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 12.244\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-38.986, 33.371] μ=-1.143e-05 σ=0.029 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.079\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-38.989, 33.375] μ=-1.144e-05 σ=0.029 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 12.468\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-39.085, 33.468] μ=-1.146e-05 σ=0.029 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.516\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-39.092, 33.476] μ=-1.146e-05 σ=0.029 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 11.546\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-39.096, 33.479] μ=-1.146e-05 σ=0.029 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 6.223\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-39.096, 33.479] μ=-1.146e-05 σ=0.029 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.987\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-39.096, 33.479] μ=-1.146e-05 σ=0.029 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.244\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-39.096, 33.479] μ=-1.146e-05 σ=0.029 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 4.862\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-39.100, 33.483] μ=-1.146e-05 σ=0.029 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 5.391\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-39.100, 33.483] μ=-1.146e-05 σ=0.029 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 5.599\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-39.103, 33.486] μ=-1.146e-05 σ=0.029 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.697\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-39.103, 33.486] μ=-1.146e-05 σ=0.029 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.746\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-39.111, 33.493] μ=-1.146e-05 σ=0.029 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 12.095\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-39.173, 33.554] μ=-1.146e-05 σ=0.029 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.847\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-39.180, 33.561] μ=-1.146e-05 σ=0.029 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 14.746\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-39.315, 33.694] μ=-1.149e-05 σ=0.029 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 4.829\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-39.315, 33.694] μ=-1.149e-05 σ=0.029 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 5.913\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-39.315, 33.694] μ=-1.149e-05 σ=0.029 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.787\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-39.319, 33.697] μ=-1.149e-05 σ=0.029 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 5.888\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-39.323, 33.701] μ=-1.149e-05 σ=0.029 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 11.888\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-39.517, 33.891] μ=-1.156e-05 σ=0.030 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 11.242\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-39.524, 33.898] μ=-1.157e-05 σ=0.030 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 6.903\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-39.524, 33.898] μ=-1.157e-05 σ=0.030 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.934\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-39.528, 33.902] μ=-1.157e-05 σ=0.030 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 11.173\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-39.532, 33.906] μ=-1.157e-05 σ=0.030 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 5.533\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-39.536, 33.910] μ=-1.157e-05 σ=0.030 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.985\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-39.543, 33.917] μ=-1.157e-05 σ=0.030 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 12.255\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-39.553, 33.927] μ=-1.160e-05 σ=0.030 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.302\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-39.604, 33.977] μ=-1.161e-05 σ=0.030 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 11.958\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-39.681, 34.053] μ=-1.159e-05 σ=0.030 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.844\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-39.681, 34.053] μ=-1.159e-05 σ=0.030 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.008\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-39.681, 34.053] μ=-1.159e-05 σ=0.030 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.775\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-39.688, 34.060] μ=-1.158e-05 σ=0.030 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.102\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-39.688, 34.060] μ=-1.158e-05 σ=0.030 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 5.486\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-39.688, 34.060] μ=-1.158e-05 σ=0.030 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.423\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-39.696, 34.067] μ=-1.158e-05 σ=0.030 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 3.868\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-39.696, 34.067] μ=-1.158e-05 σ=0.030 cuda:0\n",
      "[E17/150 I1450/4500]\n",
      "  Loss 9.708324432373047\n",
      "tensor grad AddBackward0 cuda:0 9.708\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-39.703, 34.074] μ=-1.158e-05 σ=0.030 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.948\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-39.707, 34.078] μ=-1.158e-05 σ=0.030 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.524\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-39.707, 34.078] μ=-1.158e-05 σ=0.030 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.127\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-39.721, 34.092] μ=-1.158e-05 σ=0.030 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 6.268\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-39.721, 34.092] μ=-1.158e-05 σ=0.030 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.384\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-39.721, 34.092] μ=-1.158e-05 σ=0.030 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 4.496\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-39.721, 34.092] μ=-1.158e-05 σ=0.030 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 5.421\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-39.721, 34.092] μ=-1.158e-05 σ=0.030 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 6.338\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-39.721, 34.092] μ=-1.158e-05 σ=0.030 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.557\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-39.736, 34.106] μ=-1.158e-05 σ=0.030 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 14.488\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-39.747, 34.117] μ=-1.159e-05 σ=0.030 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.880\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-39.751, 34.121] μ=-1.159e-05 σ=0.030 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 4.762\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-39.753, 34.123] μ=-1.159e-05 σ=0.030 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 14.465\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-39.990, 34.357] μ=-1.163e-05 σ=0.030 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.271\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-40.001, 34.368] μ=-1.163e-05 σ=0.030 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 11.535\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-40.052, 34.418] μ=-1.167e-05 σ=0.030 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.996\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-40.048, 34.414] μ=-1.167e-05 σ=0.030 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.908\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-40.056, 34.421] μ=-1.167e-05 σ=0.030 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.064\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-40.063, 34.428] μ=-1.167e-05 σ=0.030 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.196\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-40.074, 34.439] μ=-1.168e-05 σ=0.030 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.315\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-40.096, 34.461] μ=-1.169e-05 σ=0.030 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.939\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-40.103, 34.468] μ=-1.169e-05 σ=0.030 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.678\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-40.107, 34.471] μ=-1.169e-05 σ=0.030 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 12.604\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-40.101, 34.466] μ=-1.170e-05 σ=0.030 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.736\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-40.104, 34.469] μ=-1.170e-05 σ=0.030 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 13.817\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-40.115, 34.480] μ=-1.170e-05 σ=0.030 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.418\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-40.119, 34.483] μ=-1.170e-05 σ=0.030 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.801\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-40.213, 34.577] μ=-1.173e-05 σ=0.030 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.082\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-40.224, 34.587] μ=-1.173e-05 σ=0.030 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 4.290\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-40.224, 34.587] μ=-1.173e-05 σ=0.030 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.858\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-40.228, 34.591] μ=-1.173e-05 σ=0.030 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 12.361\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-40.231, 34.595] μ=-1.174e-05 σ=0.030 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 12.460\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-40.231, 34.595] μ=-1.174e-05 σ=0.030 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.379\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-40.231, 34.595] μ=-1.174e-05 σ=0.030 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.017\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-40.237, 34.600] μ=-1.174e-05 σ=0.030 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.966\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-40.379, 34.740] μ=-1.178e-05 σ=0.030 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 12.345\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-40.626, 34.985] μ=-1.181e-05 σ=0.031 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 14.266\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-40.641, 35.000] μ=-1.184e-05 σ=0.031 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 5.114\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-40.641, 35.000] μ=-1.184e-05 σ=0.031 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.081\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-40.641, 35.000] μ=-1.184e-05 σ=0.031 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.231\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-40.648, 35.007] μ=-1.184e-05 σ=0.031 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.086\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-40.659, 35.018] μ=-1.184e-05 σ=0.031 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.691\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-40.786, 35.144] μ=-1.186e-05 σ=0.031 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.918\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-40.794, 35.152] μ=-1.186e-05 σ=0.031 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 12.141\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-40.914, 35.271] μ=-1.187e-05 σ=0.031 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 12.944\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-40.935, 35.292] μ=-1.192e-05 σ=0.031 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.382\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-40.939, 35.296] μ=-1.192e-05 σ=0.031 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.372\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-40.943, 35.300] μ=-1.192e-05 σ=0.031 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.558\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-40.986, 35.343] μ=-1.194e-05 σ=0.031 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 11.281\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-40.986, 35.343] μ=-1.194e-05 σ=0.031 cuda:0\n",
      "[E17/150 I1500/4500]\n",
      "  Loss 5.595157623291016\n",
      "tensor grad AddBackward0 cuda:0 5.595\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-40.986, 35.343] μ=-1.194e-05 σ=0.031 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 2.978\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-40.986, 35.343] μ=-1.194e-05 σ=0.031 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 6.741\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-40.995, 35.351] μ=-1.194e-05 σ=0.031 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 15.229\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-41.046, 35.402] μ=-1.191e-05 σ=0.031 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 6.150\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-41.060, 35.417] μ=-1.191e-05 σ=0.031 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 5.008\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-41.060, 35.417] μ=-1.191e-05 σ=0.031 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.268\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-41.129, 35.485] μ=-1.193e-05 σ=0.031 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 5.352\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-41.129, 35.485] μ=-1.193e-05 σ=0.031 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.905\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-41.143, 35.499] μ=-1.194e-05 σ=0.031 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.513\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-41.143, 35.499] μ=-1.194e-05 σ=0.031 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 13.493\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-41.117, 35.473] μ=-1.194e-05 σ=0.031 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.003\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-41.123, 35.479] μ=-1.193e-05 σ=0.031 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.942\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-41.134, 35.490] μ=-1.194e-05 σ=0.031 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 13.421\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-41.276, 35.631] μ=-1.196e-05 σ=0.031 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 13.722\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-41.399, 35.754] μ=-1.196e-05 σ=0.031 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 5.533\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-41.399, 35.754] μ=-1.196e-05 σ=0.031 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 11.684\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-41.418, 35.772] μ=-1.194e-05 σ=0.031 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.363\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-41.421, 35.776] μ=-1.194e-05 σ=0.031 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.183\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-41.457, 35.812] μ=-1.197e-05 σ=0.031 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.661\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-41.461, 35.816] μ=-1.197e-05 σ=0.031 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 13.378\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-41.577, 35.932] μ=-1.197e-05 σ=0.031 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.513\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-41.581, 35.935] μ=-1.197e-05 σ=0.031 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 12.845\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-41.559, 35.914] μ=-1.199e-05 σ=0.031 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.425\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-41.566, 35.921] μ=-1.199e-05 σ=0.031 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 12.289\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-41.584, 35.938] μ=-1.199e-05 σ=0.031 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.854\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-41.584, 35.938] μ=-1.199e-05 σ=0.031 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.362\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-41.592, 35.945] μ=-1.199e-05 σ=0.031 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.239\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-41.600, 35.954] μ=-1.199e-05 σ=0.031 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.222\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-41.611, 35.965] μ=-1.199e-05 σ=0.031 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 14.538\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-41.621, 35.975] μ=-1.199e-05 σ=0.031 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.962\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-41.624, 35.978] μ=-1.200e-05 σ=0.031 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.244\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-41.632, 35.985] μ=-1.200e-05 σ=0.031 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 4.004\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-41.633, 35.987] μ=-1.200e-05 σ=0.031 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 5.729\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-41.633, 35.987] μ=-1.200e-05 σ=0.031 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 11.142\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-41.653, 36.007] μ=-1.200e-05 σ=0.031 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.864\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-41.660, 36.014] μ=-1.200e-05 σ=0.031 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.588\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-41.663, 36.017] μ=-1.200e-05 σ=0.031 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 15.922\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-41.793, 36.147] μ=-1.205e-05 σ=0.031 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 11.285\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-41.799, 36.153] μ=-1.205e-05 σ=0.031 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.502\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-41.807, 36.161] μ=-1.205e-05 σ=0.031 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 12.501\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-41.818, 36.171] μ=-1.206e-05 σ=0.031 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 4.995\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-41.818, 36.171] μ=-1.206e-05 σ=0.031 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 11.548\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-41.818, 36.172] μ=-1.205e-05 σ=0.031 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.087\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-41.822, 36.175] μ=-1.205e-05 σ=0.031 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.649\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-41.825, 36.179] μ=-1.206e-05 σ=0.031 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.830\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-41.854, 36.208] μ=-1.206e-05 σ=0.031 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 12.904\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-41.894, 36.248] μ=-1.208e-05 σ=0.031 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.401\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-41.962, 36.316] μ=-1.207e-05 σ=0.032 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.660\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-41.962, 36.316] μ=-1.207e-05 σ=0.032 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 11.587\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-42.017, 36.370] μ=-1.210e-05 σ=0.032 cuda:0\n",
      "[E17/150 I1550/4500]\n",
      "  Loss 5.543727874755859\n",
      "tensor grad AddBackward0 cuda:0 5.544\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-42.017, 36.370] μ=-1.210e-05 σ=0.032 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.878\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-42.017, 36.370] μ=-1.210e-05 σ=0.032 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 11.862\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-42.028, 36.381] μ=-1.210e-05 σ=0.032 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.759\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-42.031, 36.385] μ=-1.210e-05 σ=0.032 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 11.633\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-42.031, 36.385] μ=-1.211e-05 σ=0.032 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.208\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-42.039, 36.392] μ=-1.211e-05 σ=0.032 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 5.969\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-42.042, 36.396] μ=-1.211e-05 σ=0.032 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 12.343\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-42.103, 36.457] μ=-1.215e-05 σ=0.032 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.443\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-42.103, 36.457] μ=-1.215e-05 σ=0.032 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.655\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-42.121, 36.475] μ=-1.216e-05 σ=0.032 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.052\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-42.132, 36.485] μ=-1.217e-05 σ=0.032 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.912\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-42.138, 36.491] μ=-1.217e-05 σ=0.032 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.795\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-42.146, 36.499] μ=-1.217e-05 σ=0.032 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.454\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-42.150, 36.503] μ=-1.217e-05 σ=0.032 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.485\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-42.296, 36.649] μ=-1.220e-05 σ=0.032 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.739\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-42.300, 36.653] μ=-1.220e-05 σ=0.032 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 13.713\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-42.347, 36.700] μ=-1.224e-05 σ=0.032 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.079\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-42.347, 36.700] μ=-1.224e-05 σ=0.032 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.158\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-42.347, 36.700] μ=-1.225e-05 σ=0.032 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 12.952\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-42.354, 36.707] μ=-1.225e-05 σ=0.032 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 5.822\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-42.354, 36.707] μ=-1.225e-05 σ=0.032 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 11.814\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-42.412, 36.765] μ=-1.227e-05 σ=0.032 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 11.086\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-42.419, 36.772] μ=-1.227e-05 σ=0.032 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.295\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-42.419, 36.772] μ=-1.227e-05 σ=0.032 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 6.816\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-42.419, 36.772] μ=-1.227e-05 σ=0.032 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 11.042\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-42.423, 36.776] μ=-1.228e-05 σ=0.032 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.536\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-42.437, 36.790] μ=-1.228e-05 σ=0.032 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 13.224\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-42.441, 36.793] μ=-1.228e-05 σ=0.032 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 12.147\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-42.477, 36.829] μ=-1.228e-05 σ=0.032 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.845\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-42.477, 36.829] μ=-1.228e-05 σ=0.032 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 6.928\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-42.480, 36.832] μ=-1.228e-05 σ=0.032 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.458\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-42.480, 36.832] μ=-1.228e-05 σ=0.032 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.652\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-42.480, 36.833] μ=-1.228e-05 σ=0.032 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.585\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-42.520, 36.872] μ=-1.233e-05 σ=0.032 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 6.946\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-42.520, 36.872] μ=-1.233e-05 σ=0.032 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 5.897\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-42.520, 36.872] μ=-1.233e-05 σ=0.032 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 5.060\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-42.520, 36.872] μ=-1.233e-05 σ=0.032 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.819\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-42.527, 36.879] μ=-1.233e-05 σ=0.032 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.381\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-42.567, 36.919] μ=-1.234e-05 σ=0.032 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.699\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-42.567, 36.919] μ=-1.234e-05 σ=0.032 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 13.217\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-42.614, 36.966] μ=-1.235e-05 σ=0.032 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.277\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-42.617, 36.969] μ=-1.235e-05 σ=0.032 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 11.188\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-42.621, 36.972] μ=-1.236e-05 σ=0.032 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 6.923\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-42.621, 36.972] μ=-1.236e-05 σ=0.032 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.272\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-42.622, 36.974] μ=-1.236e-05 σ=0.032 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.443\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-42.831, 37.183] μ=-1.239e-05 σ=0.032 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 6.435\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-42.831, 37.183] μ=-1.239e-05 σ=0.032 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.894\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-42.834, 37.187] μ=-1.239e-05 σ=0.032 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.292\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-42.842, 37.194] μ=-1.239e-05 σ=0.032 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.804\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-42.849, 37.201] μ=-1.239e-05 σ=0.032 cuda:0\n",
      "[E17/150 I1600/4500]\n",
      "  Loss 11.285958290100098\n",
      "tensor grad AddBackward0 cuda:0 11.286\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-42.863, 37.215] μ=-1.239e-05 σ=0.032 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.247\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-43.007, 37.359] μ=-1.241e-05 σ=0.032 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 5.490\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-43.007, 37.359] μ=-1.241e-05 σ=0.032 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.888\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-43.018, 37.370] μ=-1.241e-05 σ=0.032 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.650\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-43.018, 37.370] μ=-1.241e-05 σ=0.032 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 5.471\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-43.018, 37.370] μ=-1.241e-05 σ=0.032 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 3.549\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-43.018, 37.370] μ=-1.241e-05 σ=0.032 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.682\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-43.018, 37.370] μ=-1.241e-05 σ=0.032 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 6.981\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-43.018, 37.370] μ=-1.241e-05 σ=0.032 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.732\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-43.028, 37.381] μ=-1.242e-05 σ=0.032 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 12.172\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-43.039, 37.392] μ=-1.241e-05 σ=0.032 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.354\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-43.043, 37.395] μ=-1.242e-05 σ=0.032 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.153\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-43.100, 37.453] μ=-1.246e-05 σ=0.033 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.488\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-43.107, 37.460] μ=-1.246e-05 σ=0.033 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 4.175\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-43.107, 37.460] μ=-1.246e-05 σ=0.033 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.248\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-43.115, 37.467] μ=-1.246e-05 σ=0.033 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.191\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-43.118, 37.471] μ=-1.246e-05 σ=0.033 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.183\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-43.211, 37.564] μ=-1.250e-05 σ=0.033 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 6.767\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-43.258, 37.611] μ=-1.250e-05 σ=0.033 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.459\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-43.258, 37.611] μ=-1.250e-05 σ=0.033 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.223\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-43.261, 37.615] μ=-1.250e-05 σ=0.033 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.760\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-43.294, 37.647] μ=-1.248e-05 σ=0.033 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.885\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-43.383, 37.737] μ=-1.249e-05 σ=0.033 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 6.383\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-43.383, 37.737] μ=-1.249e-05 σ=0.033 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.661\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-43.383, 37.737] μ=-1.249e-05 σ=0.033 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.334\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-43.380, 37.734] μ=-1.249e-05 σ=0.033 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.586\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-43.394, 37.748] μ=-1.250e-05 σ=0.033 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.829\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-43.390, 37.744] μ=-1.249e-05 σ=0.033 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 4.740\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-43.390, 37.744] μ=-1.249e-05 σ=0.033 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 15.308\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-43.491, 37.845] μ=-1.254e-05 σ=0.033 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.418\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-43.491, 37.845] μ=-1.254e-05 σ=0.033 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 11.729\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-43.534, 37.889] μ=-1.255e-05 σ=0.033 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.904\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-43.534, 37.889] μ=-1.255e-05 σ=0.033 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.758\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-43.537, 37.892] μ=-1.256e-05 σ=0.033 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.570\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-43.566, 37.921] μ=-1.258e-05 σ=0.033 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 11.014\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-43.577, 37.932] μ=-1.258e-05 σ=0.033 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 6.803\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-43.577, 37.932] μ=-1.258e-05 σ=0.033 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.067\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-43.577, 37.932] μ=-1.258e-05 σ=0.033 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.718\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-43.580, 37.936] μ=-1.259e-05 σ=0.033 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 16.385\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-43.796, 38.153] μ=-1.264e-05 σ=0.033 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.296\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-43.796, 38.153] μ=-1.264e-05 σ=0.033 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 12.979\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-43.925, 38.284] μ=-1.268e-05 σ=0.033 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.097\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-43.922, 38.280] μ=-1.268e-05 σ=0.033 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 5.285\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-43.922, 38.280] μ=-1.268e-05 σ=0.033 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 14.631\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-43.914, 38.273] μ=-1.271e-05 σ=0.033 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.979\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-43.947, 38.306] μ=-1.274e-05 σ=0.033 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 6.471\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-43.954, 38.313] μ=-1.274e-05 σ=0.033 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 11.349\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-43.957, 38.316] μ=-1.274e-05 σ=0.033 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 6.275\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-43.957, 38.316] μ=-1.274e-05 σ=0.033 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 15.614\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-44.088, 38.448] μ=-1.282e-05 σ=0.033 cuda:0\n",
      "[E17/150 I1650/4500]\n",
      "  Loss 7.176269054412842\n",
      "tensor grad AddBackward0 cuda:0 7.176\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-44.111, 38.472] μ=-1.285e-05 σ=0.034 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 14.472\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-44.208, 38.570] μ=-1.287e-05 σ=0.034 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.065\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-44.247, 38.610] μ=-1.286e-05 σ=0.034 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.066\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-44.251, 38.614] μ=-1.286e-05 σ=0.034 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 13.100\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-44.272, 38.635] μ=-1.286e-05 σ=0.034 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 5.682\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-44.272, 38.635] μ=-1.286e-05 σ=0.034 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 5.327\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-44.272, 38.635] μ=-1.286e-05 σ=0.034 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 13.779\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-44.280, 38.643] μ=-1.287e-05 σ=0.034 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 13.505\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-44.327, 38.691] μ=-1.287e-05 σ=0.034 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.560\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-44.334, 38.698] μ=-1.287e-05 σ=0.034 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.930\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-44.336, 38.700] μ=-1.287e-05 σ=0.034 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 6.232\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-44.336, 38.700] μ=-1.287e-05 σ=0.034 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 5.770\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-44.336, 38.700] μ=-1.287e-05 σ=0.034 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 14.794\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-44.350, 38.715] μ=-1.289e-05 σ=0.034 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 16.692\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-44.480, 38.846] μ=-1.288e-05 σ=0.034 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.094\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-44.484, 38.850] μ=-1.288e-05 σ=0.034 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 4.165\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-44.483, 38.850] μ=-1.288e-05 σ=0.034 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.294\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-44.516, 38.883] μ=-1.289e-05 σ=0.034 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.465\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-44.512, 38.879] μ=-1.288e-05 σ=0.034 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 6.663\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-44.512, 38.879] μ=-1.288e-05 σ=0.034 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.084\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-44.516, 38.883] μ=-1.288e-05 σ=0.034 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 11.883\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-44.518, 38.885] μ=-1.290e-05 σ=0.034 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 6.461\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-44.514, 38.882] μ=-1.290e-05 σ=0.034 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 11.366\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-44.497, 38.863] μ=-1.284e-05 σ=0.034 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 6.858\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-44.497, 38.863] μ=-1.284e-05 σ=0.034 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.148\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-44.497, 38.863] μ=-1.285e-05 σ=0.034 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.395\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-44.497, 38.863] μ=-1.285e-05 σ=0.034 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.403\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-44.500, 38.867] μ=-1.285e-05 σ=0.034 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.303\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-44.500, 38.867] μ=-1.285e-05 σ=0.034 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 11.460\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-44.504, 38.870] μ=-1.285e-05 σ=0.034 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.020\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-44.504, 38.870] μ=-1.285e-05 σ=0.034 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 6.888\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-44.504, 38.870] μ=-1.285e-05 σ=0.034 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 12.364\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-44.507, 38.874] μ=-1.285e-05 σ=0.034 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.187\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-44.554, 38.922] μ=-1.287e-05 σ=0.034 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.650\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-44.590, 38.958] μ=-1.286e-05 σ=0.034 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 12.561\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-44.687, 39.057] μ=-1.290e-05 σ=0.034 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 13.124\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-44.835, 39.207] μ=-1.294e-05 σ=0.034 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 4.175\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-44.835, 39.207] μ=-1.294e-05 σ=0.034 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 14.327\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-44.921, 39.295] μ=-1.294e-05 σ=0.034 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 14.094\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-44.932, 39.306] μ=-1.294e-05 σ=0.034 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 17.250\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-44.928, 39.302] μ=-1.295e-05 σ=0.034 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 4.764\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-44.928, 39.302] μ=-1.295e-05 σ=0.034 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.881\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-44.928, 39.302] μ=-1.296e-05 σ=0.034 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 11.269\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-44.928, 39.302] μ=-1.296e-05 σ=0.034 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.337\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-44.924, 39.298] μ=-1.296e-05 σ=0.034 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.251\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-44.924, 39.298] μ=-1.296e-05 σ=0.034 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 11.691\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-44.931, 39.306] μ=-1.296e-05 σ=0.034 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.070\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-44.939, 39.313] μ=-1.297e-05 σ=0.034 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.593\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-44.943, 39.317] μ=-1.297e-05 σ=0.034 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 16.725\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-44.961, 39.335] μ=-1.302e-05 σ=0.034 cuda:0\n",
      "[E17/150 I1700/4500]\n",
      "  Loss 11.923337936401367\n",
      "tensor grad AddBackward0 cuda:0 11.923\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-44.967, 39.342] μ=-1.302e-05 σ=0.034 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.199\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-44.978, 39.353] μ=-1.302e-05 σ=0.034 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 14.166\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-45.075, 39.452] μ=-1.304e-05 σ=0.034 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.382\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-45.075, 39.452] μ=-1.307e-05 σ=0.034 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 13.098\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-45.168, 39.547] μ=-1.309e-05 σ=0.034 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.017\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-45.168, 39.547] μ=-1.309e-05 σ=0.034 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.615\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-45.265, 39.646] μ=-1.312e-05 σ=0.035 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 12.731\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-45.283, 39.664] μ=-1.313e-05 σ=0.035 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.821\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-45.294, 39.675] μ=-1.313e-05 σ=0.035 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.749\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-45.297, 39.679] μ=-1.313e-05 σ=0.035 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.051\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-45.301, 39.682] μ=-1.313e-05 σ=0.035 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 6.324\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-45.297, 39.678] μ=-1.313e-05 σ=0.035 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 13.994\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-45.437, 39.821] μ=-1.316e-05 σ=0.035 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.276\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-45.437, 39.821] μ=-1.316e-05 σ=0.035 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 13.701\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-45.447, 39.832] μ=-1.316e-05 σ=0.035 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 13.780\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-45.602, 39.989] μ=-1.317e-05 σ=0.035 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.138\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-45.605, 39.993] μ=-1.318e-05 σ=0.035 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 12.964\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-45.634, 40.022] μ=-1.320e-05 σ=0.035 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.905\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-45.724, 40.114] μ=-1.323e-05 σ=0.035 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.266\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-45.724, 40.114] μ=-1.323e-05 σ=0.035 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 3.569\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-45.724, 40.114] μ=-1.323e-05 σ=0.035 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 13.127\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-45.727, 40.117] μ=-1.323e-05 σ=0.035 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.952\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-45.731, 40.121] μ=-1.324e-05 σ=0.035 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 6.847\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-45.731, 40.121] μ=-1.324e-05 σ=0.035 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.769\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-45.731, 40.121] μ=-1.324e-05 σ=0.035 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.272\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-45.745, 40.136] μ=-1.324e-05 σ=0.035 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.783\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-45.745, 40.136] μ=-1.324e-05 σ=0.035 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.149\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-45.752, 40.143] μ=-1.324e-05 σ=0.035 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.932\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-45.756, 40.147] μ=-1.324e-05 σ=0.035 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 12.402\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-45.759, 40.150] μ=-1.324e-05 σ=0.035 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.085\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-45.763, 40.154] μ=-1.325e-05 σ=0.035 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.724\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-45.766, 40.158] μ=-1.325e-05 σ=0.035 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.143\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-45.777, 40.169] μ=-1.325e-05 σ=0.035 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 13.701\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-45.784, 40.176] μ=-1.327e-05 σ=0.035 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.598\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-45.784, 40.176] μ=-1.327e-05 σ=0.035 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 6.255\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-45.788, 40.180] μ=-1.327e-05 σ=0.035 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.417\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-45.788, 40.180] μ=-1.327e-05 σ=0.035 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 11.628\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-45.788, 40.180] μ=-1.327e-05 σ=0.035 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.221\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-45.788, 40.180] μ=-1.327e-05 σ=0.035 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.475\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-45.795, 40.187] μ=-1.327e-05 σ=0.035 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 15.466\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-45.852, 40.246] μ=-1.330e-05 σ=0.035 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.649\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-45.849, 40.242] μ=-1.329e-05 σ=0.035 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 11.825\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-45.859, 40.253] μ=-1.330e-05 σ=0.035 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.144\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-45.859, 40.253] μ=-1.330e-05 σ=0.035 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.432\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-45.867, 40.260] μ=-1.330e-05 σ=0.035 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.164\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-45.870, 40.263] μ=-1.330e-05 σ=0.035 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 12.552\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-45.905, 40.300] μ=-1.332e-05 σ=0.035 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.706\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-45.909, 40.304] μ=-1.332e-05 σ=0.035 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 6.721\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-45.909, 40.304] μ=-1.332e-05 σ=0.035 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.285\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-45.916, 40.311] μ=-1.332e-05 σ=0.035 cuda:0\n",
      "[E17/150 I1750/4500]\n",
      "  Loss 7.901540279388428\n",
      "tensor grad AddBackward0 cuda:0 7.902\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-45.914, 40.309] μ=-1.332e-05 σ=0.035 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 5.848\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-45.914, 40.309] μ=-1.332e-05 σ=0.035 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.193\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-45.914, 40.309] μ=-1.333e-05 σ=0.035 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 6.596\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-45.914, 40.309] μ=-1.333e-05 σ=0.035 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.064\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-46.036, 40.434] μ=-1.334e-05 σ=0.035 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 6.542\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-46.032, 40.430] μ=-1.334e-05 σ=0.035 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.458\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-46.032, 40.430] μ=-1.334e-05 σ=0.035 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.458\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-46.043, 40.441] μ=-1.332e-05 σ=0.035 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.641\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-46.086, 40.485] μ=-1.331e-05 σ=0.035 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.068\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-46.086, 40.485] μ=-1.331e-05 σ=0.035 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 6.792\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-46.086, 40.485] μ=-1.331e-05 σ=0.035 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.938\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-46.104, 40.503] μ=-1.331e-05 σ=0.035 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.680\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-46.143, 40.544] μ=-1.332e-05 σ=0.035 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.936\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-46.150, 40.551] μ=-1.332e-05 σ=0.035 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 12.043\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-46.157, 40.558] μ=-1.332e-05 σ=0.035 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.442\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-46.168, 40.569] μ=-1.332e-05 σ=0.035 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.440\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-46.172, 40.574] μ=-1.333e-05 σ=0.035 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 6.467\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-46.176, 40.577] μ=-1.333e-05 σ=0.035 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.677\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-46.179, 40.581] μ=-1.333e-05 σ=0.035 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.854\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-46.272, 40.676] μ=-1.335e-05 σ=0.035 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.868\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-46.279, 40.684] μ=-1.335e-05 σ=0.035 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.261\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-46.283, 40.687] μ=-1.335e-05 σ=0.035 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.653\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-46.293, 40.698] μ=-1.335e-05 σ=0.035 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 6.731\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-46.293, 40.698] μ=-1.335e-05 σ=0.035 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 4.810\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-46.293, 40.698] μ=-1.335e-05 σ=0.035 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 6.551\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-46.293, 40.698] μ=-1.335e-05 σ=0.035 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 6.985\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-46.300, 40.705] μ=-1.336e-05 σ=0.035 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.246\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-46.300, 40.706] μ=-1.336e-05 σ=0.035 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 11.049\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-46.315, 40.720] μ=-1.336e-05 σ=0.035 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.161\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-46.329, 40.735] μ=-1.337e-05 σ=0.035 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.192\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-46.333, 40.738] μ=-1.337e-05 σ=0.035 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 12.249\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-46.329, 40.735] μ=-1.337e-05 σ=0.035 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.857\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-46.329, 40.735] μ=-1.338e-05 σ=0.035 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 14.003\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-46.340, 40.745] μ=-1.338e-05 σ=0.035 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 3.151\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-46.340, 40.746] μ=-1.338e-05 σ=0.035 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 12.143\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-46.358, 40.764] μ=-1.338e-05 σ=0.035 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 13.756\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-46.368, 40.775] μ=-1.338e-05 σ=0.035 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 6.383\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-46.368, 40.775] μ=-1.338e-05 σ=0.035 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.346\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-46.375, 40.782] μ=-1.339e-05 σ=0.035 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.613\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-46.375, 40.782] μ=-1.339e-05 σ=0.035 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 11.896\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-46.390, 40.797] μ=-1.339e-05 σ=0.035 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.609\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-46.397, 40.804] μ=-1.343e-05 σ=0.035 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.076\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-46.397, 40.804] μ=-1.343e-05 σ=0.035 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 11.450\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-46.450, 40.859] μ=-1.347e-05 σ=0.036 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.864\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-46.450, 40.859] μ=-1.347e-05 σ=0.036 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.473\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-46.457, 40.866] μ=-1.347e-05 σ=0.036 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 11.758\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-46.461, 40.870] μ=-1.347e-05 σ=0.036 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 11.594\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-46.472, 40.881] μ=-1.347e-05 σ=0.036 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.476\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-46.472, 40.881] μ=-1.347e-05 σ=0.036 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.575\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-46.547, 40.958] μ=-1.349e-05 σ=0.036 cuda:0\n",
      "[E17/150 I1800/4500]\n",
      "  Loss 5.728106498718262\n",
      "tensor grad AddBackward0 cuda:0 5.728\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-46.547, 40.958] μ=-1.349e-05 σ=0.036 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.058\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-46.678, 41.094] μ=-1.352e-05 σ=0.036 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 13.055\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-46.678, 41.094] μ=-1.352e-05 σ=0.036 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 6.370\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-46.678, 41.094] μ=-1.352e-05 σ=0.036 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 15.783\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-46.693, 41.109] μ=-1.353e-05 σ=0.036 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.565\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-46.857, 41.279] μ=-1.356e-05 σ=0.036 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.656\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-46.857, 41.279] μ=-1.356e-05 σ=0.036 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.204\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-46.868, 41.290] μ=-1.357e-05 σ=0.036 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 13.558\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-46.907, 41.330] μ=-1.359e-05 σ=0.036 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.736\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-46.907, 41.330] μ=-1.359e-05 σ=0.036 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 12.381\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-46.907, 41.330] μ=-1.359e-05 σ=0.036 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 18.730\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-46.953, 41.378] μ=-1.367e-05 σ=0.036 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.842\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-46.982, 41.408] μ=-1.368e-05 σ=0.036 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.297\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-47.032, 41.460] μ=-1.369e-05 σ=0.036 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.884\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-47.046, 41.475] μ=-1.369e-05 σ=0.036 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.023\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-47.049, 41.478] μ=-1.369e-05 σ=0.036 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 3.790\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-47.049, 41.478] μ=-1.369e-05 σ=0.036 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.162\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-47.053, 41.482] μ=-1.369e-05 σ=0.036 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.203\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-47.121, 41.553] μ=-1.371e-05 σ=0.036 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 5.513\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-47.121, 41.553] μ=-1.371e-05 σ=0.036 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.057\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-47.124, 41.557] μ=-1.371e-05 σ=0.036 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 11.328\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-47.132, 41.564] μ=-1.371e-05 σ=0.036 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 12.300\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-47.142, 41.575] μ=-1.372e-05 σ=0.036 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 11.803\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-47.149, 41.583] μ=-1.372e-05 σ=0.036 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.635\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-47.178, 41.612] μ=-1.372e-05 σ=0.036 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.877\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-47.182, 41.616] μ=-1.372e-05 σ=0.036 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 5.721\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-47.192, 41.627] μ=-1.372e-05 σ=0.036 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.021\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-47.232, 41.668] μ=-1.374e-05 σ=0.036 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 5.490\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-47.232, 41.668] μ=-1.374e-05 σ=0.036 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.060\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-47.232, 41.668] μ=-1.374e-05 σ=0.036 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 13.448\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-47.346, 41.788] μ=-1.377e-05 σ=0.036 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.960\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-47.350, 41.792] μ=-1.377e-05 σ=0.036 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.231\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-47.350, 41.792] μ=-1.377e-05 σ=0.036 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 12.389\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-47.350, 41.792] μ=-1.377e-05 σ=0.036 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 13.234\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-47.436, 41.881] μ=-1.379e-05 σ=0.036 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.610\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-47.436, 41.881] μ=-1.379e-05 σ=0.036 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.540\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-47.478, 41.926] μ=-1.378e-05 σ=0.036 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 6.936\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-47.478, 41.926] μ=-1.378e-05 σ=0.036 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.503\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-47.485, 41.933] μ=-1.378e-05 σ=0.036 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.751\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-47.485, 41.933] μ=-1.378e-05 σ=0.036 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.012\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-47.610, 42.064] μ=-1.381e-05 σ=0.037 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.128\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-47.617, 42.071] μ=-1.381e-05 σ=0.037 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.185\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-47.632, 42.086] μ=-1.381e-05 σ=0.037 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 4.623\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-47.632, 42.086] μ=-1.381e-05 σ=0.037 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 12.172\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-47.725, 42.184] μ=-1.386e-05 σ=0.037 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.898\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-47.843, 42.307] μ=-1.384e-05 σ=0.037 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 11.635\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-47.861, 42.325] μ=-1.384e-05 σ=0.037 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 13.614\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-47.969, 42.438] μ=-1.387e-05 σ=0.037 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 11.610\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-47.979, 42.450] μ=-1.387e-05 σ=0.037 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 6.334\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-47.979, 42.450] μ=-1.387e-05 σ=0.037 cuda:0\n",
      "[E17/150 I1850/4500]\n",
      "  Loss 8.924960136413574\n",
      "tensor grad AddBackward0 cuda:0 8.925\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-48.007, 42.479] μ=-1.386e-05 σ=0.037 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 6.226\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-48.009, 42.480] μ=-1.386e-05 σ=0.037 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 18.429\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-48.020, 42.492] μ=-1.387e-05 σ=0.037 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.623\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-48.030, 42.503] μ=-1.387e-05 σ=0.037 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.039\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-48.030, 42.503] μ=-1.387e-05 σ=0.037 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 12.640\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-48.223, 42.705] μ=-1.389e-05 σ=0.037 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 11.412\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-48.227, 42.709] μ=-1.389e-05 σ=0.037 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 11.573\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-48.241, 42.724] μ=-1.392e-05 σ=0.037 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.005\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-48.241, 42.724] μ=-1.392e-05 σ=0.037 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 5.476\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-48.241, 42.724] μ=-1.392e-05 σ=0.037 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 12.052\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-48.241, 42.724] μ=-1.392e-05 σ=0.037 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.487\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-48.244, 42.727] μ=-1.392e-05 σ=0.037 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 5.453\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-48.244, 42.727] μ=-1.392e-05 σ=0.037 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 11.780\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-48.259, 42.742] μ=-1.392e-05 σ=0.037 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.307\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-48.266, 42.750] μ=-1.392e-05 σ=0.037 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 6.973\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-48.266, 42.750] μ=-1.392e-05 σ=0.037 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.320\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-48.341, 42.829] μ=-1.393e-05 σ=0.037 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 11.487\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-48.437, 42.930] μ=-1.397e-05 σ=0.037 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.419\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-48.445, 42.938] μ=-1.397e-05 σ=0.037 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 12.133\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-48.512, 43.009] μ=-1.402e-05 σ=0.037 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 11.865\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-48.613, 43.115] μ=-1.405e-05 σ=0.037 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 6.360\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-48.613, 43.115] μ=-1.405e-05 σ=0.037 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.239\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-48.677, 43.182] μ=-1.408e-05 σ=0.037 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 3.188\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-48.677, 43.182] μ=-1.408e-05 σ=0.037 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.367\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-48.756, 43.265] μ=-1.409e-05 σ=0.037 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.737\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-48.773, 43.283] μ=-1.410e-05 σ=0.037 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.246\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-48.787, 43.298] μ=-1.410e-05 σ=0.037 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.510\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-48.794, 43.306] μ=-1.410e-05 σ=0.037 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 3.787\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-48.794, 43.306] μ=-1.410e-05 σ=0.037 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.250\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-48.794, 43.306] μ=-1.410e-05 σ=0.037 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 5.131\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-48.794, 43.306] μ=-1.410e-05 σ=0.037 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.239\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-48.801, 43.313] μ=-1.410e-05 σ=0.037 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.175\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-48.801, 43.313] μ=-1.410e-05 σ=0.037 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 11.161\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-48.801, 43.313] μ=-1.410e-05 σ=0.037 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.537\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-48.801, 43.313] μ=-1.410e-05 σ=0.037 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 13.443\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-48.859, 43.373] μ=-1.414e-05 σ=0.038 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.273\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-48.941, 43.460] μ=-1.419e-05 σ=0.038 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 5.668\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-48.941, 43.460] μ=-1.419e-05 σ=0.038 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.287\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-48.937, 43.456] μ=-1.419e-05 σ=0.038 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 5.552\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-48.937, 43.456] μ=-1.419e-05 σ=0.038 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 6.524\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-48.937, 43.456] μ=-1.419e-05 σ=0.038 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.404\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-48.937, 43.456] μ=-1.419e-05 σ=0.038 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.473\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-48.941, 43.460] μ=-1.419e-05 σ=0.038 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.889\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-48.951, 43.471] μ=-1.419e-05 σ=0.038 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.686\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-48.994, 43.516] μ=-1.419e-05 σ=0.038 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.531\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-48.987, 43.509] μ=-1.419e-05 σ=0.038 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.705\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-48.987, 43.509] μ=-1.419e-05 σ=0.038 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 15.538\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-49.051, 43.577] μ=-1.422e-05 σ=0.038 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 11.868\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-49.055, 43.580] μ=-1.422e-05 σ=0.038 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.315\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-49.055, 43.580] μ=-1.422e-05 σ=0.038 cuda:0\n",
      "[E17/150 I1900/4500]\n",
      "  Loss 6.868099212646484\n",
      "tensor grad AddBackward0 cuda:0 6.868\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-49.055, 43.580] μ=-1.422e-05 σ=0.038 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 12.696\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-49.098, 43.625] μ=-1.420e-05 σ=0.038 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.312\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-49.119, 43.648] μ=-1.423e-05 σ=0.038 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.873\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-49.126, 43.656] μ=-1.423e-05 σ=0.038 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.602\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-49.176, 43.708] μ=-1.426e-05 σ=0.038 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 11.256\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-49.416, 43.960] μ=-1.434e-05 σ=0.038 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.792\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-49.416, 43.960] μ=-1.434e-05 σ=0.038 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 5.946\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-49.416, 43.960] μ=-1.434e-05 σ=0.038 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.520\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-49.419, 43.964] μ=-1.434e-05 σ=0.038 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 6.800\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-49.426, 43.971] μ=-1.434e-05 σ=0.038 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 4.700\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-49.426, 43.971] μ=-1.434e-05 σ=0.038 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.856\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-49.430, 43.975] μ=-1.434e-05 σ=0.038 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 11.934\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-49.576, 44.129] μ=-1.440e-05 σ=0.038 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.861\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-49.580, 44.133] μ=-1.440e-05 σ=0.038 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.131\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-49.655, 44.212] μ=-1.443e-05 σ=0.038 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.217\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-49.662, 44.220] μ=-1.443e-05 σ=0.038 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 6.775\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-49.666, 44.224] μ=-1.443e-05 σ=0.038 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.551\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-49.676, 44.235] μ=-1.443e-05 σ=0.038 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.495\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-49.726, 44.288] μ=-1.445e-05 σ=0.038 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.197\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-49.726, 44.288] μ=-1.445e-05 σ=0.038 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 6.386\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-49.726, 44.288] μ=-1.445e-05 σ=0.038 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 5.862\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-49.726, 44.288] μ=-1.445e-05 σ=0.038 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 14.652\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-49.904, 44.476] μ=-1.448e-05 σ=0.038 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.897\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-49.904, 44.476] μ=-1.448e-05 σ=0.038 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 14.718\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-49.908, 44.480] μ=-1.448e-05 σ=0.038 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.195\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-49.911, 44.483] μ=-1.448e-05 σ=0.038 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.136\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-49.922, 44.495] μ=-1.449e-05 σ=0.038 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.849\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-49.922, 44.495] μ=-1.450e-05 σ=0.038 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 6.706\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-49.922, 44.495] μ=-1.449e-05 σ=0.038 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 13.224\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-50.068, 44.649] μ=-1.455e-05 σ=0.039 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.974\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-50.068, 44.649] μ=-1.455e-05 σ=0.039 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.085\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-50.082, 44.664] μ=-1.456e-05 σ=0.039 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.739\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-50.091, 44.674] μ=-1.456e-05 σ=0.039 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 6.277\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-50.091, 44.674] μ=-1.456e-05 σ=0.039 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.811\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-50.287, 44.881] μ=-1.462e-05 σ=0.039 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 5.407\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-50.287, 44.881] μ=-1.462e-05 σ=0.039 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.692\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-50.298, 44.892] μ=-1.462e-05 σ=0.039 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 13.840\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-50.422, 45.024] μ=-1.462e-05 σ=0.039 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.913\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-50.426, 45.028] μ=-1.462e-05 σ=0.039 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.556\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-50.426, 45.028] μ=-1.462e-05 σ=0.039 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 5.745\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-50.426, 45.028] μ=-1.462e-05 σ=0.039 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 12.820\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-50.444, 45.047] μ=-1.462e-05 σ=0.039 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.680\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-50.444, 45.047] μ=-1.462e-05 σ=0.039 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.160\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-50.447, 45.050] μ=-1.462e-05 σ=0.039 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 14.732\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-50.565, 45.175] μ=-1.466e-05 σ=0.039 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.559\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-50.568, 45.178] μ=-1.466e-05 σ=0.039 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.242\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-50.579, 45.190] μ=-1.466e-05 σ=0.039 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 5.319\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-50.579, 45.190] μ=-1.466e-05 σ=0.039 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 6.599\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-50.589, 45.201] μ=-1.466e-05 σ=0.039 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.925\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-50.565, 45.175] μ=-1.469e-05 σ=0.039 cuda:0\n",
      "[E17/150 I1950/4500]\n",
      "  Loss 6.4566650390625\n",
      "tensor grad AddBackward0 cuda:0 6.457\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-50.565, 45.175] μ=-1.469e-05 σ=0.039 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.160\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-50.572, 45.182] μ=-1.469e-05 σ=0.039 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 14.060\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-50.582, 45.193] μ=-1.469e-05 σ=0.039 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 4.460\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-50.582, 45.193] μ=-1.469e-05 σ=0.039 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.086\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-50.586, 45.197] μ=-1.469e-05 σ=0.039 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 5.703\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-50.593, 45.204] μ=-1.469e-05 σ=0.039 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.591\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-50.596, 45.208] μ=-1.469e-05 σ=0.039 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 6.576\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-50.596, 45.208] μ=-1.469e-05 σ=0.039 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.821\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-50.596, 45.208] μ=-1.469e-05 σ=0.039 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 13.968\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-50.639, 45.253] μ=-1.469e-05 σ=0.039 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 15.628\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-50.679, 45.296] μ=-1.470e-05 σ=0.039 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 3.995\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-50.679, 45.296] μ=-1.470e-05 σ=0.039 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.425\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-50.782, 45.406] μ=-1.474e-05 σ=0.039 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.613\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-50.931, 45.564] μ=-1.477e-05 σ=0.039 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.590\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-50.935, 45.568] μ=-1.477e-05 σ=0.039 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 6.329\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-50.935, 45.568] μ=-1.477e-05 σ=0.039 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.489\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-51.062, 45.704] μ=-1.479e-05 σ=0.039 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.609\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-51.062, 45.704] μ=-1.475e-05 σ=0.039 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 6.938\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-51.155, 45.802] μ=-1.477e-05 σ=0.039 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.173\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-51.165, 45.813] μ=-1.477e-05 σ=0.039 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 3.777\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-51.165, 45.813] μ=-1.477e-05 σ=0.039 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.609\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-51.197, 45.847] μ=-1.479e-05 σ=0.039 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.477\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-51.201, 45.851] μ=-1.479e-05 σ=0.039 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.516\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-51.201, 45.851] μ=-1.479e-05 σ=0.039 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.830\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-51.208, 45.859] μ=-1.480e-05 σ=0.039 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.537\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-51.240, 45.893] μ=-1.480e-05 σ=0.039 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 13.277\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-51.258, 45.912] μ=-1.482e-05 σ=0.040 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.556\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-51.265, 45.919] μ=-1.482e-05 σ=0.040 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.827\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-51.275, 45.931] μ=-1.482e-05 σ=0.040 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.329\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-51.290, 45.946] μ=-1.483e-05 σ=0.040 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 13.033\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-51.295, 45.951] μ=-1.483e-05 σ=0.040 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.787\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-51.312, 45.970] μ=-1.483e-05 σ=0.040 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 6.904\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-51.316, 45.974] μ=-1.484e-05 σ=0.040 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 6.077\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-51.316, 45.974] μ=-1.484e-05 σ=0.040 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.935\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-51.316, 45.974] μ=-1.484e-05 σ=0.040 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.415\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-51.319, 45.978] μ=-1.484e-05 σ=0.040 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 4.965\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-51.319, 45.978] μ=-1.484e-05 σ=0.040 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 4.892\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-51.319, 45.978] μ=-1.484e-05 σ=0.040 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 15.593\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-51.330, 45.989] μ=-1.484e-05 σ=0.040 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 6.821\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-51.337, 45.996] μ=-1.484e-05 σ=0.040 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.832\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-51.341, 46.000] μ=-1.484e-05 σ=0.040 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.311\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-51.343, 46.003] μ=-1.484e-05 σ=0.040 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.709\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-51.343, 46.003] μ=-1.484e-05 σ=0.040 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 5.597\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-51.343, 46.003] μ=-1.484e-05 σ=0.040 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 5.927\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-51.343, 46.003] μ=-1.484e-05 σ=0.040 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.318\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-51.343, 46.003] μ=-1.484e-05 σ=0.040 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.795\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-51.343, 46.003] μ=-1.484e-05 σ=0.040 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.478\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-51.347, 46.006] μ=-1.484e-05 σ=0.040 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 12.567\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-51.347, 46.006] μ=-1.484e-05 σ=0.040 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 6.418\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-51.350, 46.010] μ=-1.484e-05 σ=0.040 cuda:0\n",
      "[E17/150 I2000/4500]\n",
      "  Loss 6.7119035720825195\n",
      "tensor grad AddBackward0 cuda:0 6.712\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-51.350, 46.010] μ=-1.484e-05 σ=0.040 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 11.010\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-51.446, 46.112] μ=-1.486e-05 σ=0.040 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 6.360\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-51.446, 46.112] μ=-1.486e-05 σ=0.040 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.114\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-51.446, 46.112] μ=-1.486e-05 σ=0.040 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.124\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-51.449, 46.116] μ=-1.486e-05 σ=0.040 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.887\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-51.460, 46.128] μ=-1.487e-05 σ=0.040 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.590\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-51.467, 46.135] μ=-1.487e-05 σ=0.040 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.736\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-51.538, 46.211] μ=-1.491e-05 σ=0.040 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 12.381\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-51.694, 46.377] μ=-1.493e-05 σ=0.040 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.169\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-51.694, 46.377] μ=-1.493e-05 σ=0.040 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.825\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-51.701, 46.384] μ=-1.493e-05 σ=0.040 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.042\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-51.817, 46.509] μ=-1.495e-05 σ=0.040 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 6.891\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-51.817, 46.509] μ=-1.495e-05 σ=0.040 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 5.432\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-51.817, 46.509] μ=-1.495e-05 σ=0.040 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 5.819\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-51.817, 46.509] μ=-1.495e-05 σ=0.040 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 13.889\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-51.824, 46.517] μ=-1.495e-05 σ=0.040 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.640\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-51.832, 46.524] μ=-1.496e-05 σ=0.040 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 11.305\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-51.824, 46.517] μ=-1.497e-05 σ=0.040 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 6.850\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-51.824, 46.517] μ=-1.497e-05 σ=0.040 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 5.912\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-51.824, 46.517] μ=-1.497e-05 σ=0.040 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 12.995\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-51.828, 46.521] μ=-1.497e-05 σ=0.040 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.857\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-51.832, 46.524] μ=-1.497e-05 σ=0.040 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.388\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-51.832, 46.524] μ=-1.497e-05 σ=0.040 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.959\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-51.881, 46.577] μ=-1.497e-05 σ=0.040 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.477\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-51.884, 46.581] μ=-1.498e-05 σ=0.040 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.652\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-51.891, 46.589] μ=-1.498e-05 σ=0.040 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.188\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-51.966, 46.668] μ=-1.499e-05 σ=0.040 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 11.826\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-51.976, 46.680] μ=-1.500e-05 σ=0.040 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 6.849\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-51.976, 46.680] μ=-1.500e-05 σ=0.040 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.628\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-51.976, 46.680] μ=-1.500e-05 σ=0.040 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 13.919\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-52.010, 46.716] μ=-1.499e-05 σ=0.040 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 11.068\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-52.056, 46.765] μ=-1.501e-05 σ=0.040 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.177\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-52.180, 46.898] μ=-1.502e-05 σ=0.040 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 6.189\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-52.187, 46.905] μ=-1.502e-05 σ=0.040 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.896\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-52.194, 46.913] μ=-1.502e-05 σ=0.040 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 6.145\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-52.201, 46.920] μ=-1.502e-05 σ=0.040 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 13.301\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-52.278, 47.004] μ=-1.503e-05 σ=0.040 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 5.284\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-52.278, 47.004] μ=-1.503e-05 σ=0.040 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.561\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-52.310, 47.038] μ=-1.504e-05 σ=0.040 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.447\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-52.381, 47.114] μ=-1.506e-05 σ=0.040 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.962\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-52.384, 47.118] μ=-1.506e-05 σ=0.040 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.691\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-52.384, 47.118] μ=-1.506e-05 σ=0.040 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 4.487\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-52.384, 47.118] μ=-1.506e-05 σ=0.040 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.870\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-52.457, 47.196] μ=-1.508e-05 σ=0.040 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.665\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-52.461, 47.200] μ=-1.508e-05 σ=0.040 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 4.467\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-52.461, 47.200] μ=-1.508e-05 σ=0.040 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.453\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-52.521, 47.265] μ=-1.512e-05 σ=0.041 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 6.373\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-52.588, 47.337] μ=-1.514e-05 σ=0.041 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.842\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-52.591, 47.341] μ=-1.514e-05 σ=0.041 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 6.103\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-52.591, 47.341] μ=-1.514e-05 σ=0.041 cuda:0\n",
      "[E17/150 I2050/4500]\n",
      "  Loss 9.846478462219238\n",
      "tensor grad AddBackward0 cuda:0 9.846\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-52.598, 47.349] μ=-1.514e-05 σ=0.041 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 11.301\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-52.609, 47.360] μ=-1.514e-05 σ=0.041 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 14.080\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-52.613, 47.364] μ=-1.515e-05 σ=0.041 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.226\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-52.683, 47.440] μ=-1.517e-05 σ=0.041 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.232\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-52.867, 47.639] μ=-1.523e-05 σ=0.041 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 12.711\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-52.948, 47.727] μ=-1.525e-05 σ=0.041 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 6.012\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-52.948, 47.727] μ=-1.525e-05 σ=0.041 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.266\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-52.959, 47.738] μ=-1.525e-05 σ=0.041 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 11.417\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-52.959, 47.738] μ=-1.525e-05 σ=0.041 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.049\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-52.962, 47.742] μ=-1.525e-05 σ=0.041 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.327\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-52.962, 47.742] μ=-1.525e-05 σ=0.041 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.002\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-52.962, 47.742] μ=-1.525e-05 σ=0.041 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 4.317\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-52.962, 47.742] μ=-1.525e-05 σ=0.041 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.653\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-52.969, 47.749] μ=-1.525e-05 σ=0.041 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.544\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-52.972, 47.753] μ=-1.525e-05 σ=0.041 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.575\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-52.980, 47.761] μ=-1.525e-05 σ=0.041 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 14.916\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-53.008, 47.791] μ=-1.524e-05 σ=0.041 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.136\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-53.011, 47.794] μ=-1.524e-05 σ=0.041 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 12.084\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-53.053, 47.840] μ=-1.525e-05 σ=0.041 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.816\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-53.052, 47.839] μ=-1.525e-05 σ=0.041 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.785\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-53.035, 47.820] μ=-1.524e-05 σ=0.041 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.176\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-53.035, 47.820] μ=-1.524e-05 σ=0.041 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.442\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-53.035, 47.820] μ=-1.524e-05 σ=0.041 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 11.008\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-53.045, 47.832] μ=-1.524e-05 σ=0.041 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.103\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-53.052, 47.839] μ=-1.525e-05 σ=0.041 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 12.390\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-53.084, 47.874] μ=-1.528e-05 σ=0.041 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 5.721\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-53.084, 47.874] μ=-1.528e-05 σ=0.041 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.806\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-53.091, 47.881] μ=-1.528e-05 σ=0.041 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.815\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-53.087, 47.878] μ=-1.528e-05 σ=0.041 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.262\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-53.204, 48.004] μ=-1.530e-05 σ=0.041 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 6.655\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-53.204, 48.004] μ=-1.530e-05 σ=0.041 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.518\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-53.215, 48.016] μ=-1.530e-05 σ=0.041 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.641\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-53.231, 48.033] μ=-1.530e-05 σ=0.041 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.747\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-53.221, 48.022] μ=-1.530e-05 σ=0.041 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.250\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-53.224, 48.026] μ=-1.530e-05 σ=0.041 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.891\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-53.242, 48.045] μ=-1.530e-05 σ=0.041 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 5.268\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-53.242, 48.045] μ=-1.530e-05 σ=0.041 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 12.752\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-53.245, 48.049] μ=-1.529e-05 σ=0.041 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 11.994\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-53.252, 48.056] μ=-1.530e-05 σ=0.041 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.477\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-53.256, 48.060] μ=-1.530e-05 σ=0.041 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 12.964\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-53.390, 48.206] μ=-1.531e-05 σ=0.041 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.871\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-53.411, 48.229] μ=-1.529e-05 σ=0.041 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.613\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-53.411, 48.229] μ=-1.529e-05 σ=0.041 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.678\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-53.425, 48.244] μ=-1.530e-05 σ=0.041 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 4.610\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-53.425, 48.244] μ=-1.530e-05 σ=0.041 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 13.040\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-53.468, 48.290] μ=-1.531e-05 σ=0.041 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 11.624\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-53.512, 48.338] μ=-1.534e-05 σ=0.041 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.754\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-53.523, 48.350] μ=-1.534e-05 σ=0.041 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.857\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-53.523, 48.350] μ=-1.534e-05 σ=0.041 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.878\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-53.523, 48.350] μ=-1.534e-05 σ=0.041 cuda:0\n",
      "[E17/150 I2100/4500]\n",
      "  Loss 6.470038890838623\n",
      "tensor grad AddBackward0 cuda:0 6.470\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-53.523, 48.350] μ=-1.534e-05 σ=0.041 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 13.208\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-53.593, 48.426] μ=-1.536e-05 σ=0.041 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.299\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-53.600, 48.434] μ=-1.536e-05 σ=0.041 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.725\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-53.724, 48.568] μ=-1.538e-05 σ=0.042 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.876\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-53.724, 48.568] μ=-1.538e-05 σ=0.042 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 12.167\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-53.805, 48.656] μ=-1.540e-05 σ=0.042 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.525\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-53.815, 48.667] μ=-1.540e-05 σ=0.042 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.809\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-53.822, 48.675] μ=-1.541e-05 σ=0.042 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.051\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-53.833, 48.686] μ=-1.541e-05 σ=0.042 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 6.169\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-53.833, 48.686] μ=-1.541e-05 σ=0.042 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 14.545\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-53.840, 48.694] μ=-1.541e-05 σ=0.042 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.076\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-53.840, 48.694] μ=-1.541e-05 σ=0.042 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 3.252\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-53.840, 48.694] μ=-1.541e-05 σ=0.042 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.805\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-53.840, 48.694] μ=-1.541e-05 σ=0.042 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 4.803\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-53.840, 48.694] μ=-1.541e-05 σ=0.042 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 5.407\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-53.840, 48.694] μ=-1.541e-05 σ=0.042 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.270\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-53.840, 48.694] μ=-1.541e-05 σ=0.042 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 6.262\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-53.840, 48.694] μ=-1.541e-05 σ=0.042 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 13.399\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-53.896, 48.755] μ=-1.543e-05 σ=0.042 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.035\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-53.903, 48.763] μ=-1.543e-05 σ=0.042 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 5.893\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-53.903, 48.763] μ=-1.543e-05 σ=0.042 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 11.266\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-53.910, 48.771] μ=-1.543e-05 σ=0.042 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.210\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-53.910, 48.771] μ=-1.544e-05 σ=0.042 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.671\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-53.970, 48.836] μ=-1.546e-05 σ=0.042 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.293\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-53.970, 48.836] μ=-1.546e-05 σ=0.042 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.154\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-54.266, 49.158] μ=-1.550e-05 σ=0.042 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 6.752\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-54.266, 49.158] μ=-1.550e-05 σ=0.042 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 12.979\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-54.389, 49.292] μ=-1.553e-05 σ=0.042 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 6.320\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-54.389, 49.292] μ=-1.553e-05 σ=0.042 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.431\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-54.396, 49.300] μ=-1.553e-05 σ=0.042 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.704\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-54.400, 49.304] μ=-1.554e-05 σ=0.042 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.247\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-54.495, 49.407] μ=-1.555e-05 σ=0.042 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.773\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-54.498, 49.411] μ=-1.555e-05 σ=0.042 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.042\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-54.502, 49.415] μ=-1.555e-05 σ=0.042 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 15.410\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-54.509, 49.423] μ=-1.555e-05 σ=0.042 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 4.658\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-54.509, 49.423] μ=-1.555e-05 σ=0.042 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.260\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-54.520, 49.435] μ=-1.555e-05 σ=0.042 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.953\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-54.657, 49.584] μ=-1.561e-05 σ=0.042 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 4.246\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-54.657, 49.584] μ=-1.561e-05 σ=0.042 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.446\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-54.738, 49.672] μ=-1.563e-05 σ=0.042 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 13.154\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-54.762, 49.698] μ=-1.564e-05 σ=0.042 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.491\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-54.762, 49.698] μ=-1.564e-05 σ=0.042 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.358\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-54.773, 49.710] μ=-1.564e-05 σ=0.042 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.266\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-54.776, 49.714] μ=-1.564e-05 σ=0.042 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 2.680\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-54.776, 49.714] μ=-1.564e-05 σ=0.042 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.682\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-54.780, 49.717] μ=-1.564e-05 σ=0.042 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.327\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-54.784, 49.721] μ=-1.564e-05 σ=0.042 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.668\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-54.780, 49.717] μ=-1.564e-05 σ=0.042 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 11.198\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-54.822, 49.763] μ=-1.566e-05 σ=0.042 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.156\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-54.822, 49.763] μ=-1.566e-05 σ=0.042 cuda:0\n",
      "[E17/150 I2150/4500]\n",
      "  Loss 7.708000183105469\n",
      "tensor grad AddBackward0 cuda:0 7.708\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-54.822, 49.763] μ=-1.566e-05 σ=0.042 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 6.352\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-54.822, 49.763] μ=-1.566e-05 σ=0.042 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 14.404\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-54.829, 49.771] μ=-1.566e-05 σ=0.042 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.050\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-54.836, 49.779] μ=-1.566e-05 σ=0.042 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.996\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-54.836, 49.779] μ=-1.566e-05 σ=0.042 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.943\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-54.836, 49.779] μ=-1.566e-05 σ=0.042 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.228\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-54.914, 49.863] μ=-1.567e-05 σ=0.042 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.178\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-54.917, 49.867] μ=-1.567e-05 σ=0.043 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.742\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-54.914, 49.863] μ=-1.567e-05 σ=0.043 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 12.355\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-55.193, 50.167] μ=-1.571e-05 σ=0.043 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 11.919\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-55.306, 50.290] μ=-1.575e-05 σ=0.043 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.562\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-55.362, 50.352] μ=-1.576e-05 σ=0.043 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.650\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-55.433, 50.429] μ=-1.575e-05 σ=0.043 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 5.782\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-55.433, 50.429] μ=-1.575e-05 σ=0.043 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.970\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-55.493, 50.494] μ=-1.577e-05 σ=0.043 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 6.984\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-55.493, 50.494] μ=-1.577e-05 σ=0.043 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.784\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-55.493, 50.494] μ=-1.577e-05 σ=0.043 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.974\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-55.546, 50.552] μ=-1.580e-05 σ=0.043 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 11.473\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-55.556, 50.563] μ=-1.580e-05 σ=0.043 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 15.610\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-55.567, 50.575] μ=-1.580e-05 σ=0.043 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 6.735\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-55.567, 50.575] μ=-1.580e-05 σ=0.043 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.394\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-55.574, 50.583] μ=-1.580e-05 σ=0.043 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.816\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-55.581, 50.590] μ=-1.580e-05 σ=0.043 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.687\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-55.581, 50.590] μ=-1.580e-05 σ=0.043 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 11.001\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-55.616, 50.629] μ=-1.581e-05 σ=0.043 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.107\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-55.651, 50.667] μ=-1.583e-05 σ=0.043 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.077\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-55.655, 50.671] μ=-1.583e-05 σ=0.043 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.202\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-55.658, 50.675] μ=-1.583e-05 σ=0.043 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 12.726\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-55.665, 50.682] μ=-1.584e-05 σ=0.043 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.266\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-55.669, 50.686] μ=-1.584e-05 σ=0.043 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 4.901\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-55.669, 50.686] μ=-1.584e-05 σ=0.043 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.300\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-55.704, 50.725] μ=-1.586e-05 σ=0.043 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.008\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-55.708, 50.729] μ=-1.586e-05 σ=0.043 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.063\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-55.711, 50.732] μ=-1.586e-05 σ=0.043 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.301\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-55.711, 50.732] μ=-1.586e-05 σ=0.043 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 11.237\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-55.722, 50.744] μ=-1.586e-05 σ=0.043 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.461\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-55.725, 50.748] μ=-1.586e-05 σ=0.043 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.218\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-55.725, 50.748] μ=-1.586e-05 σ=0.043 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.556\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-55.785, 50.813] μ=-1.586e-05 σ=0.043 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.506\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-55.803, 50.832] μ=-1.588e-05 σ=0.043 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.353\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-55.806, 50.836] μ=-1.588e-05 σ=0.043 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 11.143\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-55.806, 50.836] μ=-1.588e-05 σ=0.043 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 15.575\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-55.909, 50.948] μ=-1.593e-05 σ=0.043 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 5.167\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-55.909, 50.948] μ=-1.593e-05 σ=0.043 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.734\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-55.909, 50.948] μ=-1.593e-05 σ=0.043 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 12.149\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-55.923, 50.963] μ=-1.593e-05 σ=0.043 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.314\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-55.937, 50.979] μ=-1.594e-05 σ=0.043 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 14.036\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-55.940, 50.982] μ=-1.594e-05 σ=0.043 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 4.329\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-55.940, 50.982] μ=-1.594e-05 σ=0.043 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 14.457\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-56.095, 51.152] μ=-1.597e-05 σ=0.044 cuda:0\n",
      "[E17/150 I2200/4500]\n",
      "  Loss 9.432991027832031\n",
      "tensor grad AddBackward0 cuda:0 9.433\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-56.177, 51.241] μ=-1.599e-05 σ=0.044 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.540\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-56.254, 51.326] μ=-1.601e-05 σ=0.044 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.919\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-56.293, 51.369] μ=-1.601e-05 σ=0.044 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 15.135\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-56.494, 51.590] μ=-1.605e-05 σ=0.044 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.237\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-56.497, 51.593] μ=-1.605e-05 σ=0.044 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.136\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-56.497, 51.593] μ=-1.605e-05 σ=0.044 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.427\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-56.501, 51.597] μ=-1.605e-05 σ=0.044 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.974\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-56.505, 51.601] μ=-1.605e-05 σ=0.044 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.248\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-56.512, 51.609] μ=-1.605e-05 σ=0.044 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 4.431\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-56.512, 51.609] μ=-1.605e-05 σ=0.044 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 6.703\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-56.512, 51.609] μ=-1.605e-05 σ=0.044 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 5.101\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-56.512, 51.609] μ=-1.605e-05 σ=0.044 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 13.069\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-56.621, 51.729] μ=-1.606e-05 σ=0.044 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.924\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-56.755, 51.876] μ=-1.609e-05 σ=0.044 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.544\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-56.882, 52.016] μ=-1.611e-05 σ=0.044 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 12.217\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-56.882, 52.016] μ=-1.611e-05 σ=0.044 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 11.627\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-56.946, 52.086] μ=-1.613e-05 σ=0.044 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 16.614\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-56.967, 52.109] μ=-1.613e-05 σ=0.044 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.976\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-56.974, 52.117] μ=-1.613e-05 σ=0.044 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 4.563\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-56.974, 52.117] μ=-1.613e-05 σ=0.044 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.933\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-56.974, 52.117] μ=-1.614e-05 σ=0.044 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.905\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-56.974, 52.117] μ=-1.614e-05 σ=0.044 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 4.901\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-56.974, 52.117] μ=-1.614e-05 σ=0.044 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.863\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-56.979, 52.123] μ=-1.614e-05 σ=0.044 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 11.838\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-56.986, 52.130] μ=-1.614e-05 σ=0.044 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.444\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-56.986, 52.130] μ=-1.613e-05 σ=0.044 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.628\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-56.986, 52.130] μ=-1.613e-05 σ=0.044 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.889\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-56.986, 52.130] μ=-1.613e-05 σ=0.044 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.150\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-56.993, 52.138] μ=-1.613e-05 σ=0.044 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.888\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-57.004, 52.150] μ=-1.613e-05 σ=0.044 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 5.371\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-57.004, 52.150] μ=-1.613e-05 σ=0.044 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.316\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-57.004, 52.150] μ=-1.613e-05 σ=0.044 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.932\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-57.018, 52.165] μ=-1.615e-05 σ=0.044 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.768\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-57.014, 52.161] μ=-1.611e-05 σ=0.044 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.804\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-57.018, 52.165] μ=-1.611e-05 σ=0.044 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 14.154\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-57.019, 52.167] μ=-1.612e-05 σ=0.044 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 4.870\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-57.019, 52.167] μ=-1.612e-05 σ=0.044 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 6.493\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-57.019, 52.167] μ=-1.612e-05 σ=0.044 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 11.103\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-57.033, 52.182] μ=-1.612e-05 σ=0.044 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 14.776\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-57.088, 52.243] μ=-1.614e-05 σ=0.044 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.142\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-57.088, 52.243] μ=-1.614e-05 σ=0.044 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 6.192\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-57.088, 52.243] μ=-1.614e-05 σ=0.044 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 12.333\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-57.096, 52.251] μ=-1.614e-05 σ=0.044 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 14.423\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-57.103, 52.259] μ=-1.614e-05 σ=0.044 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 5.720\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-57.103, 52.259] μ=-1.614e-05 σ=0.044 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.470\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-57.113, 52.270] μ=-1.615e-05 σ=0.044 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.555\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-57.117, 52.274] μ=-1.615e-05 σ=0.044 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.911\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-57.120, 52.278] μ=-1.615e-05 σ=0.044 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.802\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-57.120, 52.278] μ=-1.615e-05 σ=0.044 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.450\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-57.124, 52.282] μ=-1.615e-05 σ=0.044 cuda:0\n",
      "[E17/150 I2250/4500]\n",
      "  Loss 6.235384464263916\n",
      "tensor grad AddBackward0 cuda:0 6.235\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-57.124, 52.282] μ=-1.615e-05 σ=0.044 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.592\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-57.163, 52.325] μ=-1.615e-05 σ=0.044 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.259\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-57.166, 52.329] μ=-1.615e-05 σ=0.044 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.801\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-57.198, 52.363] μ=-1.615e-05 σ=0.044 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.081\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-57.205, 52.371] μ=-1.615e-05 σ=0.044 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.932\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-57.205, 52.371] μ=-1.615e-05 σ=0.044 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.556\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-57.208, 52.375] μ=-1.616e-05 σ=0.044 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.396\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-57.219, 52.387] μ=-1.616e-05 σ=0.044 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 11.842\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-57.335, 52.514] μ=-1.619e-05 σ=0.044 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.412\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-57.338, 52.518] μ=-1.619e-05 σ=0.044 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.110\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-57.342, 52.522] μ=-1.619e-05 σ=0.044 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.471\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-57.416, 52.604] μ=-1.621e-05 σ=0.045 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 4.962\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-57.416, 52.603] μ=-1.621e-05 σ=0.045 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.531\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-57.419, 52.607] μ=-1.621e-05 σ=0.045 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 13.643\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-57.458, 52.650] μ=-1.621e-05 σ=0.045 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 5.938\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-57.458, 52.650] μ=-1.621e-05 σ=0.045 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 11.435\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-57.518, 52.716] μ=-1.624e-05 σ=0.045 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.280\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-57.529, 52.728] μ=-1.625e-05 σ=0.045 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.974\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-57.529, 52.728] μ=-1.624e-05 σ=0.045 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.048\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-57.582, 52.786] μ=-1.626e-05 σ=0.045 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.131\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-57.589, 52.794] μ=-1.626e-05 σ=0.045 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 6.677\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-57.589, 52.794] μ=-1.626e-05 σ=0.045 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 6.788\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-57.589, 52.794] μ=-1.626e-05 σ=0.045 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 12.975\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-57.591, 52.797] μ=-1.626e-05 σ=0.045 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.281\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-57.595, 52.801] μ=-1.626e-05 σ=0.045 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.205\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-57.595, 52.801] μ=-1.626e-05 σ=0.045 cuda:0\n",
      "tensor grad AddBackward0 cuda:0 16.038\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-57.690, 34.411] μ=-2.581e-05 σ=0.040 \u001b[31mNaN!\u001b[0m cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.912\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-57.715, 34.428] μ=-2.586e-05 σ=0.040 \u001b[31mNaN!\u001b[0m cuda:0\n",
      "tensor grad AddBackward0 cuda:0 12.381\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-57.757, 34.458] μ=-2.591e-05 σ=0.040 \u001b[31mNaN!\u001b[0m cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.943\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-57.764, 34.463] μ=-2.591e-05 σ=0.040 \u001b[31mNaN!\u001b[0m cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.014\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-57.771, 34.468] μ=-2.591e-05 σ=0.040 \u001b[31mNaN!\u001b[0m cuda:0\n",
      "tensor grad AddBackward0 cuda:0 5.816\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-57.771, 34.468] μ=-2.591e-05 σ=0.040 \u001b[31mNaN!\u001b[0m cuda:0\n",
      "tensor grad AddBackward0 cuda:0 5.663\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-57.775, 34.471] μ=-2.592e-05 σ=0.040 \u001b[31mNaN!\u001b[0m cuda:0\n",
      "tensor grad AddBackward0 cuda:0 11.003\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-57.779, 34.473] μ=-2.592e-05 σ=0.040 \u001b[31mNaN!\u001b[0m cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.194\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-57.796, 34.486] μ=-2.594e-05 σ=0.040 \u001b[31mNaN!\u001b[0m cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.116\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-57.800, 34.488] μ=-2.594e-05 σ=0.040 \u001b[31mNaN!\u001b[0m cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.455\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-57.881, 34.546] μ=-2.599e-05 σ=0.040 \u001b[31mNaN!\u001b[0m cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.113\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-57.913, 34.568] μ=-2.599e-05 σ=0.040 \u001b[31mNaN!\u001b[0m cuda:0\n",
      "tensor grad AddBackward0 cuda:0 6.480\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-57.913, 34.568] μ=-2.599e-05 σ=0.040 \u001b[31mNaN!\u001b[0m cuda:0\n",
      "tensor grad AddBackward0 cuda:0 5.659\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-57.913, 34.568] μ=-2.599e-05 σ=0.040 \u001b[31mNaN!\u001b[0m cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.568\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-57.916, 34.571] μ=-2.599e-05 σ=0.040 \u001b[31mNaN!\u001b[0m cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.758\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-57.913, 34.568] μ=-2.599e-05 σ=0.040 \u001b[31mNaN!\u001b[0m cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.202\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-57.966, 34.606] μ=-2.597e-05 σ=0.040 \u001b[31mNaN!\u001b[0m cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.625\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-57.966, 34.606] μ=-2.597e-05 σ=0.040 \u001b[31mNaN!\u001b[0m cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.450\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-57.969, 34.608] μ=-2.597e-05 σ=0.040 \u001b[31mNaN!\u001b[0m cuda:0\n",
      "tensor grad AddBackward0 cuda:0 15.986\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-58.011, 34.638] μ=-2.600e-05 σ=0.040 \u001b[31mNaN!\u001b[0m cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.693\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-58.018, 34.643] μ=-2.601e-05 σ=0.040 \u001b[31mNaN!\u001b[0m cuda:0\n",
      "tensor grad AddBackward0 cuda:0 14.407\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-58.044, 34.661] μ=-2.601e-05 σ=0.040 \u001b[31mNaN!\u001b[0m cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.012\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-58.047, 34.664] μ=-2.601e-05 σ=0.040 \u001b[31mNaN!\u001b[0m cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.684\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-58.092, 34.695] μ=-2.604e-05 σ=0.040 \u001b[31mNaN!\u001b[0m cuda:0\n",
      "[E17/150 I2300/4500]\n",
      "  Loss 9.1083345413208\n",
      "tensor grad AddBackward0 cuda:0 9.108\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-58.092, 34.695] μ=-2.604e-05 σ=0.040 \u001b[31mNaN!\u001b[0m cuda:0\n",
      "tensor grad AddBackward0 cuda:0 11.392\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-58.219, 34.785] μ=-2.607e-05 σ=0.040 \u001b[31mNaN!\u001b[0m cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.660\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-58.268, 34.820] μ=-2.610e-05 σ=0.040 \u001b[31mNaN!\u001b[0m cuda:0\n",
      "tensor grad AddBackward0 cuda:0 6.997\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-58.268, 34.820] μ=-2.610e-05 σ=0.040 \u001b[31mNaN!\u001b[0m cuda:0\n",
      "tensor grad AddBackward0 cuda:0 12.670\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-58.638, 35.082] μ=-2.623e-05 σ=0.040 \u001b[31mNaN!\u001b[0m cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.648\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-58.758, 35.167] μ=-2.627e-05 σ=0.040 \u001b[31mNaN!\u001b[0m cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.473\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-58.774, 35.178] μ=-2.625e-05 σ=0.040 \u001b[31mNaN!\u001b[0m cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.391\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-58.784, 35.185] μ=-2.625e-05 σ=0.040 \u001b[31mNaN!\u001b[0m cuda:0\n",
      "tensor grad AddBackward0 cuda:0 13.625\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-58.788, 35.188] μ=-2.625e-05 σ=0.040 \u001b[31mNaN!\u001b[0m cuda:0\n",
      "tensor grad AddBackward0 cuda:0 6.238\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-58.788, 35.188] μ=-2.625e-05 σ=0.040 \u001b[31mNaN!\u001b[0m cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.018\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-58.783, 35.185] μ=-2.625e-05 σ=0.040 \u001b[31mNaN!\u001b[0m cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.566\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-58.783, 35.185] μ=-2.625e-05 σ=0.040 \u001b[31mNaN!\u001b[0m cuda:0\n",
      "tensor grad AddBackward0 cuda:0 13.591\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-58.804, 35.200] μ=-2.627e-05 σ=0.040 \u001b[31mNaN!\u001b[0m cuda:0\n",
      "tensor grad AddBackward0 cuda:0 6.698\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-58.806, 35.201] μ=-2.627e-05 σ=0.040 \u001b[31mNaN!\u001b[0m cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.056\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-58.807, 35.202] μ=-2.628e-05 σ=0.040 \u001b[31mNaN!\u001b[0m cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.032\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-58.811, 35.205] μ=-2.628e-05 σ=0.040 \u001b[31mNaN!\u001b[0m cuda:0\n",
      "tensor grad AddBackward0 cuda:0 14.846\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-58.896, 35.265] μ=-2.629e-05 σ=0.040 \u001b[31mNaN!\u001b[0m cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.329\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-58.896, 35.265] μ=-2.629e-05 σ=0.040 \u001b[31mNaN!\u001b[0m cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.222\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-58.896, 35.265] μ=-2.629e-05 σ=0.040 \u001b[31mNaN!\u001b[0m cuda:0\n",
      "tensor grad AddBackward0 cuda:0 17.943\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-58.977, 35.322] μ=-2.633e-05 σ=0.040 \u001b[31mNaN!\u001b[0m cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.669\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-59.002, 35.339] μ=-2.631e-05 σ=0.040 \u001b[31mNaN!\u001b[0m cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.172\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-59.037, 35.364] μ=-2.627e-05 σ=0.040 \u001b[31mNaN!\u001b[0m cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.083\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-59.037, 35.364] μ=-2.626e-05 σ=0.040 \u001b[31mNaN!\u001b[0m cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.306\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-59.121, 35.424] μ=-2.626e-05 σ=0.041 \u001b[31mNaN!\u001b[0m cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.160\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-59.122, 35.424] μ=-2.626e-05 σ=0.041 \u001b[31mNaN!\u001b[0m cuda:0\n",
      "tensor grad AddBackward0 cuda:0 6.012\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-59.129, 35.429] μ=-2.626e-05 σ=0.041 \u001b[31mNaN!\u001b[0m cuda:0\n",
      "tensor grad AddBackward0 cuda:0 13.264\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-59.130, 35.430] μ=-2.622e-05 σ=0.041 \u001b[31mNaN!\u001b[0m cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.727\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-59.131, 35.431] μ=-2.622e-05 σ=0.041 \u001b[31mNaN!\u001b[0m cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.180\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-59.145, 35.441] μ=-2.622e-05 σ=0.041 \u001b[31mNaN!\u001b[0m cuda:0\n",
      "tensor grad AddBackward0 cuda:0 12.297\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-59.159, 35.451] μ=-2.621e-05 σ=0.041 \u001b[31mNaN!\u001b[0m cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.384\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-59.166, 35.456] μ=-2.622e-05 σ=0.041 \u001b[31mNaN!\u001b[0m cuda:0\n",
      "tensor grad AddBackward0 cuda:0 13.082\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-59.248, 35.513] μ=-2.626e-05 σ=0.041 \u001b[31mNaN!\u001b[0m cuda:0\n",
      "tensor grad AddBackward0 cuda:0 13.567\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-59.332, 35.573] μ=-2.627e-05 σ=0.041 \u001b[31mNaN!\u001b[0m cuda:0\n",
      "tensor grad AddBackward0 cuda:0 4.112\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-59.332, 35.573] μ=-2.627e-05 σ=0.041 \u001b[31mNaN!\u001b[0m cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.754\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-59.356, 35.590] μ=-2.629e-05 σ=0.041 \u001b[31mNaN!\u001b[0m cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.184\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-59.409, 35.627] μ=-2.634e-05 σ=0.041 \u001b[31mNaN!\u001b[0m cuda:0\n",
      "tensor grad AddBackward0 cuda:0 6.366\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-59.409, 35.627] μ=-2.634e-05 σ=0.041 \u001b[31mNaN!\u001b[0m cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.241\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-59.409, 35.627] μ=-2.633e-05 σ=0.041 \u001b[31mNaN!\u001b[0m cuda:0\n",
      "tensor grad AddBackward0 cuda:0 11.306\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-59.476, 35.675] μ=-2.631e-05 σ=0.041 \u001b[31mNaN!\u001b[0m cuda:0\n",
      "tensor grad AddBackward0 cuda:0 11.092\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-59.483, 35.680] μ=-2.631e-05 σ=0.041 \u001b[31mNaN!\u001b[0m cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.450\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-59.497, 35.690] μ=-2.631e-05 σ=0.041 \u001b[31mNaN!\u001b[0m cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.439\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-59.502, 35.693] μ=-2.632e-05 σ=0.041 \u001b[31mNaN!\u001b[0m cuda:0\n",
      "tensor grad AddBackward0 cuda:0 6.877\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-59.506, 35.696] μ=-2.632e-05 σ=0.041 \u001b[31mNaN!\u001b[0m cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.531\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-59.502, 35.693] μ=-2.632e-05 σ=0.041 \u001b[31mNaN!\u001b[0m cuda:0\n",
      "tensor grad AddBackward0 cuda:0 6.644\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-59.502, 35.693] μ=-2.632e-05 σ=0.041 \u001b[31mNaN!\u001b[0m cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.274\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-59.502, 35.693] μ=-2.632e-05 σ=0.041 \u001b[31mNaN!\u001b[0m cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.490\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-59.505, 35.695] μ=-2.632e-05 σ=0.041 \u001b[31mNaN!\u001b[0m cuda:0\n",
      "tensor grad AddBackward0 cuda:0 11.146\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-59.491, 35.685] μ=-2.635e-05 σ=0.041 \u001b[31mNaN!\u001b[0m cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.038\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-59.498, 35.690] μ=-2.636e-05 σ=0.041 \u001b[31mNaN!\u001b[0m cuda:0\n",
      "tensor grad AddBackward0 cuda:0 6.939\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-59.498, 35.690] μ=-2.636e-05 σ=0.041 \u001b[31mNaN!\u001b[0m cuda:0\n",
      "[E17/150 I2350/4500]\n",
      "  Loss 13.431129455566406\n",
      "tensor grad AddBackward0 cuda:0 13.431\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-59.640, 35.791] μ=-2.643e-05 σ=0.041 \u001b[31mNaN!\u001b[0m cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.220\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-59.704, 35.836] μ=-2.648e-05 σ=0.041 \u001b[31mNaN!\u001b[0m cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.818\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-59.711, 35.841] μ=-2.648e-05 σ=0.041 \u001b[31mNaN!\u001b[0m cuda:0\n",
      "tensor grad AddBackward0 cuda:0 3.340\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-59.711, 35.841] μ=-2.648e-05 σ=0.041 \u001b[31mNaN!\u001b[0m cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.665\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-59.711, 35.841] μ=-2.648e-05 σ=0.041 \u001b[31mNaN!\u001b[0m cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.043\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-59.760, 35.876] μ=-2.650e-05 σ=0.041 \u001b[31mNaN!\u001b[0m cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.675\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-59.764, 35.878] μ=-2.650e-05 σ=0.041 \u001b[31mNaN!\u001b[0m cuda:0\n",
      "tensor grad AddBackward0 cuda:0 13.013\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-59.789, 35.896] μ=-2.654e-05 σ=0.041 \u001b[31mNaN!\u001b[0m cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.754\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-59.799, 35.903] μ=-2.655e-05 σ=0.041 \u001b[31mNaN!\u001b[0m cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.783\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-59.803, 35.906] μ=-2.655e-05 σ=0.041 \u001b[31mNaN!\u001b[0m cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.699\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-59.803, 35.906] μ=-2.655e-05 σ=0.041 \u001b[31mNaN!\u001b[0m cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.588\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-59.803, 35.906] μ=-2.656e-05 σ=0.041 \u001b[31mNaN!\u001b[0m cuda:0\n",
      "tensor grad AddBackward0 cuda:0 12.099\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-59.808, 35.909] μ=-2.656e-05 σ=0.041 \u001b[31mNaN!\u001b[0m cuda:0\n",
      "tensor grad AddBackward0 cuda:0 6.999\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-59.804, 35.907] μ=-2.656e-05 σ=0.041 \u001b[31mNaN!\u001b[0m cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.159\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-59.907, 35.980] μ=-2.661e-05 σ=0.041 \u001b[31mNaN!\u001b[0m cuda:0\n",
      "tensor grad AddBackward0 cuda:0 13.070\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-59.918, 35.987] μ=-2.661e-05 σ=0.041 \u001b[31mNaN!\u001b[0m cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.163\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-59.926, 35.993] μ=-2.661e-05 σ=0.041 \u001b[31mNaN!\u001b[0m cuda:0\n",
      "tensor grad AddBackward0 cuda:0 11.251\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-59.997, 36.043] μ=-2.663e-05 σ=0.041 \u001b[31mNaN!\u001b[0m cuda:0\n",
      "tensor grad AddBackward0 cuda:0 11.468\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-60.004, 36.048] μ=-2.663e-05 σ=0.041 \u001b[31mNaN!\u001b[0m cuda:0\n",
      "tensor grad AddBackward0 cuda:0 14.203\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-60.067, 36.093] μ=-2.665e-05 σ=0.041 \u001b[31mNaN!\u001b[0m cuda:0\n",
      "tensor grad AddBackward0 cuda:0 12.197\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-60.071, 36.095] μ=-2.666e-05 σ=0.041 \u001b[31mNaN!\u001b[0m cuda:0\n",
      "tensor grad AddBackward0 cuda:0 14.644\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-60.152, 36.153] μ=-2.669e-05 σ=0.041 \u001b[31mNaN!\u001b[0m cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.160\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-60.156, 36.155] μ=-2.669e-05 σ=0.041 \u001b[31mNaN!\u001b[0m cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.304\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-60.159, 36.158] μ=-2.669e-05 σ=0.041 \u001b[31mNaN!\u001b[0m cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.565\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-60.159, 36.158] μ=-2.670e-05 σ=0.041 \u001b[31mNaN!\u001b[0m cuda:0\n",
      "tensor grad AddBackward0 cuda:0 6.569\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-60.159, 36.158] μ=-2.669e-05 σ=0.041 \u001b[31mNaN!\u001b[0m cuda:0\n",
      "tensor grad AddBackward0 cuda:0 13.019\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-60.163, 36.160] μ=-2.669e-05 σ=0.041 \u001b[31mNaN!\u001b[0m cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.308\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-60.170, 36.165] μ=-2.670e-05 σ=0.041 \u001b[31mNaN!\u001b[0m cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.218\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-60.170, 36.165] μ=-2.669e-05 σ=0.041 \u001b[31mNaN!\u001b[0m cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.136\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-60.170, 36.165] μ=-2.669e-05 σ=0.041 \u001b[31mNaN!\u001b[0m cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.030\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-60.213, 36.195] μ=-2.671e-05 σ=0.041 \u001b[31mNaN!\u001b[0m cuda:0\n",
      "tensor grad AddBackward0 cuda:0 6.494\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-60.220, 36.200] μ=-2.671e-05 σ=0.041 \u001b[31mNaN!\u001b[0m cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.968\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-60.223, 36.203] μ=-2.672e-05 σ=0.041 \u001b[31mNaN!\u001b[0m cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.972\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-60.234, 36.210] μ=-2.672e-05 σ=0.041 \u001b[31mNaN!\u001b[0m cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.071\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-60.234, 36.210] μ=-2.672e-05 σ=0.041 \u001b[31mNaN!\u001b[0m cuda:0\n",
      "tensor grad AddBackward0 cuda:0 9.164\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-60.255, 36.225] μ=-2.674e-05 σ=0.041 \u001b[31mNaN!\u001b[0m cuda:0\n",
      "tensor grad AddBackward0 cuda:0 6.896\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-60.253, 36.224] μ=-2.675e-05 σ=0.041 \u001b[31mNaN!\u001b[0m cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.890\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-60.257, 36.227] μ=-2.675e-05 σ=0.041 \u001b[31mNaN!\u001b[0m cuda:0\n",
      "tensor grad AddBackward0 cuda:0 12.214\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-60.285, 36.247] μ=-2.678e-05 σ=0.041 \u001b[31mNaN!\u001b[0m cuda:0\n",
      "tensor grad AddBackward0 cuda:0 10.880\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-60.296, 36.254] μ=-2.679e-05 σ=0.041 \u001b[31mNaN!\u001b[0m cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.248\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-60.296, 36.254] μ=-2.679e-05 σ=0.041 \u001b[31mNaN!\u001b[0m cuda:0\n",
      "tensor grad AddBackward0 cuda:0 8.314\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-60.296, 36.254] μ=-2.679e-05 σ=0.041 \u001b[31mNaN!\u001b[0m cuda:0\n",
      "tensor grad AddBackward0 cuda:0 11.170\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-60.366, 36.304] μ=-2.687e-05 σ=0.042 \u001b[31mNaN!\u001b[0m cuda:0\n",
      "tensor grad AddBackward0 cuda:0 7.650\n",
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-60.370, 36.307] μ=-2.687e-05 σ=0.042 \u001b[31mNaN!\u001b[0m cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 | 0/133 [1:00:43<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor grad AddBackward0 cuda:0 11.916\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[69], line 169\u001b[0m\n\u001b[1;32m    166\u001b[0m \u001b[38;5;66;03m# accelerator.backward(loss)\u001b[39;00m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28mprint\u001b[39m(loss)\n\u001b[0;32m--> 169\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m    170\u001b[0m \u001b[38;5;28mprint\u001b[39m(model\u001b[38;5;241m.\u001b[39mdiffusion_prior\u001b[38;5;241m.\u001b[39mnet\u001b[38;5;241m.\u001b[39mcausal_transformer\u001b[38;5;241m.\u001b[39mlayers[\u001b[38;5;241m4\u001b[39m][\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m5\u001b[39m]\u001b[38;5;241m.\u001b[39mweight\u001b[38;5;241m.\u001b[39mgrad)\n\u001b[1;32m    171\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[0;32m~/miniconda3/envs/mindeye/lib/python3.11/site-packages/torch/_tensor.py:492\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    482\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    483\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    484\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    485\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    490\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    491\u001b[0m     )\n\u001b[0;32m--> 492\u001b[0m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mbackward(\n\u001b[1;32m    493\u001b[0m     \u001b[38;5;28mself\u001b[39m, gradient, retain_graph, create_graph, inputs\u001b[38;5;241m=\u001b[39minputs\n\u001b[1;32m    494\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/mindeye/lib/python3.11/site-packages/torch/autograd/__init__.py:251\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    246\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    248\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 251\u001b[0m Variable\u001b[38;5;241m.\u001b[39m_execution_engine\u001b[38;5;241m.\u001b[39mrun_backward(  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    252\u001b[0m     tensors,\n\u001b[1;32m    253\u001b[0m     grad_tensors_,\n\u001b[1;32m    254\u001b[0m     retain_graph,\n\u001b[1;32m    255\u001b[0m     create_graph,\n\u001b[1;32m    256\u001b[0m     inputs,\n\u001b[1;32m    257\u001b[0m     allow_unreachable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    258\u001b[0m     accumulate_grad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    259\u001b[0m )\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "### tracking\n",
    "# epoch = 0\n",
    "# losses, test_losses, lrs = [], [], []\n",
    "# best = {\"loss\": 1e9, \"epoch\": 0}\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "### optimization\n",
    "mse = nn.MSELoss()\n",
    "l1 = nn.L1Loss()\n",
    "cfg[\"model\"][\"cos_anneal_start\"] = 0.004\n",
    "cfg[\"model\"][\"cos_anneal_end\"] = 0.0075\n",
    "soft_loss_temps = utils.cosine_anneal(\n",
    "    cfg[\"model\"][\"cos_anneal_start\"],\n",
    "    cfg[\"model\"][\"cos_anneal_end\"],\n",
    "    cfg[\"model\"][\"num_epochs\"] - int(cfg[\"model\"][\"mixup_pct\"] * cfg[\"model\"][\"num_epochs\"])\n",
    ")\n",
    "\n",
    "### run\n",
    "model.to(cfg[\"device\"])\n",
    "progress_bar = tqdm(range(epoch, cfg[\"model\"][\"num_epochs\"]), ncols=1200, disable=False)\n",
    "seed_all(cfg[\"seed\"])\n",
    "for epoch in progress_bar:\n",
    "    fwd_percent_correct = 0.\n",
    "    bwd_percent_correct = 0.\n",
    "    recon_cossim = 0.\n",
    "    recon_mse = 0.\n",
    "    loss_clip_total = 0.\n",
    "    loss_blurry_total = 0.\n",
    "    loss_blurry_cont_total = 0.\n",
    "    loss_prior_total = 0.\n",
    "    blurry_pixcorr = 0.\n",
    "\n",
    "    train_dl = get_dataloaders(config=cfg)[0][\"train\"][\"brainreader_mouse\"]\n",
    "\n",
    "    ### train\n",
    "    model.train()\n",
    "    for train_i, batch in enumerate(train_dl):\n",
    "        if train_i % 50 == 0:\n",
    "            print(f\"[E{epoch}/{cfg['model']['num_epochs']} I{train_i}/{cfg['model']['num_iterations_per_epoch']}]\")\n",
    "        with torch.cuda.amp.autocast(dtype=cfg[\"data_type\"]):\n",
    "            optimizer.zero_grad()\n",
    "            loss = 0.\n",
    "\n",
    "            ### select data\n",
    "            voxel_list = [dp[\"resp\"].unsqueeze(1).to(cfg[\"device\"]) for dp in batch]  # (B, 1, num_voxels = num_of_neurons)\n",
    "            image = img_tform(torch.cat([dp[\"stim\"] for dp in batch], dim=0).to(cfg[\"device\"]))  # (B, 3, 224, 224)\n",
    "\n",
    "            ### augment image\n",
    "            if cfg[\"model\"][\"use_image_aug\"]: \n",
    "                image = img_augment(image)\n",
    "\n",
    "            if epoch < int(cfg[\"model\"][\"mixup_pct\"] * cfg[\"model\"][\"num_epochs\"]):\n",
    "                perm_list = [perm_iters[f\"subj0{s}_iter{train_i}\"].detach().to(cfg[\"device\"]) for s in cfg[\"model\"][\"subj_list\"]]\n",
    "                perm = torch.cat(perm_list, dim=0)\n",
    "                betas_list = [betas_iters[f\"subj0{s}_iter{train_i}\"].detach().to(cfg[\"device\"]) for s in cfg[\"model\"][\"subj_list\"]]\n",
    "                betas = torch.cat(betas_list, dim=0).to(cfg[\"data_type\"])\n",
    "                select_list = [select_iters[f\"subj0{s}_iter{train_i}\"].detach().to(cfg[\"device\"]) for s in cfg[\"model\"][\"subj_list\"]]\n",
    "                select = torch.cat(select_list, dim=0)\n",
    "\n",
    "            ### map voxels to clip space\n",
    "            voxel_ridge = torch.cat([model.ridge(voxel_list[si], si) for si, s in enumerate(cfg[\"model\"][\"subj_list\"])], dim=0)\n",
    "            backbone, clip_voxels, blurry_image_enc_ = model.backbone(voxel_ridge)\n",
    "\n",
    "            ### map GT image to clip space\n",
    "            clip_target = clip_img_embedder(image)\n",
    "            assert not torch.any(torch.isnan(clip_target))\n",
    "\n",
    "            ### normalize clip embeddings\n",
    "            if cfg[\"model\"][\"clip_scale\"] > 0:\n",
    "                clip_voxels_norm = nn.functional.normalize(clip_voxels.flatten(1), dim=-1)\n",
    "                clip_target_norm = nn.functional.normalize(clip_target.flatten(1), dim=-1)\n",
    "\n",
    "            if cfg[\"model\"][\"use_prior\"]:\n",
    "                loss_prior, prior_out = model.diffusion_prior(text_embed=backbone, image_embed=clip_target)\n",
    "                if torch.isnan(loss_prior).any():\n",
    "                    print(f\"  Loss prior is NaN, skipping...\")\n",
    "                    del backbone, clip_voxels, blurry_image_enc_, clip_target, clip_voxels_norm, clip_target_norm, loss_prior, prior_out\n",
    "                    import gc\n",
    "                    gc.collect()\n",
    "                    torch.cuda.empty_cache()\n",
    "                    continue\n",
    "                for i in range(3):\n",
    "                    if torch.isnan(loss_prior).any():\n",
    "                        print(f\"  Loss prior is NaN, trying again...\")\n",
    "                        del loss_prior, prior_out\n",
    "                        torch.cuda.empty_cache()\n",
    "                        loss_prior, prior_out = model.diffusion_prior(text_embed=backbone, image_embed=clip_target)\n",
    "                    else:\n",
    "                        break\n",
    "\n",
    "                loss_prior_total += loss_prior.item()\n",
    "                loss_prior *= cfg[\"model\"][\"prior_scale\"]\n",
    "                loss += loss_prior\n",
    "\n",
    "                recon_cossim += nn.functional.cosine_similarity(prior_out, clip_target).mean().item()\n",
    "                recon_mse += mse(prior_out, clip_target).item()\n",
    "\n",
    "            if cfg[\"model\"][\"clip_scale\"] > 0:\n",
    "                if epoch < int(cfg[\"model\"][\"mixup_pct\"] * cfg[\"model\"][\"num_epochs\"]):\n",
    "                    loss_clip = utils.mixco_nce(\n",
    "                        clip_voxels_norm,\n",
    "                        clip_target_norm,\n",
    "                        temp=.006,\n",
    "                        perm=perm, betas=betas, select=select)\n",
    "                else:\n",
    "                    epoch_temp = soft_loss_temps[epoch - int(cfg[\"model\"][\"mixup_pct\"] * cfg[\"model\"][\"num_epochs\"])]\n",
    "                    loss_clip = utils.soft_clip_loss(\n",
    "                        clip_voxels_norm,\n",
    "                        clip_target_norm,\n",
    "                        temp=epoch_temp,\n",
    "                    )\n",
    "\n",
    "                loss_clip_total += loss_clip.item()\n",
    "                loss_clip *= cfg[\"model\"][\"clip_scale\"]\n",
    "                loss += loss_clip\n",
    "\n",
    "            if cfg[\"model\"][\"blurry_recon\"]:     \n",
    "                image_enc_pred, transformer_feats = blurry_image_enc_\n",
    "\n",
    "                # image_enc = autoenc.encode(2 * image - 1).latent_dist.mode() * 0.18215\n",
    "                image_enc = autoenc.encode(image).latent_dist.mode() * 0.18215  # already z-scored\n",
    "                loss_blurry = l1(image_enc_pred, image_enc)\n",
    "                loss_blurry_total += loss_blurry.item()\n",
    "\n",
    "                if epoch < int(cfg[\"model\"][\"mixup_pct\"] * cfg[\"model\"][\"num_epochs\"]):\n",
    "                    image_enc_shuf = image_enc[perm]\n",
    "                    betas_shape = [-1] + [1]*(len(image_enc.shape)-1)\n",
    "                    image_enc[select] = image_enc[select] * betas[select].reshape(*betas_shape) + \\\n",
    "                        image_enc_shuf[select] * (1 - betas[select]).reshape(*betas_shape)\n",
    "\n",
    "                # image_norm = (image - mean) / std\n",
    "                image_norm = image  # already z-scored\n",
    "                # print(f\"  Blurring Aug {image_norm.shape}\")\n",
    "                # image_aug = (blur_augs(image) - mean) / std\n",
    "                image_aug = blur_augs(image)  # already z-scored\n",
    "                _, cnx_embeds = cnx(image_norm)\n",
    "                _, cnx_aug_embeds = cnx(image_aug)\n",
    "\n",
    "                cont_loss = utils.soft_cont_loss(\n",
    "                    nn.functional.normalize(transformer_feats.reshape(-1, transformer_feats.shape[-1]), dim=-1),\n",
    "                    nn.functional.normalize(cnx_embeds.reshape(-1, cnx_embeds.shape[-1]), dim=-1),\n",
    "                    nn.functional.normalize(cnx_aug_embeds.reshape(-1, cnx_embeds.shape[-1]), dim=-1),\n",
    "                    temp=0.2)\n",
    "                loss_blurry_cont_total += cont_loss.item()\n",
    "\n",
    "                loss += (loss_blurry + 0.1 * cont_loss) * cfg[\"model\"][\"blur_scale\"] #/.18215\n",
    "\n",
    "            if cfg[\"model\"][\"clip_scale\"]>0:\n",
    "                # forward and backward top 1 accuracy        \n",
    "                labels = torch.arange(len(clip_voxels_norm)).to(clip_voxels_norm.device) \n",
    "                fwd_percent_correct += utils.topk(utils.batchwise_cosine_similarity(clip_voxels_norm, clip_target_norm), labels, k=1).item()\n",
    "                bwd_percent_correct += utils.topk(utils.batchwise_cosine_similarity(clip_target_norm, clip_voxels_norm), labels, k=1).item()\n",
    "\n",
    "            if cfg[\"model\"][\"blurry_recon\"]:\n",
    "                with torch.no_grad():\n",
    "                    # only doing pixcorr eval on a subset of the samples per batch because its costly & slow to compute autoenc.decode()\n",
    "                    random_samps = np.random.choice(np.arange(len(image)), size=len(image)//5, replace=False)\n",
    "                    # blurry_recon_images = (autoenc.decode(image_enc_pred[random_samps]/0.18215).sample / 2 + 0.5).clamp(0,1)\n",
    "                    blurry_recon_images = (autoenc.decode(image_enc_pred[random_samps]/0.18215).sample)\n",
    "                    pixcorr = utils.pixcorr(image[random_samps], blurry_recon_images)\n",
    "                    blurry_pixcorr += pixcorr.item()\n",
    "\n",
    "            if train_i % 50 == 0:\n",
    "                print(f\"  Loss {loss.item()}\")\n",
    "            utils.check_loss(loss)\n",
    "            # accelerator.backward(loss)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            losses.append(loss.item())\n",
    "            lrs.append(optimizer.param_groups[0]['lr'])\n",
    "\n",
    "            if cfg[\"model\"][\"optimization\"][\"lr_scheduler_type\"] is not None:\n",
    "                lr_scheduler.step()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "    ### evaluate\n",
    "    print(\"\\n---Evaluating---\\n\")\n",
    "    model.eval()\n",
    "    with torch.no_grad(), torch.cuda.amp.autocast(dtype=cfg[\"data_type\"]):\n",
    "        n_minibatches = 0\n",
    "        test_loss=0.\n",
    "        test_loss_clip_total = 0.\n",
    "        test_loss_prior_total = 0.\n",
    "        test_blurry_pixcorr = 0.\n",
    "        test_fwd_percent_correct = 0.\n",
    "        test_bwd_percent_correct = 0.\n",
    "        eval_dl = get_dataloaders(config=cfg)[0][\"val\"][\"brainreader_mouse\"]\n",
    "        for batch in eval_dl:\n",
    "            voxel_list = [dp[\"resp\"].unsqueeze(1).to(cfg[\"device\"]) for dp in batch]  # (B, 1, num_voxels = num_of_neurons)\n",
    "            image = img_tform(torch.cat([dp[\"stim\"] for dp in batch], dim=0).to(cfg[\"device\"]))  # (B, 3, 224, 224)\n",
    "\n",
    "            voxel_ridge = torch.cat([model.ridge(voxel_list[si], si) for si, s in enumerate(cfg[\"model\"][\"subj_list\"])], dim=0)\n",
    "            backbone, clip_voxels, blurry_image_enc_ = model.backbone(voxel_ridge)\n",
    "\n",
    "            clip_target = clip_img_embedder(image.float())\n",
    "            if cfg[\"model\"][\"clip_scale\"]>0:\n",
    "                clip_voxels_norm = nn.functional.normalize(clip_voxels.flatten(1), dim=-1)\n",
    "                clip_target_norm = nn.functional.normalize(clip_target.flatten(1), dim=-1)\n",
    "\n",
    "            if cfg[\"model\"][\"use_prior\"]:\n",
    "                loss_prior, _ = model.diffusion_prior(text_embed=backbone, image_embed=clip_target)\n",
    "                test_loss_prior_total += loss_prior.item()\n",
    "                loss_prior *= cfg[\"model\"][\"prior_scale\"]\n",
    "                test_loss += loss_prior\n",
    "\n",
    "            if cfg[\"model\"][\"clip_scale\"]>0:\n",
    "                loss_clip = utils.soft_clip_loss(\n",
    "                    clip_voxels_norm,\n",
    "                    clip_target_norm,\n",
    "                    temp=.006,\n",
    "                )\n",
    "\n",
    "                test_loss_clip_total += loss_clip.item()\n",
    "                loss_clip = loss_clip * cfg[\"model\"][\"clip_scale\"]\n",
    "                test_loss += loss_clip\n",
    "\n",
    "            if cfg[\"model\"][\"blurry_recon\"]:\n",
    "                image_enc_pred, _ = blurry_image_enc_\n",
    "                # blurry_recon_images = (autoenc.decode(image_enc_pred/0.18215).sample / 2 + 0.5).clamp(0,1)\n",
    "                blurry_recon_images = (autoenc.decode(image_enc_pred/0.18215).sample)\n",
    "                pixcorr = utils.pixcorr(image, blurry_recon_images)\n",
    "                test_blurry_pixcorr += pixcorr.item()\n",
    "\n",
    "            if cfg[\"model\"][\"clip_scale\"]>0:\n",
    "                # forward and backward top 1 accuracy        \n",
    "                labels = torch.arange(len(clip_voxels_norm)).to(clip_voxels_norm.device) \n",
    "                test_fwd_percent_correct += utils.topk(utils.batchwise_cosine_similarity(clip_voxels_norm, clip_target_norm), labels, k=1).item()\n",
    "                test_bwd_percent_correct += utils.topk(utils.batchwise_cosine_similarity(clip_target_norm, clip_voxels_norm), labels, k=1).item()\n",
    "\n",
    "            n_minibatches += 1\n",
    "\n",
    "        test_loss /= n_minibatches\n",
    "        test_loss_clip_total /= n_minibatches\n",
    "        test_loss_prior_total /= n_minibatches\n",
    "        test_blurry_pixcorr /= n_minibatches\n",
    "        test_fwd_percent_correct /= n_minibatches\n",
    "        test_bwd_percent_correct /= n_minibatches\n",
    "\n",
    "        utils.check_loss(test_loss)                \n",
    "        test_losses.append(test_loss.item())\n",
    "\n",
    "        if test_loss.item() < best[\"loss\"]:\n",
    "            save_ckpt(f'best')\n",
    "            best[\"loss\"] = test_loss.item()\n",
    "            best[\"epoch\"] = epoch\n",
    "\n",
    "        logs = {\n",
    "            \"train/loss\": np.mean(losses[-(train_i+1):]),\n",
    "            \"test/loss\": test_loss.item(),\n",
    "            \"train/lr\": lrs[-1],\n",
    "            \"train/num_steps\": len(losses),\n",
    "            \"test/num_steps\": len(test_losses),\n",
    "            \"train/fwd_pct_correct\": fwd_percent_correct / (train_i + 1),\n",
    "            \"train/bwd_pct_correct\": bwd_percent_correct / (train_i + 1),\n",
    "            \"test/test_fwd_pct_correct\": test_fwd_percent_correct,\n",
    "            \"test/test_bwd_pct_correct\": test_bwd_percent_correct,\n",
    "            \"train/loss_clip_total\": loss_clip_total / (train_i + 1),\n",
    "            \"train/loss_blurry_total\": loss_blurry_total / (train_i + 1),\n",
    "            \"train/loss_blurry_cont_total\": loss_blurry_cont_total / (train_i + 1),\n",
    "            \"test/loss_clip_total\": test_loss_clip_total,\n",
    "            \"train/blurry_pixcorr\": blurry_pixcorr / (train_i + 1),\n",
    "            \"test/blurry_pixcorr\": test_blurry_pixcorr,\n",
    "            \"train/recon_cossim\": recon_cossim / (train_i + 1),\n",
    "            \"train/recon_mse\": recon_mse / (train_i + 1),\n",
    "            \"train/loss_prior\": loss_prior_total / (train_i + 1),\n",
    "            \"test/loss_prior\": test_loss_prior_total,\n",
    "        }\n",
    "\n",
    "        # if finished training, save jpg recons if they exist\n",
    "        if (epoch == cfg[\"model\"][\"num_epochs\"]-1) or (epoch % cfg[\"model\"][\"ckpt_interval\"] == 0):\n",
    "            if cfg[\"model\"][\"blurry_recon\"]:    \n",
    "                # image_enc = autoenc.encode(2*image[:4]-1).latent_dist.mode() * 0.18215\n",
    "                image_enc = autoenc.encode(image[:4]).latent_dist.mode() * 0.18215  # already z-scored\n",
    "                # transform blurry recon latents to images and plot it\n",
    "                fig, axes = plt.subplots(1, 8, figsize=(10, 4))\n",
    "                jj=-1\n",
    "                for j in [0,1,2,3]:\n",
    "                    jj+=1\n",
    "                    # axes[jj].imshow(utils.torch_to_Image((autoenc.decode(image_enc[[j]]/0.18215).sample / 2 + 0.5).clamp(0,1)))\n",
    "                    axes[jj].imshow(utils.torch_to_Image(autoenc.decode(image_enc[[j]]/0.18215).sample))\n",
    "                    axes[jj].axis('off')\n",
    "                    jj+=1\n",
    "                    # axes[jj].imshow(utils.torch_to_Image((autoenc.decode(image_enc_pred[[j]]/0.18215).sample / 2 + 0.5).clamp(0,1)))\n",
    "                    axes[jj].imshow(utils.torch_to_Image(autoenc.decode(image_enc_pred[[j]]/0.18215).sample))\n",
    "                    axes[jj].axis('off')\n",
    "\n",
    "                if wandb_log:\n",
    "                    logs[f\"test/blur_recons\"] = wandb.Image(fig, caption=f\"epoch{epoch:03d}\")\n",
    "                    plt.close()\n",
    "                else:\n",
    "                    plt.show()\n",
    "\n",
    "        progress_bar.set_postfix(**logs)\n",
    "\n",
    "        if wandb_log: wandb.log(logs)\n",
    "\n",
    "    # Save model checkpoint and reconstruct\n",
    "    # if (ckpt_saving) and (epoch % ckpt_interval == 0):\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        save_ckpt(f'ep{epoch}')\n",
    "    save_ckpt(f'last')\n",
    "\n",
    "    # wait for other GPUs to catch up if needed\n",
    "    # accelerator.wait_for_everyone()\n",
    "    torch.cuda.empty_cache()\n",
    "    print(f\"Finished epoch {epoch} / {cfg['model']['num_epochs']}\")\n",
    "    \n",
    "    plt.imshow(blurry_recon_images[0].permute(1,2,0).cpu().detach().to(torch.float32))\n",
    "    plt.show()\n",
    "    plt.imshow(image[0].permute(1,2,0).cpu().detach().to(torch.float32))\n",
    "    plt.show()\n",
    "    plt.plot(losses)\n",
    "    plt.show()\n",
    "    plt.plot(test_losses)\n",
    "    plt.show()\n",
    "\n",
    "print(\"\\n===Finished!===\\n\")\n",
    "save_ckpt(f'last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83743a36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor[1664, 6656] n=11075584 (42Mb) x∈[-0.333, 0.529] μ=4.843e-14 σ=0.001 cuda:0\n"
     ]
    }
   ],
   "source": [
    "loss.backward()\n",
    "print(model.diffusion_prior.net.causal_transformer.layers[4][1][5].weight.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "8d7e4439",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "6704dbfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  diffusion_prior.net.causal_transformer.layers.4.1.5.weight has NaN values\n"
     ]
    }
   ],
   "source": [
    "for n,p in model.named_parameters():\n",
    "    # print(n,p.grad)\n",
    "    if p.grad is not None and torch.isnan(p.grad).any():\n",
    "        print(f\"  {n} has NaN values\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b4f5a349",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial NaN count: 0\n",
      "requires_grad: True\n",
      "NaN count in new_weight_matrix before assignment: 0\n",
      "Number of NaN values after reinitialization: 0\n",
      "requires_grad preserved: True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Get the weight matrix\n",
    "weight_matrix = model.diffusion_prior.net.causal_transformer.layers[4][1][5].weight\n",
    "\n",
    "# Check initial state\n",
    "print(f\"Initial NaN count: {torch.isnan(weight_matrix).sum().item()}\")\n",
    "print(f\"requires_grad: {weight_matrix.requires_grad}\")\n",
    "\n",
    "# Create a mask for NaN values\n",
    "nan_mask = torch.isnan(weight_matrix)\n",
    "\n",
    "# Generate random values from uniform distribution (e.g., between -0.1 and 0.1)\n",
    "random_values = torch.rand_like(weight_matrix, dtype=weight_matrix.dtype, \n",
    "                              device=weight_matrix.device) * 0.2 - 0.1  # Scale to [-0.1, 0.1]\n",
    "\n",
    "# Replace NaN values using torch.where (non-in-place)\n",
    "new_weight_matrix = torch.where(nan_mask, random_values, weight_matrix)\n",
    "\n",
    "# Verify no NaNs in the new tensor before assignment\n",
    "print(f\"NaN count in new_weight_matrix before assignment: {torch.isnan(new_weight_matrix).sum().item()}\")\n",
    "\n",
    "# Reassign to the model parameter\n",
    "model.diffusion_prior.net.causal_transformer.layers[4][1][5].weight = nn.Parameter(\n",
    "    new_weight_matrix, requires_grad=weight_matrix.requires_grad\n",
    ")\n",
    "\n",
    "# Verify the update in the model\n",
    "updated_weight_matrix = model.diffusion_prior.net.causal_transformer.layers[4][1][5].weight\n",
    "print(f\"Number of NaN values after reinitialization: {torch.isnan(updated_weight_matrix).sum().item()}\")\n",
    "print(f\"requires_grad preserved: {updated_weight_matrix.requires_grad}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "9b794105",
   "metadata": {},
   "outputs": [],
   "source": [
    "for n,p in model.named_parameters():\n",
    "    if torch.isnan(p).any():\n",
    "        print(f\"  {n} has NaN values\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "90989d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_ckpt(tag):\n",
    "    ckpt_path = cfg[\"model\"][\"outdir\"]+f'/{tag}.pth'\n",
    "    torch.save({\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'lr_scheduler': lr_scheduler.state_dict(),\n",
    "        'train_losses': losses,\n",
    "        'test_losses': test_losses,\n",
    "        'lrs': lrs,\n",
    "        \"cfg\": cfg,\n",
    "        \"best\": best,\n",
    "    }, ckpt_path)\n",
    "    print(f\"\\n---saved {cfg['model']['outdir']}/{tag} ckpt!---\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "a7e81ae3-171f-40ad-a3e8-24bee4472325",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(losses)\n",
    "plt.show()\n",
    "plt.plot(test_losses)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6533885",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mindeye",
   "language": "python",
   "name": "mindeye"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
