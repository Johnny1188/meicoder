{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "import lovely_tensors as lt\n",
    "\n",
    "import csng\n",
    "from csng.CNN_Decoder import CNN_Decoder\n",
    "from csng.utils import plot_comparison, standardize, normalize, get_mean_and_std, count_parameters\n",
    "from csng.losses import SSIMLoss, MSELossWithCrop\n",
    "\n",
    "# from orig_data import prepare_spiking_data_loaders\n",
    "from data import prepare_v1_dataloaders, SyntheticDataset, BatchPatchesDataLoader, MixedBatchLoader, PerSampleStoredDataset\n",
    "\n",
    "lt.monkey_patch()\n",
    "\n",
    "DATA_PATH = os.path.join(os.environ[\"DATA_PATH\"], \"cat_V1_spiking_model\")\n",
    "print(f\"{DATA_PATH=}\")\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"{device=}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_name = \"2023-08-26_10-50-13\"\n",
    "\n",
    "### load ckpt\n",
    "ckpt = torch.load(os.path.join(DATA_PATH, \"models\", run_name, \"decoder.pt\"))\n",
    "config = ckpt[\"config\"]\n",
    "history = ckpt[\"history\"]\n",
    "best = ckpt[\"best\"]\n",
    "decoder = CNN_Decoder(**config[\"decoder\"][\"model\"]).to(device)\n",
    "decoder.load_state_dict(ckpt[\"decoder\"])\n",
    "\n",
    "if config[\"stim_crop_win\"] is not None:\n",
    "    crop_stim = lambda x: x[..., config[\"stim_crop_win\"][0], config[\"stim_crop_win\"][1]]\n",
    "else:\n",
    "    crop_stim = lambda x: x\n",
    "\n",
    "np.random.seed(config[\"seed\"])\n",
    "torch.manual_seed(config[\"seed\"])\n",
    "random.seed(config[\"seed\"])\n",
    "\n",
    "decoder.eval()\n",
    "### turn off only batchnorm and dropout\n",
    "# for m in decoder.modules():\n",
    "#     if isinstance(m, (nn.BatchNorm1d, nn.BatchNorm2d, nn.Dropout)):\n",
    "#         m.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### input\n",
    "x = torch.zeros(1, decoder.layers[0].in_features, device=device)\n",
    "# x = torch.ones(1, decoder.layers[0].in_features, device=device)\n",
    "x.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### output - intermediate\n",
    "y = decoder.layers[0](x)\n",
    "y = decoder.layers[4](y) # (B, C, H, W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### output - final\n",
    "y = decoder.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### collect gradient maps for each channel for specific location\n",
    "loc = (0, 0)\n",
    "grad_maps = []\n",
    "for i in range(y.shape[1]):\n",
    "    y[0, i, loc[0], loc[1]].backward(retain_graph=True)\n",
    "    grad_maps.append(x.grad.detach().cpu().numpy()[0])\n",
    "    x.grad.zero_()\n",
    "grad_maps = np.array(grad_maps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(grad_maps == 0).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### plot - intermediate\n",
    "fig, axs = plt.subplots(4, 4, figsize=(16, 16))\n",
    "for i, ax in enumerate(axs.flatten()):\n",
    "    grad_map_standardized = standardize(torch.tensor(grad_maps[i]).view(1, 1, 100, 100)).numpy()[0, 0]\n",
    "    ax.imshow(-np.log(1 - grad_map_standardized + 1e-4), cmap=\"magma\")\n",
    "    ax.set_title(f\"C={i} H={loc[0]} W={loc[1]}\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### plot - final\n",
    "fig = plt.figure(figsize=(6, 6))\n",
    "ax = fig.add_subplot(111)\n",
    "grad_map_standardized = standardize(torch.tensor(grad_maps[0]).view(1, 1, 100, 100)).numpy()[0, 0]\n",
    "ax.imshow(-np.log(1 - grad_map_standardized + 1e-4), cmap=\"magma\")\n",
    "ax.set_title(f\"H={loc[0]} W={loc[1]}\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
