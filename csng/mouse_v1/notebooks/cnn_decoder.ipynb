{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from copy import deepcopy\n",
    "import dill\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "import lovely_tensors as lt\n",
    "import wandb\n",
    "from nnfabrik.builder import get_data\n",
    "\n",
    "import csng\n",
    "from csng.CNN_Decoder import CNN_Decoder\n",
    "from csng.utils import crop, plot_comparison, standardize, normalize, get_mean_and_std, count_parameters, plot_losses\n",
    "from csng.losses import SSIMLoss, MultiSSIMLoss, Loss, CroppedLoss\n",
    "from csng.data import MixedBatchLoader\n",
    "from csng.readins import (\n",
    "    MultiReadIn,\n",
    "    HypernetReadIn,\n",
    "    ConvReadIn,\n",
    "    AttentionReadIn,\n",
    "    FCReadIn,\n",
    "    AutoEncoderReadIn,\n",
    "    Conv1dReadIn,\n",
    "    LocalizedFCReadIn,\n",
    "    MEIReadIn,\n",
    ")\n",
    "\n",
    "from encoder import get_encoder\n",
    "from data_utils import (\n",
    "    get_mouse_v1_data,\n",
    "    append_syn_dataloaders,\n",
    "    append_data_aug_dataloaders,\n",
    "    RespGaussianNoise,\n",
    ")\n",
    "from cnn_decoder_utils import train, val, get_all_data\n",
    "\n",
    "lt.monkey_patch()\n",
    "DATA_PATH = os.path.join(os.environ[\"DATA_PATH\"], \"mouse_v1_sensorium22\")\n",
    "print(f\"{DATA_PATH=}\")\n",
    "\n",
    "%env \"WANDB_NOTEBOOK_NAME\" \"cnn_decoder.ipynb\"\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"data\": {\n",
    "        \"mixing_strategy\": \"parallel_min\", # needed only with multiple base dataloaders\n",
    "    },\n",
    "    \"device\": \"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    "    \"seed\": 0,\n",
    "    # \"crop_win\": None,\n",
    "    # \"crop_win\": (slice(7, 29), slice(15, 51)),\n",
    "    \"crop_win\": (22, 36),\n",
    "    # \"wandb\": None,\n",
    "    \"wandb\": {\n",
    "        \"project\": \"CSNG\",\n",
    "        \"group\": \"sensorium_2022\",\n",
    "    },\n",
    "}\n",
    "print(f\"... Running on {config['device']} ...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(config[\"seed\"])\n",
    "torch.manual_seed(config[\"seed\"])\n",
    "random.seed(config[\"seed\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloaders = dict()\n",
    "config[\"data\"][\"mouse_v1\"] = None\n",
    "config[\"data\"][\"syn_dataset_config\"] = None\n",
    "config[\"data\"][\"data_augmentation\"] = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mouse V1 dataset (Sensorium 2022)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### prep data config\n",
    "config[\"data\"][\"mouse_v1\"] = {\n",
    "    \"dataset_fn\": \"sensorium.datasets.static_loaders\",\n",
    "    \"dataset_config\": {\n",
    "        \"paths\": [ # from https://gin.g-node.org/cajal/Sensorium2022/src/master\n",
    "            # os.path.join(DATA_PATH, \"static26872-17-20-GrayImageNet-94c6ff995dac583098847cfecd43e7b6.zip\"), # mouse 1\n",
    "            # os.path.join(DATA_PATH, \"static27204-5-13-GrayImageNet-94c6ff995dac583098847cfecd43e7b6.zip\"), # sensorium+ (mouse 2)\n",
    "            os.path.join(DATA_PATH, \"static21067-10-18-GrayImageNet-94c6ff995dac583098847cfecd43e7b6.zip\"), # pretraining (mouse 3)\n",
    "            os.path.join(DATA_PATH, \"static22846-10-16-GrayImageNet-94c6ff995dac583098847cfecd43e7b6.zip\"), # pretraining (mouse 4)\n",
    "            os.path.join(DATA_PATH, \"static23343-5-17-GrayImageNet-94c6ff995dac583098847cfecd43e7b6.zip\"), # pretraining (mouse 5)\n",
    "            os.path.join(DATA_PATH, \"static23656-14-22-GrayImageNet-94c6ff995dac583098847cfecd43e7b6.zip\"), # pretraining (mouse 6)\n",
    "            os.path.join(DATA_PATH, \"static23964-4-22-GrayImageNet-94c6ff995dac583098847cfecd43e7b6.zip\"), # pretraining (mouse 7)\n",
    "        ],\n",
    "        \"normalize\": True,\n",
    "        \"scale\": 0.25, # 256x144 -> 64x36\n",
    "        \"include_behavior\": False,\n",
    "        \"add_behavior_as_channels\": False,\n",
    "        \"include_eye_position\": True,\n",
    "        \"exclude\": None,\n",
    "        \"file_tree\": True,\n",
    "        \"cuda\": \"cuda\" in config[\"device\"],\n",
    "        \"batch_size\": 7,\n",
    "        \"seed\": config[\"seed\"],\n",
    "        \"use_cache\": False,\n",
    "    },\n",
    "    \"skip_train\": False,\n",
    "    \"skip_val\": False,\n",
    "    \"skip_test\": False,\n",
    "    \"normalize_neuron_coords\": True,\n",
    "    \"average_test_multitrial\": True,\n",
    "    \"save_test_multitrial\": True,\n",
    "    \"test_batch_size\": 7,\n",
    "    \"device\": config[\"device\"],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### get dataloaders and cell coordinates\n",
    "dataloaders, neuron_coords = get_mouse_v1_data(config[\"data\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### show data\n",
    "sample_data_key = dataloaders[\"mouse_v1\"][\"test\"].data_keys[0]\n",
    "datapoint = next(iter(dataloaders[\"mouse_v1\"][\"test\"].dataloaders[0]))\n",
    "stim, resp = datapoint.images, datapoint.responses\n",
    "pupil_center = datapoint.pupil_center\n",
    "print(\n",
    "    f\"Training dataset:\\t {sum(len(dl) * dl.batch_size for dl in dataloaders['mouse_v1']['train'].dataloaders)} samples\"\n",
    "    f\"\\nValidation dataset:\\t {sum(len(dl) * dl.batch_size for dl in dataloaders['mouse_v1']['val'].dataloaders)} samples\"\n",
    "    f\"\\nTest dataset:\\t\\t {sum(len(dl) * dl.batch_size for dl in dataloaders['mouse_v1']['test'].dataloaders)} samples\"\n",
    "    f\"\\nTest (no resp) dataset:\\t {sum(len(dl) * dl.batch_size for dl in dataloaders['mouse_v1']['test_no_resp'].dataloaders)} samples\"\n",
    "\n",
    "    \"\\n\\nstimuli:\"\n",
    "    f\"\\n  {stim.shape}\"\n",
    "    f\"\\n  min={stim.min().item():.3f}  max={stim.max().item():.3f}\"\n",
    "    f\"\\n  mean={stim.mean().item():.3f}  std={stim.std().item():.3f}\"\n",
    "    \"\\nresponses:\"\n",
    "    f\"\\n  {resp.shape}\"\n",
    "    f\"\\n  min={resp.min().item():.3f}  max={resp.max().item():.3f}\"\n",
    "    f\"\\n  mean={resp.mean().item():.3f}  std={resp.std().item():.3f}\"\n",
    "    \"\\nneuronal coordinates:\"\n",
    "    f\"\\n  {neuron_coords[sample_data_key].shape}\"\n",
    "    f\"\\n  min={neuron_coords[sample_data_key].min():.3f}  max={neuron_coords[sample_data_key].max():.3f}\"\n",
    "    f\"\\n  mean={neuron_coords[sample_data_key].mean():.3f}  std={neuron_coords[sample_data_key].std():.3f}\"\n",
    ")\n",
    "\n",
    "### plot sample data\n",
    "sample_idx = 0\n",
    "\n",
    "fig = plt.figure(figsize=(16, 6))\n",
    "ax = fig.add_subplot(131)\n",
    "ax.imshow(stim[sample_idx].squeeze().unsqueeze(-1).cpu(), cmap=\"gray\")\n",
    "\n",
    "ax = fig.add_subplot(132)\n",
    "ax.imshow(crop(stim[sample_idx].cpu(), config[\"crop_win\"]).squeeze().unsqueeze(-1), cmap=\"gray\")\n",
    "\n",
    "### bin the neuronal responses based on their neuron coordinates and sum within each bin -> 2D grid of vals\n",
    "coords = neuron_coords[sample_data_key]\n",
    "H, W = stim.shape[-2:] # the size of the grid\n",
    "n_x_bins, n_y_bins = 32, 18 # number of bins in each dimension\n",
    "min_x, max_x, min_y, max_y = coords[:,0].min().item(), coords[:,0].max().item(), coords[:,1].min().item(), coords[:,1].max().item()\n",
    "x_bins = torch.linspace(min_x, max_x, n_x_bins + 1)\n",
    "y_bins = torch.linspace(min_y, max_y, n_y_bins + 1)\n",
    "binned_resp = torch.zeros(n_y_bins, n_x_bins)\n",
    "for i in range(n_y_bins):\n",
    "    for j in range(n_x_bins):\n",
    "        ### mask of the neurons in the bin\n",
    "        mask = (x_bins[j] <= coords[:,0]) &\\\n",
    "               (coords[:,0] < x_bins[j + 1]) &\\\n",
    "               (y_bins[i] <= coords[:,1]) &\\\n",
    "               (coords[:,1] < y_bins[i + 1])\n",
    "        binned_resp[i,j] = resp[sample_idx, mask.cpu()].sum(0)\n",
    "ax = fig.add_subplot(133)\n",
    "ax.imshow(binned_resp.squeeze().cpu(), cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Synthetic dataset (different image stimuli -> encoder -> responses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### append synthetic data\n",
    "config[\"data\"][\"syn_dataset_config\"] = {\n",
    "    \"data_keys\": [\n",
    "        \"21067-10-18\",\n",
    "        \"22846-10-16\",\n",
    "        \"23343-5-17\",\n",
    "        \"23656-14-22\",\n",
    "        \"23964-4-22\",\n",
    "    ],\n",
    "    \"batch_size\": 7,\n",
    "    \"append_data_parts\": [\"train\"],\n",
    "    # \"data_key_prefix\": \"syn\",\n",
    "    \"data_key_prefix\": None, # the same data key as the original (real) data\n",
    "    \"dir_name\": \"synthetic_data_mouse_v1_encoder_new_stimuli\",\n",
    "    \"device\": config[\"device\"],\n",
    "}\n",
    "\n",
    "dataloaders = append_syn_dataloaders(dataloaders, config=config[\"data\"][\"syn_dataset_config\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### show data\n",
    "syn_stim, syn_resp, syn_pupil_center = next(iter(dataloaders[\"mouse_v1\"][\"train\"].dataloaders[-1]))\n",
    "syn_sample_data_key = dataloaders[\"mouse_v1\"][\"train\"].data_keys[-1]\n",
    "print(\n",
    "    f\"Training dataset:\\t {sum(len(dl) * dl.batch_size for dl in dataloaders['mouse_v1']['train'].dataloaders)} samples\"\n",
    "    f\"\\nValidation dataset:\\t {sum(len(dl) * dl.batch_size for dl in dataloaders['mouse_v1']['val'].dataloaders)} samples\"\n",
    "    f\"\\nTest dataset:\\t\\t {sum(len(dl) * dl.batch_size for dl in dataloaders['mouse_v1']['test'].dataloaders)} samples\"\n",
    "    f\"\\nTest (no resp) dataset:\\t {sum(len(dl) * dl.batch_size for dl in dataloaders['mouse_v1']['test_no_resp'].dataloaders)} samples\"\n",
    "\n",
    "    \"\\n\\nstimuli:\"\n",
    "    f\"\\n  {syn_stim.shape}\"\n",
    "    f\"\\n  min={syn_stim.min().item():.3f}  max={syn_stim.max().item():.3f}\"\n",
    "    f\"\\n  mean={syn_stim.mean().item():.3f}  std={syn_stim.std().item():.3f}\"\n",
    "    \"\\nresponses:\"\n",
    "    f\"\\n  {syn_resp.shape}\"\n",
    "    f\"\\n  min={syn_resp.min().item():.3f}  max={syn_resp.max().item():.3f}\"\n",
    "    f\"\\n  mean={syn_resp.mean().item():.3f}  std={syn_resp.std().item():.3f}\"\n",
    "    \"\\nNeuron coordinates:\"\n",
    "    f\"\\n  {neuron_coords[syn_sample_data_key].shape}\"\n",
    "    f\"\\n  min={neuron_coords[syn_sample_data_key].min():.3f}  max={neuron_coords[syn_sample_data_key].max():.3f}\"\n",
    "    f\"\\n  mean={neuron_coords[syn_sample_data_key].mean():.3f}  std={neuron_coords[syn_sample_data_key].std():.3f}\"\n",
    "    \"\\nPupil center:\"\n",
    "    f\"\\n  {syn_pupil_center.shape}\"\n",
    "    f\"\\n  min={syn_pupil_center.min().item():.3f}  max={syn_pupil_center.max().item():.3f}\"\n",
    "    f\"\\n  mean={syn_pupil_center.mean().item():.3f}  std={syn_pupil_center.std().item():.3f}\"\n",
    ")\n",
    "\n",
    "### plot sample data\n",
    "sample_idx = 0\n",
    "\n",
    "fig = plt.figure(figsize=(16, 6))\n",
    "ax = fig.add_subplot(131)\n",
    "ax.imshow(syn_stim[sample_idx].squeeze().unsqueeze(-1).cpu(), cmap=\"gray\")\n",
    "\n",
    "ax = fig.add_subplot(132)\n",
    "ax.imshow(crop(syn_stim[sample_idx].cpu(), config[\"crop_win\"]).squeeze().unsqueeze(-1), cmap=\"gray\")\n",
    "\n",
    "### bin the neuronal responses based on their neuron coordinates and sum within each bin -> 2D grid of vals\n",
    "coords = neuron_coords[syn_sample_data_key]\n",
    "H, W = syn_stim.shape[-2:] # the size of the grid\n",
    "n_x_bins, n_y_bins = 32, 18 # number of bins in each dimension\n",
    "min_x, max_x, min_y, max_y = coords[:,0].min().item(), coords[:,0].max().item(), coords[:,1].min().item(), coords[:,1].max().item()\n",
    "x_bins = torch.linspace(min_x, max_x, n_x_bins + 1)\n",
    "y_bins = torch.linspace(min_y, max_y, n_y_bins + 1)\n",
    "binned_resp = torch.zeros(n_y_bins, n_x_bins)\n",
    "for i in range(n_x_bins):\n",
    "    for j in range(n_y_bins):\n",
    "        ### mask of the neurons in the bin\n",
    "        mask = (x_bins[i] <= coords[:,0]) &\\\n",
    "               (coords[:,0] < x_bins[i + 1]) &\\\n",
    "               (y_bins[j] <= coords[:,1]) &\\\n",
    "               (coords[:,1] < y_bins[j + 1])\n",
    "        binned_resp[j,i] = syn_resp[sample_idx, mask.cpu()].sum(0)\n",
    "ax = fig.add_subplot(133)\n",
    "ax.imshow(binned_resp.squeeze().cpu(), cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config[\"data\"][\"data_augmentation\"] = {\n",
    "    \"data_transforms\": [[  # for synthetic data\n",
    "        RespGaussianNoise(\n",
    "            noise_std=2 * torch.from_numpy(np.load(os.path.join(DATA_PATH, dataset.dirname, \"stats\", f\"responses_iqr.npy\"))).float().to(config[\"device\"]),\n",
    "            clip_min=0.0,\n",
    "            # dynamic_mul_factor=0.05,\n",
    "            # resp_fn=\"squared\",\n",
    "        ) for dataset in dataloaders[\"mouse_v1\"][\"train\"].datasets\n",
    "    ]],\n",
    "    \"append_data_parts\": [\"train\"],\n",
    "    \"force_same_order\": True,\n",
    "    \"seed\": config[\"seed\"],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloaders = append_data_aug_dataloaders(\n",
    "    dataloaders=dataloaders,\n",
    "    config=config[\"data\"][\"data_augmentation\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for b in dataloaders[\"mouse_v1\"][\"train\"]:\n",
    "    break\n",
    "dataloaders[\"mouse_v1\"][\"train\"].dataloaders, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### show data\n",
    "aug_sample_data_key = dataloaders[\"mouse_v1\"][\"train\"].data_keys[-1]\n",
    "aug_datapoint = next(iter(dataloaders[\"mouse_v1\"][\"train\"].dataloaders[-1]))\n",
    "aug_stim, aug_resp = aug_datapoint.images, aug_datapoint.responses\n",
    "aug_pupil_center = aug_datapoint.pupil_center\n",
    "\n",
    "no_aug_datapoint = next(iter(dataloaders[\"mouse_v1\"][\"train\"].dataloaders[len(dataloaders[\"mouse_v1\"][\"train\"].dataloaders) // 2 - 1]))\n",
    "no_aug_resp = no_aug_datapoint.responses\n",
    "\n",
    "### plot sample data\n",
    "sample_idx = 0\n",
    "\n",
    "fig = plt.figure(figsize=(20, 6))\n",
    "ax = fig.add_subplot(141)\n",
    "ax.imshow(aug_stim[sample_idx].squeeze().unsqueeze(-1).cpu(), cmap=\"gray\")\n",
    "\n",
    "ax = fig.add_subplot(142)\n",
    "ax.imshow(crop(aug_stim[sample_idx].cpu(), config[\"crop_win\"]).squeeze().unsqueeze(-1), cmap=\"gray\")\n",
    "\n",
    "### no_aug_resp: bin the neuronal responses based on their neuron coordinates and sum within each bin -> 2D grid of vals\n",
    "coords = neuron_coords[aug_sample_data_key]\n",
    "H, W = aug_stim.shape[-2:] # the size of the grid\n",
    "n_x_bins, n_y_bins = 32, 18 # number of bins in each dimension\n",
    "min_x, max_x, min_y, max_y = coords[:,0].min().item(), coords[:,0].max().item(), coords[:,1].min().item(), coords[:,1].max().item()\n",
    "x_bins = torch.linspace(min_x, max_x, n_x_bins + 1)\n",
    "y_bins = torch.linspace(min_y, max_y, n_y_bins + 1)\n",
    "binned_resp = torch.zeros(n_y_bins, n_x_bins)\n",
    "for i in range(n_y_bins):\n",
    "    for j in range(n_x_bins):\n",
    "        ### mask of the neurons in the bin\n",
    "        mask = (x_bins[j] <= coords[:,0]) &\\\n",
    "               (coords[:,0] < x_bins[j + 1]) &\\\n",
    "               (y_bins[i] <= coords[:,1]) &\\\n",
    "               (coords[:,1] < y_bins[i + 1])\n",
    "        binned_resp[i,j] = no_aug_resp[sample_idx, mask.cpu()].sum(0)\n",
    "ax = fig.add_subplot(143)\n",
    "ax.set_title(\"Responses before augmentation\")\n",
    "ax.imshow(binned_resp.squeeze().cpu(), cmap=\"gray\")\n",
    "\n",
    "### aug_resp: bin the neuronal responses based on their neuron coordinates and sum within each bin -> 2D grid of vals\n",
    "coords = neuron_coords[aug_sample_data_key]\n",
    "H, W = aug_stim.shape[-2:] # the size of the grid\n",
    "n_x_bins, n_y_bins = 32, 18 # number of bins in each dimension\n",
    "min_x, max_x, min_y, max_y = coords[:,0].min().item(), coords[:,0].max().item(), coords[:,1].min().item(), coords[:,1].max().item()\n",
    "x_bins = torch.linspace(min_x, max_x, n_x_bins + 1)\n",
    "y_bins = torch.linspace(min_y, max_y, n_y_bins + 1)\n",
    "binned_resp = torch.zeros(n_y_bins, n_x_bins)\n",
    "for i in range(n_y_bins):\n",
    "    for j in range(n_x_bins):\n",
    "        ### mask of the neurons in the bin\n",
    "        mask = (x_bins[j] <= coords[:,0]) &\\\n",
    "               (coords[:,0] < x_bins[j + 1]) &\\\n",
    "               (y_bins[i] <= coords[:,1]) &\\\n",
    "               (coords[:,1] < y_bins[i + 1])\n",
    "        binned_resp[i,j] = aug_resp[sample_idx, mask.cpu()].sum(0)\n",
    "ax = fig.add_subplot(144)\n",
    "ax.set_title(\"Responses after augmentation\")\n",
    "ax.imshow(binned_resp.squeeze().cpu(), cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = get_encoder(\n",
    "    ckpt_path=os.path.join(DATA_PATH, \"models\", \"encoder_sens22.pth\"),\n",
    "    device=config[\"device\"],\n",
    "    eval_mode=True,\n",
    "    # ckpt_path=os.path.join(DATA_PATH, \"models\", \"encoder_sens22_no_shifter.pth\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config[\"decoder\"] = {\n",
    "    \"model\": {\n",
    "        \"readins_config\": [\n",
    "            {\n",
    "                \"data_key\": data_key,\n",
    "                \"in_shape\": n_coords.shape[-2],\n",
    "                \"decoding_objective_config\": None,\n",
    "                # \"decoding_objective_config\": {\n",
    "                #     \"decoder_cls\": FCReadIn,\n",
    "                #     \"decoder_config\": {\n",
    "                #         \"in_shape\": 68*9*16,\n",
    "                #         \"layers_config\": [(\"fc\", 264), (\"fc\", d.n_neurons),],\n",
    "                #         \"act_fn\": nn.LeakyReLU,\n",
    "                #         \"out_act_fn\": nn.Identity,\n",
    "                #         \"dropout\": 0.0,\n",
    "                #         \"batch_norm\": False,\n",
    "                #     },\n",
    "                #     \"loss_fn\": nn.MSELoss(),\n",
    "                # },\n",
    "                \"layers\": [\n",
    "                    # (\"fc\", 432),\n",
    "                    # (\"unflatten\", 1, (3, 9, 16)),\n",
    "\n",
    "                    # (LocalizedFCReadIn, {\n",
    "                    #     \"in_shape\": d.n_neurons,\n",
    "                    #     \"layers\": [\n",
    "                    #         {\"n_bins\": 20, \"reduce_by\": 3},\n",
    "                    #         {\"n_bins\": 12, \"reduce_by\": 2},\n",
    "                    #         {\"n_bins\": 7, \"reduce_by\": 2},\n",
    "                    #         {\"n_bins\": 2, \"reduce_by\": 2},\n",
    "                    #     ],\n",
    "                    #     \"out_config\": {\n",
    "                    #         \"shape\": (3, 9, 16),\n",
    "                    #         \"method\": \"linear\",\n",
    "                    #     },\n",
    "                    #     \"act_fn\": nn.LeakyReLU,\n",
    "                    #     \"out_act_fn\": nn.Identity,\n",
    "                    #     \"dropout\": 0.15,\n",
    "                    #     \"batch_norm\": True,\n",
    "                    # }),\n",
    "\n",
    "                    # (AttentionReadIn, {\n",
    "                    #     \"in_shape\": d.n_neurons,\n",
    "                    #     \"shift_coords\": True,\n",
    "                    #     \"shifter_net_layers\": [\n",
    "                    #         (\"fc\", 10),\n",
    "                    #         (\"fc\", 10),\n",
    "                    #         (\"fc\", 2),\n",
    "                    #     ],\n",
    "                    #     \"shifter_net_act_fn\": nn.LeakyReLU,\n",
    "                    #     \"shifter_net_out_act_fn\": nn.Tanh,\n",
    "                    #     \"attn_config\": {\n",
    "                    #         \"layers\": 1,\n",
    "                    #         \"token_neurons\": 20,\n",
    "                    #         \"dim_head\": 256,\n",
    "                    #         \"dropout\": 0.1,\n",
    "                    #         \"attn_num_heads\": 1,\n",
    "                    #     },\n",
    "                    #     \"attn_interleave_config\": {\n",
    "                    #         \"layers\": [\n",
    "                    #             (\"fc\", 512),\n",
    "                    #             (\"act_fn\", nn.ReLU),\n",
    "                    #             (\"dropout\", 0.15),\n",
    "                    #             (\"fc\", 256)\n",
    "                    #         ],\n",
    "                    #         \"after_last\": True,\n",
    "                    #     },\n",
    "                    #     \"neuron_embed_dim\": 16,\n",
    "                    #     \"conv_out_config\": {\n",
    "                    #         \"out_channels\": 64,\n",
    "                    #         \"kernel_size\": 5,\n",
    "                    #         \"stride\": 1,\n",
    "                    #         \"padding\": 2,\n",
    "                    #         \"bias\": False,\n",
    "                    #         \"batch_norm\": True,\n",
    "                    #         \"act_fn\": nn.LeakyReLU,\n",
    "                    #     },\n",
    "                    # }),\n",
    "\n",
    "                    (ConvReadIn, {\n",
    "                        \"shift_coords\": False,\n",
    "                        \"learn_grid\": True,\n",
    "                        \"grid_l1_reg\": 8e-3,\n",
    "                        \"in_channels_group_size\": 1,\n",
    "                        # \"grid_net_config\": {\n",
    "                        #     \"in_channels\": 32, # x, y, z, resp\n",
    "                        #     \"layers_config\": [(\"fc\", 64), (\"fc\", 64), (\"fc\", 16*9)],\n",
    "                        #     \"act_fn\": nn.LeakyReLU,\n",
    "                        #     \"out_act_fn\": nn.Identity,\n",
    "                        #     \"dropout\": 0.1,\n",
    "                        #     \"batch_norm\": False,\n",
    "                        # },\n",
    "                        \"pointwise_conv_config\": {\n",
    "                            \"in_channels\": n_coords.shape[-2],\n",
    "                            \"out_channels\": 256,\n",
    "                            \"act_fn\": nn.LeakyReLU,\n",
    "                            \"bias\": False,\n",
    "                            \"batch_norm\": True,\n",
    "                            # \"dropout\": 0.15,\n",
    "                        },\n",
    "                        \"gauss_blur\": False,\n",
    "                        \"gauss_blur_kernel_size\": 7,\n",
    "                        \"gauss_blur_sigma\": \"fixed\", # \"fixed\", \"single\", \"per_neuron\"\n",
    "                        # \"gauss_blur_sigma\": \"per_neuron\", # \"fixed\", \"single\", \"per_neuron\"\n",
    "                        \"gauss_blur_sigma_init\": 1.5,\n",
    "                        \"neuron_emb_dim\": None,\n",
    "                    }),\n",
    "\n",
    "                    # (MEIReadIn, {\n",
    "                    #     \"meis_path\": os.path.join(DATA_PATH, \"meis\", data_key,  \"meis.pt\"),\n",
    "                    #     \"n_neurons\": n_coords.shape[-2],\n",
    "                    #     \"mei_resize_method\": \"resize\",\n",
    "                    #     \"mei_target_shape\": (22, 36),\n",
    "                    #     \"pointwise_conv_config\": {\n",
    "                    #         \"out_channels\": 256,\n",
    "                    #         \"bias\": False,\n",
    "                    #         \"batch_norm\": True,\n",
    "                    #         \"act_fn\": nn.Identity,\n",
    "                    #     },\n",
    "                    #     \"ctx_net_config\": {\n",
    "                    #         \"in_channels\": 3, # resp, x, y\n",
    "                    #         \"layers_config\": [(\"fc\", 32), (\"fc\", 128), (\"fc\", 22*36)],\n",
    "                    #         \"act_fn\": nn.LeakyReLU,\n",
    "                    #         \"out_act_fn\": nn.Identity,\n",
    "                    #         \"dropout\": 0.1,\n",
    "                    #         \"batch_norm\": True,\n",
    "                    #     },\n",
    "                    #     \"shift_coords\": False,\n",
    "                    #     \"device\": config[\"device\"],\n",
    "                    # }),\n",
    "\n",
    "                    # (FCReadIn, {\n",
    "                    #     \"in_shape\": n_coords.shape[-2],\n",
    "                    #     \"layers_config\": [\n",
    "                    #         (\"fc\", 432),\n",
    "                    #         (\"unflatten\", 1, (3, 9, 16)),\n",
    "                    #     ],\n",
    "                    #     # \"act_fn\": nn.LeakyReLU,\n",
    "                    #     \"act_fn\": nn.GELU,\n",
    "                    #     \"out_act_fn\": nn.Identity,\n",
    "                    #     # \"batch_norm\": True,\n",
    "                    #     \"batch_norm\": False,\n",
    "                    #     \"layer_norm\": True,\n",
    "                    #     # \"dropout\": 0.3,\n",
    "                    #     \"dropout\": 0.3,\n",
    "                    #     \"l2_reg_mul\": 1e-3,\n",
    "                    #     \"out_channels\": 3,\n",
    "                    # }),\n",
    "\n",
    "                    # (AutoEncoderReadIn, {\n",
    "                    #     \"loss_mul\": 1,\n",
    "                    #     \"encoder_config\": {\n",
    "                    #         \"in_shape\": d.n_neurons,\n",
    "                    #         \"layers_config\": [\n",
    "                    #             (\"fc\", 288),\n",
    "                    #             (\"unflatten\", 1, (2, 9, 16)),\n",
    "                    #         ],\n",
    "                    #         \"act_fn\": nn.LeakyReLU,\n",
    "                    #         \"out_act_fn\": nn.Identity,\n",
    "                    #         \"batch_norm\": True,\n",
    "                    #         \"dropout\": 0.2,\n",
    "                    #         \"out_channels\": 2,\n",
    "                    #     },\n",
    "                    #     \"decoder_config\": {\n",
    "                    #         \"layers_config\": [\n",
    "                    #             (\"fc\", 312),\n",
    "                    #             (\"fc\", d.n_neurons),\n",
    "                    #         ],\n",
    "                    #         \"act_fn\": nn.LeakyReLU,\n",
    "                    #         \"out_act_fn\": nn.Identity,\n",
    "                    #         \"batch_norm\": False,\n",
    "                    #         \"dropout\": 0.1,\n",
    "                    #     },\n",
    "                    # }),\n",
    "\n",
    "                    # (Conv1dReadIn, {\n",
    "                    #     # \"in_shape\": d.n_neurons,\n",
    "                    #     \"in_shape\": 1,\n",
    "                    #     \"out_channels\": 2,\n",
    "                    #     \"layers_config\": [\n",
    "                    #         (\"conv1d\", 64, 7, 3, 3),\n",
    "                    #         (\"conv1d\", 32, 7, 3, 3),\n",
    "                    #         (\"conv1d\", 16, 5, 2, 2),\n",
    "                    #         (\"conv1d\", 8, 4, 2, 1),\n",
    "                    #         (\"flatten\", 1, -1, 1632),\n",
    "                    #         (\"fc\", 288),\n",
    "                    #         (\"unflatten\", 1, (2, 9, 16)),\n",
    "                    #     ],\n",
    "                    #     \"act_fn\": nn.ReLU,\n",
    "                    #     \"out_act_fn\": nn.Identity,\n",
    "                    #     \"batch_norm\": True,\n",
    "                    #     \"dropout\": 0.15,\n",
    "                    # }),\n",
    "\n",
    "                    # (HypernetReadIn, {\n",
    "                    #     \"n_neurons\": d.n_neurons,\n",
    "                    #     \"hypernet_layers\": [\n",
    "                    #         # (\"fc\", 40),\n",
    "                    #         (\"fc\", 64),\n",
    "                    #         (\"fc\", 64),\n",
    "                    #         (\"fc\", 1152),\n",
    "                    #     ],\n",
    "                    #     \"hypernet_act_fn\": nn.LeakyReLU,\n",
    "                    #     # \"hypernet_act_fn\": nn.Tanh,\n",
    "                    #     \"hypernet_out_act_fn\": nn.Identity,\n",
    "                    #     \"hypernet_dropout\": 0.,\n",
    "                    #     \"hypernet_batch_norm\": False,\n",
    "                    #     \"hypernet_init\": \"normal\",\n",
    "                    #     \"hypernet_init_kwargs\": {\n",
    "                    #         \"mean\": 0,\n",
    "                    #         \"std\": 1/(d.n_neurons*1152),\n",
    "                    #     },\n",
    "                    #     \"hypernet_neuron_embed_dim\": 32,\n",
    "                    #     \"target_in_shape\": d.n_neurons,\n",
    "                    #     \"target_layers\": [\n",
    "                    #         (\"fc\", 1152),\n",
    "                    #         (\"unflatten\", 1, (8, 9, 16)),\n",
    "                    #     ],\n",
    "                    #     # \"target_act_fn\": nn.LeakyReLU,\n",
    "                    #     \"target_act_fn\": nn.Identity,\n",
    "                    #     \"target_out_act_fn\": nn.Identity,\n",
    "                    #     \"target_dropout\": 0.15,\n",
    "                    #     \"target_out_layer_norm\": True,\n",
    "                    #     \"shift_coords\": True,\n",
    "                    #     \"shifter_net_layers\": [\n",
    "                    #         (\"fc\", 10),\n",
    "                    #         (\"fc\", 10),\n",
    "                    #         (\"fc\", 2),\n",
    "                    #     ],\n",
    "                    #     \"shifter_net_act_fn\": nn.LeakyReLU,\n",
    "                    #     \"shifter_net_out_act_fn\": nn.Tanh,\n",
    "                    # }),\n",
    "\n",
    "                ],\n",
    "            } for data_key, n_coords in dataloaders[\"mouse_v1\"][\"train\"].neuron_coords.items()\n",
    "        ],\n",
    "        \"core_cls\": CNN_Decoder,\n",
    "        \"core_config\": {\n",
    "            \"resp_shape\": [256],\n",
    "            \"stim_shape\": list(stim.shape[1:]),\n",
    "            \"layers\": [\n",
    "                ### for conv_readin\n",
    "                # (\"deconv\", 256, 5, 2, 2),\n",
    "                (\"deconv\", 256, 7, 2, 2),\n",
    "                # (\"deconv\", 128, 7, 2, 1),\n",
    "                # (\"deconv\", 64, 5, 2, 2),\n",
    "                \n",
    "                (\"deconv\", 128, 5, 1, 2),\n",
    "                # (\"deconv\", 64, 5, 1, 1),\n",
    "\n",
    "                # (\"deconv\", 64, 4, 1, 1),\n",
    "                (\"deconv\", 64, 5, 1, 2),\n",
    "                # (\"deconv\", 32, 4, 1, 1),\n",
    "\n",
    "                # (\"deconv\", 64, 3, 1, 1),\n",
    "                (\"deconv\", 64, 4, 1, 1),\n",
    "                # (\"deconv\", 32, 4, 1, 1),\n",
    "\n",
    "                # (\"deconv\", 64, 4, 1, 1),\n",
    "                # (\"deconv\", 64, 3, 1, 1),\n",
    "                (\"deconv\", 32, 3, 1, 1),\n",
    "\n",
    "                (\"deconv\", 1, 3, 1, 0),\n",
    "\n",
    "                # ### for MEIReadin\n",
    "                # (\"conv\", 256, 7, 1, 3),\n",
    "                # (\"conv\", 128, 5, 1, 2),\n",
    "                # (\"conv\", 64, 3, 1, 1),\n",
    "                # (\"conv\", 64, 3, 1, 1),\n",
    "                # (\"conv\", 1, 3, 1, 1),\n",
    "\n",
    "                ### for attn_readin\n",
    "                # (\"deconv\", 64, 7, 2, 3),\n",
    "                # (\"deconv\", 32, 4, 1, 2),\n",
    "                # (\"deconv\", 1, 3, 1, 0),\n",
    "            ],\n",
    "            \"act_fn\": nn.ReLU,\n",
    "            \"out_act_fn\": nn.Identity,\n",
    "            \"dropout\": 0.3,\n",
    "            \"batch_norm\": True,\n",
    "        },\n",
    "    },\n",
    "    \"opter_cls\": torch.optim.Adam,\n",
    "    \"opter_kwargs\": {\n",
    "        \"lr\": 3e-4,\n",
    "        # \"weight_decay\": 1e-3,\n",
    "    },\n",
    "    \"loss\": {\n",
    "        # \"loss_fn\": CroppedLoss(window=config[\"crop_win\"], loss_fn=nn.MSELoss(), normalize=False, standardize=False),\n",
    "        # \"loss_fn\": MultiSSIMLoss(\n",
    "        \"loss_fn\": SSIMLoss(\n",
    "            window=config[\"crop_win\"],\n",
    "            log_loss=True,\n",
    "            inp_normalized=True,\n",
    "            inp_standardized=False,\n",
    "        ),\n",
    "        \"l1_reg_mul\": 0,\n",
    "        \"l2_reg_mul\": 1e-5,\n",
    "        \"con_reg_mul\": 0,\n",
    "        # \"con_reg_mul\": 1,\n",
    "        # \"con_reg_loss_fn\": MultiSSIMLoss(\n",
    "        \"con_reg_loss_fn\": SSIMLoss(\n",
    "            window=config[\"crop_win\"],\n",
    "            log_loss=True,\n",
    "            inp_normalized=True,\n",
    "            inp_standardized=False,\n",
    "        ),\n",
    "        # \"con_reg_loss_fn\": CroppedLoss(window=config[\"crop_win\"], loss_fn=nn.MSELoss(), normalize=False, standardize=False),\n",
    "        \"encoder\": None,\n",
    "        # \"encoder\": get_encoder(\n",
    "        #     ckpt_path=os.path.join(DATA_PATH, \"models\", \"encoder_sens22.pth\"),\n",
    "        #     device=config[\"device\"],\n",
    "        #     eval_mode=True,\n",
    "        #     # ckpt_path=os.path.join(DATA_PATH, \"models\", \"encoder_sens22_no_shifter.pth\"),\n",
    "        # ),\n",
    "    },\n",
    "    \"n_epochs\": 200,\n",
    "    \"load_ckpt\": None,\n",
    "    # \"load_ckpt\": {\n",
    "    #     \"load_only_core\": False,\n",
    "    #     # \"load_only_core\": True,\n",
    "    #     \"ckpt_path\": os.path.join(\n",
    "    #         # DATA_PATH, \"models\", \"cat_v1_pretraining\", \"2024-02-27_19-17-39\", \"decoder.pt\"),\n",
    "    #         DATA_PATH, \"models\", \"cnn\", \"2024-03-20_17-51-50\", \"ckpt\", \"decoder_55.pt\"),\n",
    "    #     \"resume_checkpointing\": True,\n",
    "    #     \"resume_wandb_id\": \"ufhjka2b\"\n",
    "    # },\n",
    "    \"save_run\": True,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### initialize (and load ckpt if needed)\n",
    "if config[\"decoder\"][\"load_ckpt\"] != None:\n",
    "    print(f\"[INFO] Loading checkpoint from {config['decoder']['load_ckpt']['ckpt_path']}...\")\n",
    "    ckpt = torch.load(config[\"decoder\"][\"load_ckpt\"][\"ckpt_path\"], map_location=config[\"device\"], pickle_module=dill)\n",
    "\n",
    "    if config[\"decoder\"][\"load_ckpt\"][\"load_only_core\"]:\n",
    "        print(\"[INFO] Loading only the core of the model (no history, no best ckpt)...\")\n",
    "\n",
    "        ### init decoder (load only the core)\n",
    "        config[\"decoder\"][\"model\"][\"core_cls\"] = ckpt[\"config\"][\"decoder\"][\"model\"][\"core_cls\"]\n",
    "        config[\"decoder\"][\"model\"][\"core_config\"] = ckpt[\"config\"][\"decoder\"][\"model\"][\"core_config\"]\n",
    "        decoder = MultiReadIn(**config[\"decoder\"][\"model\"]).to(config[\"device\"])\n",
    "        decoder.load_state_dict({k:v for k,v in ckpt[\"best\"][\"model\"].items() if \"readin\" not in k}, strict=False)\n",
    "\n",
    "        ### init the rest\n",
    "        opter = config[\"decoder\"][\"opter_cls\"](decoder.parameters(), **config[\"decoder\"][\"opter_kwargs\"])\n",
    "        loss_fn = Loss(model=decoder, config=config[\"decoder\"][\"loss\"])\n",
    "        history = {\"train_loss\": [], \"val_loss\": []}\n",
    "        best = {\"val_loss\": np.inf, \"epoch\": 0, \"model\": None}\n",
    "    else:\n",
    "        print(\"[INFO] Loading the whole model (the latest - not the BEST; with history and best ckpt)...\")\n",
    "        history, config[\"decoder\"][\"model\"], best = ckpt[\"history\"], ckpt[\"config\"][\"decoder\"][\"model\"], ckpt[\"best\"]\n",
    "\n",
    "        ### overwrite config?\n",
    "        if input(\"[WARNING] Do you want to overwrite the config with the one from the checkpoint? (y/n): \") == \"y\":\n",
    "            config = ckpt[\"config\"]\n",
    "\n",
    "        decoder = MultiReadIn(**config[\"decoder\"][\"model\"]).to(config[\"device\"])\n",
    "        decoder.load_state_dict(ckpt[\"decoder\"])\n",
    "\n",
    "        opter = config[\"decoder\"][\"opter_cls\"](decoder.parameters(), **config[\"decoder\"][\"opter_kwargs\"])\n",
    "        opter.load_state_dict(ckpt[\"opter\"])\n",
    "        loss_fn = Loss(model=decoder, config=config[\"decoder\"][\"loss\"])\n",
    "else:\n",
    "    print(\"[INFO] Initializing the model from scratch...\")\n",
    "    decoder = MultiReadIn(**config[\"decoder\"][\"model\"]).to(config[\"device\"])\n",
    "    opter = config[\"decoder\"][\"opter_cls\"](decoder.parameters(), **config[\"decoder\"][\"opter_kwargs\"])\n",
    "    loss_fn = Loss(model=decoder, config=config[\"decoder\"][\"loss\"])\n",
    "    \n",
    "    history = {\"train_loss\": [], \"val_loss\": []}\n",
    "    best = {\"val_loss\": np.inf, \"epoch\": 0, \"model\": None}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### print model and fix sizes of stimuli\n",
    "with torch.no_grad():\n",
    "    stim_pred = decoder(resp.to(config[\"device\"]), data_key=sample_data_key, neuron_coords=neuron_coords[sample_data_key], pupil_center=pupil_center.to(config[\"device\"]))\n",
    "    if stim_pred.shape != crop(stim, config[\"crop_win\"]).shape:\n",
    "        print(f\"[WARNING] Stimulus prediction shape {stim_pred.shape} does not match stimulus shape {crop(stim, config['crop_win']).shape}.\")\n",
    "        assert stim_pred.shape[-2] >= crop(stim, config[\"crop_win\"]).shape[-2] \\\n",
    "            and stim_pred.shape[-1] >= crop(stim, config[\"crop_win\"]).shape[-1]\n",
    "    print(stim_pred.shape)\n",
    "    del stim_pred\n",
    "\n",
    "print(\n",
    "    f\"Number of parameters:\"\n",
    "    f\"\\n  whole model: {count_parameters(decoder)}\"\n",
    "    f\"\\n  core: {count_parameters(decoder.core)} ({count_parameters(decoder.core) / count_parameters(decoder) * 100:.2f}%)\"\n",
    "    f\"\\n  readins: {count_parameters(decoder.readins)} ({count_parameters(decoder.readins) / count_parameters(decoder) * 100:.2f}%)\"\n",
    "    f\"\\n    ({', '.join([f'{k}: {count_parameters(v)} [{count_parameters(v) / count_parameters(decoder) * 100:.2f}%]' for k, v in decoder.readins.items()])})\"\n",
    ")\n",
    "\n",
    "decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### prepare checkpointing and wandb logging\n",
    "if config[\"decoder\"][\"load_ckpt\"] == None \\\n",
    "    or config[\"decoder\"][\"load_ckpt\"][\"resume_checkpointing\"] is False:\n",
    "    config[\"run_name\"] = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "    if config[\"decoder\"][\"save_run\"]:\n",
    "        ### save config\n",
    "        config[\"dir\"] = os.path.join(DATA_PATH, \"models\", \"cnn\", config[\"run_name\"])\n",
    "        os.makedirs(config[\"dir\"], exist_ok=True)\n",
    "        with open(os.path.join(config[\"dir\"], \"config.json\"), \"w\") as f:\n",
    "            json.dump(config, f, indent=4, default=str)\n",
    "        os.makedirs(os.path.join(config[\"dir\"], \"samples\"), exist_ok=True)\n",
    "        os.makedirs(os.path.join(config[\"dir\"], \"ckpt\"), exist_ok=True)\n",
    "        make_sample_path = lambda epoch, prefix: os.path.join(\n",
    "            config[\"dir\"], \"samples\", f\"{prefix}stim_comparison_{epoch}e.png\"\n",
    "        )\n",
    "        print(f\"Run name: {config['run_name']}\\nRun dir: {config['dir']}\")\n",
    "    else:\n",
    "        make_sample_path = lambda epoch, prefix: None\n",
    "        print(\"[WARNING] Not saving the run and the config.\")\n",
    "else:\n",
    "    config[\"run_name\"] = ckpt[\"config\"][\"run_name\"]\n",
    "    config[\"dir\"] = ckpt[\"config\"][\"dir\"]\n",
    "    make_sample_path = lambda epoch, prefix: os.path.join(\n",
    "        config[\"dir\"], \"samples\", f\"{prefix}stim_comparison_{epoch}e.png\"\n",
    "    )\n",
    "    print(f\"Checkpointing resumed - Run name: {config['run_name']}\\nRun dir: {config['dir']}\")\n",
    "\n",
    "### wandb logging\n",
    "if config[\"decoder\"][\"load_ckpt\"] == None \\\n",
    "    or config[\"decoder\"][\"load_ckpt\"][\"resume_wandb_id\"] == None:\n",
    "    if config[\"wandb\"]:\n",
    "        wdb_run = wandb.init(**config[\"wandb\"], name=config[\"run_name\"], config=config,\n",
    "            tags=[\n",
    "                config[\"decoder\"][\"model\"][\"core_cls\"].__name__,\n",
    "                config[\"decoder\"][\"model\"][\"readins_config\"][0][\"layers\"][0][0].__name__,\n",
    "            ],\n",
    "            notes=None)\n",
    "        wdb_run.watch(decoder)\n",
    "    else:\n",
    "        print(\"[WARNING] Not using wandb.\")\n",
    "else:\n",
    "    wdb_run = wandb.init(**config[\"wandb\"], name=config[\"run_name\"], config=config, id=config[\"decoder\"][\"load_ckpt\"][\"resume_wandb_id\"], resume=\"must\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### train\n",
    "s, e = len(history[\"train_loss\"]), config[\"decoder\"][\"n_epochs\"]\n",
    "for epoch in range(s, e):\n",
    "    print(f\"[{epoch + 1}/{e}]\")\n",
    "\n",
    "    ### train and val\n",
    "    dls, neuron_coords = get_all_data(config=config)\n",
    "    train_dataloader, val_dataloader = dls[\"mouse_v1\"][\"train\"], dls[\"mouse_v1\"][\"val\"]\n",
    "    train_loss = train(\n",
    "        model=decoder,\n",
    "        dataloader=train_dataloader,\n",
    "        opter=opter,\n",
    "        loss_fn=loss_fn,\n",
    "    )\n",
    "    val_losses = val(\n",
    "        model=decoder,\n",
    "        dataloader=val_dataloader,\n",
    "        loss_fn=loss_fn,\n",
    "    )\n",
    "\n",
    "    ### save best model\n",
    "    if val_losses[\"total\"] < best[\"val_loss\"]:\n",
    "        best[\"val_loss\"] = val_losses[\"total\"]\n",
    "        best[\"epoch\"] = epoch\n",
    "        best[\"model\"] = deepcopy(decoder.state_dict())\n",
    "\n",
    "    ### log\n",
    "    history[\"train_loss\"].append(train_loss)\n",
    "    history[\"val_loss\"].append(val_losses[\"total\"])\n",
    "    if config[\"wandb\"]: wdb_run.log({\"train_loss\": train_loss, \"val_loss\": val_losses[\"total\"]}, commit=False)\n",
    "    print(f\"{train_loss=:.4f}, {val_losses['total']=:.4f}\", end=\"\")\n",
    "    for data_key, loss in val_losses.items():\n",
    "        if data_key != \"total\":\n",
    "            print(f\", {data_key}: {loss:.4f}\", end=\"\")\n",
    "    print(\"\")\n",
    "\n",
    "    ### plot reconstructions\n",
    "    stim_pred = decoder(\n",
    "        resp[:8].to(config[\"device\"]),\n",
    "        data_key=sample_data_key,\n",
    "        neuron_coords=neuron_coords[sample_data_key],\n",
    "        pupil_center=pupil_center[:8].to(config[\"device\"]),\n",
    "    ).detach()\n",
    "    fig = plot_comparison(target=crop(stim[:8], config[\"crop_win\"]).cpu(), pred=crop(stim_pred[:8], config[\"crop_win\"]).cpu(), save_to=make_sample_path(epoch, \"\"))\n",
    "    if config[\"wandb\"]: wdb_run.log({\"val_stim_reconstruction\": fig})\n",
    "\n",
    "    ### plot losses\n",
    "    if epoch % 5 == 0 and epoch > 0:\n",
    "        plot_losses(history=history, epoch=epoch, save_to=os.path.join(config[\"dir\"], f\"losses_{epoch}.png\") if config[\"decoder\"][\"save_run\"] else None)\n",
    "\n",
    "    ### save ckpt\n",
    "    if epoch % 5 == 0 and epoch > 0:\n",
    "        ### ckpt\n",
    "        if config[\"decoder\"][\"save_run\"]:\n",
    "            torch.save({\n",
    "                \"decoder\": decoder.state_dict(),\n",
    "                \"opter\": opter.state_dict(),\n",
    "                \"history\": history,\n",
    "                \"config\": config,\n",
    "                \"best\": best,\n",
    "            }, os.path.join(config[\"dir\"], \"ckpt\", f\"decoder_{epoch}.pt\"), pickle_module=dill)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### final evaluation + logging + saving\n",
    "print(f\"Best val loss: {best['val_loss']:.4f} at epoch {best['epoch']}\")\n",
    "\n",
    "### save final ckpt\n",
    "if config[\"decoder\"][\"save_run\"]:\n",
    "    torch.save({\n",
    "        \"decoder\": decoder.state_dict(),\n",
    "        \"opter\": opter.state_dict(),\n",
    "        \"history\": history,\n",
    "        \"config\": config,\n",
    "        \"best\": best,\n",
    "    }, os.path.join(config[\"dir\"], f\"decoder.pt\"), pickle_module=dill)\n",
    "\n",
    "### eval on test set w/ current params\n",
    "print(\"Evaluating on test set with current model...\")\n",
    "dls, neuron_coords = get_all_data(config=config)\n",
    "test_loss_curr = val(\n",
    "    model=decoder,\n",
    "    dataloader=dls[\"mouse_v1\"][\"test\"],\n",
    "    loss_fn=loss_fn,\n",
    ")\n",
    "print(f\"  Test loss (current model): {test_loss_curr['total']:.4f}\")\n",
    "\n",
    "stim_pred_curr = decoder(\n",
    "    resp.to(config[\"device\"]),\n",
    "    data_key=sample_data_key,\n",
    "    neuron_coords=neuron_coords[sample_data_key],\n",
    "    pupil_center=pupil_center.to(config[\"device\"]),\n",
    ").detach().cpu()\n",
    "fig = plot_comparison(\n",
    "    target=crop(stim[:8], config[\"crop_win\"]).cpu(),\n",
    "    pred=crop(stim_pred_curr[:8], config[\"crop_win\"]).cpu(),\n",
    "    save_to=os.path.join(config[\"dir\"], \"stim_comparison_latest_model.png\") if config[\"decoder\"][\"save_run\"] else None,\n",
    "    pred_title=\"Reconstructed (latest model)\"\n",
    ")\n",
    "\n",
    "\n",
    "### load best model\n",
    "decoder.load_state_dict(best[\"model\"])\n",
    "\n",
    "### eval on test set w/ best params\n",
    "print(\"Evaluating on test set with best model...\")\n",
    "dls, neuron_coords = get_all_data(config=config)\n",
    "test_loss_final = val(\n",
    "    model=decoder,\n",
    "    dataloader=dls[\"mouse_v1\"][\"test\"],\n",
    "    loss_fn=loss_fn,\n",
    ")\n",
    "print(f\"  Test loss (best model): {test_loss_final['total']:.4f}\")\n",
    "\n",
    "### plot reconstructions of the final model\n",
    "stim_pred_best = decoder(\n",
    "    resp.to(config[\"device\"]),\n",
    "    data_key=sample_data_key,\n",
    "    neuron_coords=neuron_coords[sample_data_key],\n",
    "    pupil_center=pupil_center.to(config[\"device\"]),\n",
    ").detach().cpu()\n",
    "fig = plot_comparison(\n",
    "    target=crop(stim[:8], config[\"crop_win\"]).cpu(),\n",
    "    pred=crop(stim_pred_best[:8], config[\"crop_win\"]).cpu(),\n",
    "    save_to=os.path.join(config[\"dir\"], \"stim_comparison_best.png\") if config[\"decoder\"][\"save_run\"] else None,\n",
    ")\n",
    "\n",
    "### log\n",
    "if config[\"wandb\"]:\n",
    "    wandb.run.summary[\"best_val_loss\"] = best[\"val_loss\"]\n",
    "    wandb.run.summary[\"best_epoch\"] = best[\"epoch\"]\n",
    "    wandb.run.summary[\"curr_test_loss\"] = test_loss_curr[\"total\"]\n",
    "    wandb.run.summary[\"final_test_loss\"] = test_loss_final[\"total\"]\n",
    "    wandb.run.summary[\"best_reconstruction\"] = fig\n",
    "\n",
    "### save/delete wandb run\n",
    "if config[\"wandb\"]:\n",
    "    if input(\"Delete run with 'd', save with anything else: \") == \"d\":\n",
    "        print(\"Deleting wandb run...\")\n",
    "        api = wandb.Api()\n",
    "        run = api.run(f\"johnny1188/{config['wandb']['project']}/{wdb_run.id}\")\n",
    "        run.delete()\n",
    "    else:\n",
    "        wdb_run.finish()\n",
    "\n",
    "### plot losses\n",
    "plot_losses(\n",
    "    history=history,\n",
    "    save_to=None if not config[\"decoder\"][\"save_run\"] else os.path.join(config[\"dir\"], f\"losses.png\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### show training reconstructions\n",
    "datapoint_training = next(iter(dls[\"mouse_v1\"][\"train\"].dataloaders[0]))\n",
    "stim_training, resp_training, pupil_center_training = datapoint_training.images, datapoint_training.responses, datapoint_training.pupil_center\n",
    "stim_training_pred_best = decoder(\n",
    "    resp_training.to(config[\"device\"]),\n",
    "    data_key=sample_data_key,\n",
    "    neuron_coords=neuron_coords[sample_data_key],\n",
    "    pupil_center=pupil_center_training.to(config[\"device\"]),\n",
    ").detach().cpu()\n",
    "plot_comparison(\n",
    "    target=crop(stim_training[:8], config[\"crop_win\"]).cpu(),\n",
    "    pred=crop(stim_training_pred_best[:8], config[\"crop_win\"]).cpu(),\n",
    "    save_to=os.path.join(config[\"dir\"], \"training_stim_comparison_best.png\") if config[\"decoder\"][\"save_run\"] else None,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
