{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from copy import deepcopy\n",
    "import dill\n",
    "import wandb\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "import lovely_tensors as lt\n",
    "from nnfabrik.builder import get_data\n",
    "from neuralpredictors.data.transforms import NeuroNormalizer\n",
    "from neuralpredictors.measures.modules import PoissonLoss\n",
    "from lurz2020.models.models import se2d_fullgaussian2d\n",
    "from lurz2020.utility.measures import get_correlations\n",
    "\n",
    "import csng\n",
    "from csng.CNN_Decoder import CNN_Decoder\n",
    "from csng.utils import crop, plot_comparison, standardize, normalize, get_mean_and_std, count_parameters, plot_losses\n",
    "from csng.losses import SSIMLoss, MSELossWithCrop, Loss\n",
    "from csng.data import MixedBatchLoader\n",
    "from csng.data import MixedBatchLoader\n",
    "from csng.readins import (\n",
    "    MultiReadIn,\n",
    "    HypernetReadIn,\n",
    "    ConvReadIn,\n",
    "    AttentionReadIn,\n",
    "    FCReadIn,\n",
    "    AutoEncoderReadIn,\n",
    "    Conv1dReadIn,\n",
    ")\n",
    "\n",
    "# from models import MultiReadIn, ConvReadIn, Loss\n",
    "from L2O_Decoder import L2O_Decoder, L2O_Shallow_Decoder\n",
    "from data_utils import get_mouse_v1_data\n",
    "\n",
    "lt.monkey_patch()\n",
    "\n",
    "DATA_PATH = os.path.join(os.environ[\"DATA_PATH\"], \"mouse_v1_sensorium22\")\n",
    "print(f\"{DATA_PATH=}\")\n",
    "\n",
    "%env \"WANDB_NOTEBOOK_NAME\" \"l2o_decoder.ipynb\"\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"data\": {\n",
    "        \"mixing_strategy\": \"parallel_min\", # needed only with multiple base dataloaders\n",
    "    },\n",
    "    \"device\": \"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    "    \"seed\": 0,\n",
    "    \"crop_win\": (slice(7, 29), slice(15, 51)),\n",
    "    # \"wandb\": None,\n",
    "    \"wandb\": {\n",
    "        \"project\": \"CSNG\",\n",
    "        \"group\": \"sensorium_2022\",\n",
    "    },\n",
    "}\n",
    "\n",
    "print(f\"... Running on {config['device']} ...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(config[\"seed\"])\n",
    "torch.manual_seed(config[\"seed\"])\n",
    "random.seed(config[\"seed\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloaders = dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mouse V1 dataset (Sensorium 2022)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### prep data config\n",
    "filenames = [ # from https://gin.g-node.org/cajal/Sensorium2022/src/master\n",
    "    # \"static26872-17-20-GrayImageNet-94c6ff995dac583098847cfecd43e7b6.zip\", # mouse 1\n",
    "    # \"static27204-5-13-GrayImageNet-94c6ff995dac583098847cfecd43e7b6.zip\", # sensorium+ (mouse 2)\n",
    "    \"static21067-10-18-GrayImageNet-94c6ff995dac583098847cfecd43e7b6.zip\", # pretraining (mouse 3)\n",
    "    \"static22846-10-16-GrayImageNet-94c6ff995dac583098847cfecd43e7b6.zip\", # pretraining (mouse 4)\n",
    "    \"static23343-5-17-GrayImageNet-94c6ff995dac583098847cfecd43e7b6.zip\", # pretraining (mouse 5)\n",
    "    \"static23656-14-22-GrayImageNet-94c6ff995dac583098847cfecd43e7b6.zip\", # pretraining (mouse 6)\n",
    "    \"static23964-4-22-GrayImageNet-94c6ff995dac583098847cfecd43e7b6.zip\", # pretraining (mouse 7)\n",
    "]\n",
    "for f_idx, f_name in enumerate(filenames):\n",
    "    filenames[f_idx] = os.path.join(DATA_PATH, f_name)\n",
    "\n",
    "config[\"data\"].update({\n",
    "    \"paths\": filenames,\n",
    "    \"dataset_fn\": \"sensorium.datasets.static_loaders\",\n",
    "    \"dataset_config\": {\n",
    "        \"paths\": filenames,\n",
    "        \"normalize\": True,\n",
    "        \"scale\": 0.25, # 256x144 -> 64x36\n",
    "        \"include_behavior\": False,\n",
    "        \"add_behavior_as_channels\": False,\n",
    "        \"include_eye_position\": True,\n",
    "        \"exclude\": None,\n",
    "        \"exclude\": [\"images\"], # manual normalization of images\n",
    "        \"file_tree\": True,\n",
    "        \"cuda\": False,\n",
    "        # \"batch_size\": 32,\n",
    "        \"batch_size\": 7,\n",
    "        \"seed\": config[\"seed\"],\n",
    "        \"use_cache\": False,\n",
    "    },\n",
    "    \"normalize_neuron_coords\": True,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_normalized_mouse_v1_data(config):\n",
    "    ### insert normalization to [0,1] transform to all datasets\n",
    "    ### - note: train, val, test all share one underlying dataset,\n",
    "    ###         so we only need to add the transform to one of them\n",
    "    \n",
    "    dls, neuron_coords = get_mouse_v1_data(config=config)\n",
    "    \n",
    "    for d_idx in range(dls[\"mouse_v1\"][\"test\"].n_dataloaders):\n",
    "        tr_to_add = NeuroNormalizer(\n",
    "            data=dls[\"mouse_v1\"][\"test\"].datasets[d_idx],\n",
    "            exclude=[\"behavior\", \"responses\", \"eye_position\"],\n",
    "            inputs_mean=0,\n",
    "            inputs_std=255,\n",
    "        )\n",
    "        dls[\"mouse_v1\"][\"test\"].datasets[d_idx].transforms.insert(0, tr_to_add)\n",
    "    \n",
    "    return dls, neuron_coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### get dataloaders and cell coordinates\n",
    "dataloaders, neuron_coords = get_normalized_mouse_v1_data(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### show data\n",
    "sample_data_key = dataloaders[\"mouse_v1\"][\"val\"].data_keys[0]\n",
    "datapoint = next(iter(dataloaders[\"mouse_v1\"][\"val\"].dataloaders[0]))\n",
    "stim, resp = datapoint.images, datapoint.responses\n",
    "pupil_center = datapoint.pupil_center\n",
    "print(\n",
    "    f\"Training dataset:\\t {sum(len(dl) * config['data']['dataset_config']['batch_size'] for dl in dataloaders['mouse_v1']['train'].dataloaders)} samples\"\n",
    "    f\"\\nValidation dataset:\\t {sum(len(dl) * config['data']['dataset_config']['batch_size'] for dl in dataloaders['mouse_v1']['val'].dataloaders)} samples\"\n",
    "    f\"\\nTest dataset:\\t\\t {sum(len(dl) * config['data']['dataset_config']['batch_size'] for dl in dataloaders['mouse_v1']['test'].dataloaders)} samples\"\n",
    "    f\"\\nTest (no resp) dataset:\\t {sum(len(dl) * config['data']['dataset_config']['batch_size'] for dl in dataloaders['mouse_v1']['test_no_resp'].dataloaders)} samples\"\n",
    "\n",
    "    \"\\n\\nstimuli:\"\n",
    "    f\"\\n  {stim.shape}\"\n",
    "    f\"\\n  min={stim.min().item():.3f}  max={stim.max().item():.3f}\"\n",
    "    f\"\\n  mean={stim.mean().item():.3f}  std={stim.std().item():.3f}\"\n",
    "    \"\\nresponses:\"\n",
    "    f\"\\n  {resp.shape}\"\n",
    "    f\"\\n  min={resp.min().item():.3f}  max={resp.max().item():.3f}\"\n",
    "    f\"\\n  mean={resp.mean().item():.3f}  std={resp.std().item():.3f}\"\n",
    "    \"\\nneuronal coordinates:\"\n",
    "    f\"\\n  {neuron_coords[sample_data_key].shape}\"\n",
    "    f\"\\n  min={neuron_coords[sample_data_key].min():.3f}  max={neuron_coords[sample_data_key].max():.3f}\"\n",
    "    f\"\\n  mean={neuron_coords[sample_data_key].mean():.3f}  std={neuron_coords[sample_data_key].std():.3f}\"\n",
    ")\n",
    "\n",
    "fig = plt.figure(figsize=(16, 6))\n",
    "ax = fig.add_subplot(121)\n",
    "ax.imshow(stim[0].squeeze().unsqueeze(-1).cpu(), cmap=\"gray\")\n",
    "\n",
    "ax = fig.add_subplot(122)\n",
    "reshape_to = None\n",
    "for i in range(30, 150):\n",
    "    if resp.shape[-1] % i == 0:\n",
    "        reshape_to = (i, resp.shape[-1] // i)\n",
    "        break\n",
    "if reshape_to != None:\n",
    "    ax.imshow(resp[0].view(reshape_to).squeeze(0).unsqueeze(-1).cpu(), cmap=\"gray\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### load encoder\n",
    "print(\"Loading encoder...\")\n",
    "\n",
    "### load pretrained encoder ckpt\n",
    "encoder_ckpt = torch.load(\n",
    "    os.path.join(DATA_PATH, \"models\", \"encoder.pt\"),\n",
    "    map_location=config[\"device\"],\n",
    ")\n",
    "\n",
    "### get temporary dataloaders for the encoder\n",
    "_dataloaders = get_data(\n",
    "    encoder_ckpt[\"config\"][\"data\"][\"dataset_fn\"],\n",
    "    encoder_ckpt[\"config\"][\"data\"][\"dataset_config\"]\n",
    ")\n",
    "\n",
    "### init encoder\n",
    "encoder = se2d_fullgaussian2d(\n",
    "    **encoder_ckpt[\"config\"][\"encoder\"][\"model_config\"],\n",
    "    dataloaders=_dataloaders,\n",
    "    seed=encoder_ckpt[\"config\"][\"seed\"],\n",
    ").float()\n",
    "encoder.load_state_dict(encoder_ckpt[\"encoder_state\"], strict=True)\n",
    "encoder.to(config[\"device\"])\n",
    "encoder.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### validate encoder is working (corr on val set should be ~ 0.32)\n",
    "train_correlation = get_correlations(encoder, _dataloaders[\"train\"], device=config[\"device\"], as_dict=False, per_neuron=False)\n",
    "validation_correlation = get_correlations(encoder, _dataloaders[\"validation\"], device=config[\"device\"], as_dict=False, per_neuron=False)\n",
    "test_correlation = get_correlations(encoder, _dataloaders[\"test\"], device=config[\"device\"], as_dict=False, per_neuron=False)\n",
    "\n",
    "print(\n",
    "    f\"Correlation (train set):      {train_correlation:.3f}\"\n",
    "    f\"\\nCorrelation (validation set): {validation_correlation:.3f}\"\n",
    "    f\"\\nCorrelation (test set):       {test_correlation:.3f}\"\n",
    ")\n",
    "\n",
    "### validate w/ my data (TODO: normalizing in L2O_Decoder, so this is not needed atm)\n",
    "t = {dk: dl for dk, dl in zip(dataloaders[\"mouse_v1\"][\"train\"].data_keys, dataloaders[\"mouse_v1\"][\"train\"].dataloaders)}\n",
    "v = {dk: dl for dk, dl in zip(dataloaders[\"mouse_v1\"][\"val\"].data_keys, dataloaders[\"mouse_v1\"][\"val\"].dataloaders)}\n",
    "te = {dk: dl for dk, dl in zip(dataloaders[\"mouse_v1\"][\"test\"].data_keys, dataloaders[\"mouse_v1\"][\"test\"].dataloaders)}\n",
    "\n",
    "### validate encoder is working (corr on val set should be ~ 0.32)\n",
    "train_correlation = get_correlations(encoder, t, device=config[\"device\"], as_dict=False, per_neuron=False)\n",
    "validation_correlation = get_correlations(encoder, v, device=config[\"device\"], as_dict=False, per_neuron=False)\n",
    "test_correlation = get_correlations(encoder, te, device=config[\"device\"], as_dict=False, per_neuron=False)\n",
    "\n",
    "print(\n",
    "    f\"Correlation (train set):      {train_correlation:.3f}\"\n",
    "    f\"\\nCorrelation (validation set): {validation_correlation:.3f}\"\n",
    "    f\"\\nCorrelation (test set):       {test_correlation:.3f}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### delete dataloaders\n",
    "del _dataloaders"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, dataloader, config, verbose=True):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    n_batches = len(dataloader)\n",
    "\n",
    "    ### run\n",
    "    for batch_idx, b in enumerate(dataloader):\n",
    "        loss = 0\n",
    "        \n",
    "        ### combine from all data keys\n",
    "        for data_key, (stim, resp, neuron_coords, pupil_center) in b.items():\n",
    "            ### train\n",
    "            stim_pred, _ = model(\n",
    "                x=resp,\n",
    "                data_key=data_key,\n",
    "                neuron_coords=neuron_coords,\n",
    "                pupil_center=pupil_center,\n",
    "                additional_core_inp=dict(\n",
    "                    train=True,\n",
    "                    resp=resp,\n",
    "                    stim=stim,\n",
    "                    neuron_coords=neuron_coords,\n",
    "                    pupil_center=pupil_center,\n",
    "                    data_key=data_key,\n",
    "                    n_steps=config[\"decoder\"][\"n_steps\"],\n",
    "                    x_hat_history_iters=None,\n",
    "                ),\n",
    "            )\n",
    "\n",
    "            ### log\n",
    "            loss += config[\"decoder\"][\"model\"][\"core_config\"][\"stim_loss_fn\"](\n",
    "                stim_pred, stim, phase=\"train\", data_key=data_key).item()\n",
    "            model.set_additional_loss(\n",
    "                inp={\n",
    "                    \"resp\": resp,\n",
    "                    \"stim\": stim,\n",
    "                    \"neuron_coords\": neuron_coords,\n",
    "                    \"pupil_center\": pupil_center,\n",
    "                    \"data_key\": data_key,\n",
    "                }, out={\n",
    "                    \"stim_pred\": stim_pred,\n",
    "                },\n",
    "            )\n",
    "            loss += model.get_additional_loss(data_key=data_key)\n",
    "\n",
    "        loss /= len(b)\n",
    "        train_loss += loss\n",
    "\n",
    "        if verbose and batch_idx % 100 == 0:\n",
    "            print(f\"Training progress: [{batch_idx}/{n_batches} ({100. * batch_idx / n_batches:.0f}%)]\"\n",
    "                  f\"  Loss: {loss:.6f}\")\n",
    "\n",
    "    train_loss /= n_batches \n",
    "    return train_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def val(model, dataloader, loss_fn, config, only_data_keys=None):\n",
    "    model.eval()\n",
    "    val_losses = {\"total\": 0}\n",
    "    denom_data_keys = {}\n",
    "    for b in dataloader:\n",
    "        ### combine from all data keys\n",
    "        for data_key, (stim, resp, neuron_coords, pupil_center) in b.items():\n",
    "            if only_data_keys is not None and data_key not in only_data_keys:\n",
    "                continue\n",
    "\n",
    "            stim_pred, stim_pred_history = model(\n",
    "                x=resp,\n",
    "                data_key=data_key,\n",
    "                neuron_coords=neuron_coords,\n",
    "                pupil_center=pupil_center,\n",
    "                additional_core_inp=dict(\n",
    "                    train=False,\n",
    "                    stim=None,\n",
    "                    resp=resp,\n",
    "                    neuron_coords=neuron_coords,\n",
    "                    pupil_center=pupil_center,\n",
    "                    data_key=data_key,\n",
    "                    n_steps=config[\"decoder\"][\"n_steps\"],\n",
    "                    x_hat_history_iters=None,\n",
    "                ),\n",
    "            )\n",
    "            loss = loss_fn(stim_pred, stim).item()\n",
    "            val_losses[data_key] = loss if data_key not in val_losses else val_losses[data_key] + loss\n",
    "            val_losses[\"total\"] += loss / len(b)\n",
    "            denom_data_keys[data_key] = denom_data_keys[data_key] + 1 if data_key in denom_data_keys else 1\n",
    "\n",
    "    val_losses[\"total\"] /= len(dataloader)\n",
    "    for k in denom_data_keys:\n",
    "        val_losses[k] /= denom_data_keys[k]\n",
    "    return val_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config[\"decoder\"] = {\n",
    "    \"model\": {\n",
    "        \"readins_config\": [\n",
    "            {\n",
    "                \"data_key\": data_key,\n",
    "                \"in_shape\": d.n_neurons,\n",
    "                \"layers\": [\n",
    "                    (ConvReadIn, {\n",
    "                        \"shift_coords\": True,\n",
    "                        \"learn_grid\": False,\n",
    "                        \"grid_l1_reg\": 3e-3,\n",
    "                        \"in_channels_group_size\": 2,\n",
    "                        \"pointwise_conv_config\": {\n",
    "                            \"in_channels\": d.n_neurons,\n",
    "                            \"out_channels\": 86,\n",
    "                            \"act_fn\": nn.LeakyReLU,\n",
    "                            \"bias\": False,\n",
    "                            \"batch_norm\": True,\n",
    "                            \"dropout\": 0.,\n",
    "                        },\n",
    "                        \"gauss_blur\": True,\n",
    "                        \"gauss_blur_kernel_size\": 7,\n",
    "                        # \"gauss_blur_sigma\": \"fixed\", # \"fixed\", \"single\", \"per_neuron\"\n",
    "                        \"gauss_blur_sigma\": \"per_neuron\", # \"fixed\", \"single\", \"per_neuron\"\n",
    "                        \"gauss_blur_sigma_init\": 1.5,\n",
    "                    }),\n",
    "                ],\n",
    "            } for d, data_key in zip(dataloaders[\"mouse_v1\"][\"train\"].datasets, dataloaders[\"mouse_v1\"][\"train\"].data_keys)\n",
    "        ],\n",
    "        # \"core_cls\": L2O_Decoder,\n",
    "        \"core_cls\": L2O_Decoder,\n",
    "        \"core_config\": {\n",
    "            \"encoder\": encoder.float(),\n",
    "            # \"resp_shape\": resp.shape[1:],\n",
    "            \"resp_shape\": [86],\n",
    "            \"stim_shape\": (1, 36, 64),\n",
    "            \"in_shape\": (4, 36, 64),\n",
    "            # \"reconstruction_init_method\": \"zero\",\n",
    "            # \"resp_layers_cfg\": {\n",
    "            #     \"layers\": [\n",
    "            #         (\"fc\", 288),\n",
    "            #         (\"unflatten\", 1, (2, 9, 16)),\n",
    "            #         (\"deconv\", 64, 9, 2, 4),\n",
    "            #         (\"deconv\", 32, 7, 2, 3),\n",
    "            #         (\"deconv\", 1, 4, 1, 0),\n",
    "            #     ],\n",
    "            #     \"act_fn\": nn.ReLU(),\n",
    "            #     \"out_act_fn\": nn.Sigmoid(),\n",
    "            #     \"dropout\": 0.2,\n",
    "            #     \"batch_norm\": True,\n",
    "            # },\n",
    "            # \"reconstruction_init_method\": \"resp_layers\",\n",
    "            \"resp_layers_cfg\": {\n",
    "                \"layers\": [\n",
    "                    # (\"deconv\", 64, 9, 2, 4),\n",
    "                    # (\"deconv\", 32, 7, 2, 3),\n",
    "                    # (\"deconv\", 1, 4, 1, 0),\n",
    "                    (\"deconv\", 64, 7, 2, 3),\n",
    "                    (\"deconv\", 32, 6, 2, 2),\n",
    "                    # (\"deconv\", 32, 5, 1, 2),\n",
    "                    (\"deconv\", 1, 3, 1, 0),\n",
    "                ],\n",
    "                \"act_fn\": nn.ReLU(),\n",
    "                \"out_act_fn\": nn.Sigmoid(),\n",
    "                \"dropout\": 0.2,\n",
    "                \"batch_norm\": True,\n",
    "            },\n",
    "            \"reconstruction_init_method\": \"resp_layers\",\n",
    "            \"act_fn\": nn.ReLU(),\n",
    "            # \"reconstruction_layers_cfg\": {\n",
    "            #     \"layers\": [\n",
    "            #         (\"conv\", 64, 5, 1, 2),\n",
    "            #         (\"conv\", 64, 5, 1, 2),\n",
    "            #         (\"conv\", 32, 5, 1, 2),\n",
    "            #         (\"conv\", 1, 3, 1, 1)\n",
    "            #     ],\n",
    "            #     \"batch_norm\": True,\n",
    "            #     \"dropout\": 0.2,\n",
    "            #     \"act_fn\": nn.LeakyReLU,\n",
    "            #     \"out_act_fn\": nn.Identity,\n",
    "            # },\n",
    "            # \"stim_loss_fn\": MSELossWithCrop(config[\"stim_crop_win\"]),\n",
    "            # \"stim_loss_fn\": SSIMLoss(\n",
    "            #     log_loss=True,\n",
    "            #     inp_normalized=False,\n",
    "            #     inp_standardized=True,\n",
    "            # ),\n",
    "            # \"stim_loss_fn\": lambda x_hat, x: 0.9 * ssim_loss(x_hat, x) + 0.1 * F.mse_loss(x_hat, x),\n",
    "            # \"resp_loss_fn\": nn.MSELoss(),\n",
    "            \"resp_loss_fn\": PoissonLoss(avg=True),\n",
    "            \"opter_cls\": torch.optim.Adam,\n",
    "            \"opter_kwargs\": {\n",
    "                \"lr\": 0.001,\n",
    "            },\n",
    "            \"unroll\": 4,\n",
    "            \"preproc_grad\": True,\n",
    "            \"device\": config[\"device\"],\n",
    "        },\n",
    "    },\n",
    "    \"loss\": {\n",
    "        \"loss_fn\": SSIMLoss(\n",
    "            window=config[\"crop_win\"],\n",
    "            log_loss=True,\n",
    "            inp_normalized=False,\n",
    "            inp_standardized=True,\n",
    "        ),\n",
    "        \"l1_reg_mul\": 0,\n",
    "        \"l2_reg_mul\": 1e-5,\n",
    "        \"con_reg_mul\": 0,\n",
    "        # \"con_reg_loss_fn\": SSIMLoss(\n",
    "        #     window=config[\"crop_win\"],\n",
    "        #     log_loss=True,\n",
    "        #     inp_normalized=True,\n",
    "        #     inp_standardized=False,\n",
    "        # ),\n",
    "        \"encoder\": None,\n",
    "        # \"encoder\": encoder,\n",
    "    },\n",
    "    \"n_epochs\": 200,\n",
    "    \"n_steps\": 8,\n",
    "    \"load_ckpt\": None,\n",
    "    # \"load_ckpt\": {\n",
    "    #     \"run_name\": \"2024-02-25_17-07-04\",\n",
    "    #     \"ckpt_path\": os.path.join(DATA_PATH, \"models\", \"l2o\", \"2024-02-25_17-07-04\", \"decoder.pt\"),\n",
    "    # },\n",
    "    \"save_run\": True,\n",
    "}\n",
    "\n",
    "config[\"decoder\"][\"model\"][\"core_config\"][\"stim_loss_fn\"] = Loss(model=None, config=config[\"decoder\"][\"loss\"])\n",
    "decoder = MultiReadIn(**config[\"decoder\"][\"model\"]).to(config[\"device\"])\n",
    "decoder.core.stim_loss_fn.model = decoder\n",
    "config[\"decoder\"][\"model\"][\"core_config\"][\"stim_loss_fn\"] = decoder.core.stim_loss_fn\n",
    "sl = SSIMLoss(\n",
    "    window=config[\"crop_win\"],\n",
    "    log_loss=True,\n",
    "    inp_normalized=True,\n",
    "    inp_standardized=False,\n",
    ")\n",
    "val_loss_fn = lambda y_pred, y: sl(normalize(y_pred), normalize(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### prepare checkpointing\n",
    "config[\"run_name\"] = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "if config[\"decoder\"][\"save_run\"]:\n",
    "    ### save config\n",
    "    config[\"dir\"] = os.path.join(DATA_PATH, \"models\", \"l2o\", config[\"run_name\"])\n",
    "    os.makedirs(config[\"dir\"], exist_ok=True)\n",
    "    with open(os.path.join(config[\"dir\"], \"config.json\"), \"w\") as f:\n",
    "        json.dump(config, f, indent=4, default=str)\n",
    "    os.makedirs(os.path.join(config[\"dir\"], \"samples\"), exist_ok=True)\n",
    "    os.makedirs(os.path.join(config[\"dir\"], \"ckpt\"), exist_ok=True)\n",
    "    make_sample_path = lambda epoch, prefix: os.path.join(\n",
    "        config[\"dir\"], \"samples\", f\"{prefix}stim_comparison_{epoch}e.png\"\n",
    "    )\n",
    "    \n",
    "    print(f\"Run name: {config['run_name']}\\nRun dir: {config['dir']}\")\n",
    "else:\n",
    "    make_sample_path = lambda epoch, prefix: None\n",
    "    print(\"WARNING: Not saving the run and the config.\")\n",
    "\n",
    "### wandb\n",
    "if config[\"wandb\"]:\n",
    "    wdb_run = wandb.init(**config[\"wandb\"], name=config[\"run_name\"], config=config,\n",
    "        tags=[\n",
    "            config[\"decoder\"][\"model\"][\"core_cls\"].__name__,\n",
    "            config[\"decoder\"][\"model\"][\"readins_config\"][0][\"layers\"][0][0].__name__,\n",
    "        ],\n",
    "        notes=None)\n",
    "    wdb_run.watch(decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### load ckpt\n",
    "if config[\"decoder\"][\"load_ckpt\"] != None:\n",
    "    run_name = config[\"decoder\"][\"load_ckpt\"][\"run_name\"] # \"2023-09-24_18-49-50\"\n",
    "    ckpt = torch.load(config[\"decoder\"][\"load_ckpt\"][\"ckpt_path\"], map_location=config[\"device\"], pickle_module=dill)\n",
    "\n",
    "    history = ckpt[\"history\"]\n",
    "    config = ckpt[\"config\"]\n",
    "    best = ckpt[\"best\"]\n",
    "\n",
    "    # decoder = L2O_Decoder(**config[\"decoder\"][\"model\"]).to(config[\"device\"])\n",
    "    decoder = MultiReadIn(**config[\"decoder\"][\"model\"]).to(config[\"device\"])\n",
    "    decoder.core.stim_loss_fn.model = decoder\n",
    "    config[\"decoder\"][\"model\"][\"core_config\"][\"stim_loss_fn\"] = decoder.core.stim_loss_fn\n",
    "    decoder.load_state_dict(ckpt[\"decoder\"])\n",
    "\n",
    "    make_sample_path = lambda epoch, prefix: os.path.join(\n",
    "        config[\"dir\"], \"samples\", f\"{prefix}stim_comparison_{epoch}e.png\"\n",
    "    )\n",
    "else:\n",
    "    history = {\"train_loss\": [], \"val_loss\": []}\n",
    "    best = {\"val_loss\": np.inf, \"epoch\": 0, \"model\": None}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### print model\n",
    "print(decoder(\n",
    "    resp.to(config[\"device\"]),\n",
    "    data_key=sample_data_key,\n",
    "    neuron_coords=neuron_coords[sample_data_key].to(config[\"device\"]),\n",
    "    pupil_center=pupil_center.to(config[\"device\"]),\n",
    "    additional_core_inp=dict(\n",
    "        resp=resp.to(config[\"device\"]),\n",
    "        stim=stim.to(config[\"device\"]),\n",
    "        data_key=sample_data_key,\n",
    "        n_steps=3,\n",
    "        train=False,\n",
    "        x_hat_history_iters=None,\n",
    "    ))[0].shape)\n",
    "print(f\"Number of parameters: {count_parameters(decoder)}\")\n",
    "\n",
    "decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### train\n",
    "s, e = len(history[\"train_loss\"]), len(history[\"train_loss\"]) + config[\"decoder\"][\"n_epochs\"]\n",
    "for epoch in range(s, e):\n",
    "    print(f\"[{epoch + 1}/{e}]\")\n",
    "\n",
    "    ### train and val\n",
    "    dls, neuron_coords = get_normalized_mouse_v1_data(config=config)\n",
    "    train_dataloader, val_dataloader = dls[\"mouse_v1\"][\"train\"], dls[\"mouse_v1\"][\"val\"]\n",
    "    train_loss = train(\n",
    "        model=decoder,\n",
    "        dataloader=train_dataloader,\n",
    "        config=config,\n",
    "    )\n",
    "    val_losses = val(\n",
    "        model=decoder,\n",
    "        dataloader=val_dataloader,\n",
    "        loss_fn=val_loss_fn,\n",
    "        # loss_fn=config[\"decoder\"][\"model\"][\"stim_loss_fn\"],\n",
    "        config=config,\n",
    "    )\n",
    "\n",
    "    ### save best model\n",
    "    if val_losses[\"total\"] < best[\"val_loss\"]:\n",
    "        best[\"val_loss\"] = val_losses[\"total\"]\n",
    "        best[\"epoch\"] = epoch\n",
    "        best[\"model\"] = deepcopy(decoder.state_dict())\n",
    "\n",
    "    ### log\n",
    "    history[\"train_loss\"].append(train_loss)\n",
    "    history[\"val_loss\"].append(val_losses[\"total\"])\n",
    "    if config[\"wandb\"]: wdb_run.log({\"train_loss\": train_loss, \"val_loss\": val_losses[\"total\"]}, commit=False)\n",
    "    print(f\"{val_losses['total']=:.4f}\", end=\"\")\n",
    "    for data_key, loss in val_losses.items():\n",
    "        if data_key != \"total\":\n",
    "            print(f\", {data_key}: {loss:.4f}\", end=\"\")\n",
    "    print(\"\")\n",
    "\n",
    "    ### plot sample reconstructions\n",
    "    stim_pred = decoder(\n",
    "        x=resp.to(config[\"device\"]),\n",
    "        data_key=sample_data_key,\n",
    "        neuron_coords=neuron_coords[sample_data_key].to(config[\"device\"]),\n",
    "        pupil_center=pupil_center.to(config[\"device\"]),\n",
    "        additional_core_inp=dict(\n",
    "            resp=resp.to(config[\"device\"]),\n",
    "            stim=stim.to(config[\"device\"]),\n",
    "            data_key=sample_data_key,\n",
    "            n_steps=config[\"decoder\"][\"n_steps\"],\n",
    "            train=False,\n",
    "            x_hat_history_iters=None,\n",
    "        ),\n",
    "    )[0].detach()\n",
    "    fig = plot_comparison(target=crop(stim[:8], config[\"crop_win\"]).cpu(), pred=crop(stim_pred[:8], config[\"crop_win\"]).cpu(), save_to=make_sample_path(epoch, \"\"))\n",
    "    if config[\"wandb\"]: wdb_run.log({\"val_stim_reconstruction\": fig})\n",
    "\n",
    "    ### plot losses\n",
    "    if epoch % 5 == 0 and epoch > 0:\n",
    "        plot_losses(history=history, epoch=epoch, save_to=os.path.join(config[\"dir\"], f\"losses_{epoch}.png\") if config[\"decoder\"][\"save_run\"] else None)\n",
    "\n",
    "        ### ckpt\n",
    "    if epoch % 5 == 0 and epoch > 0 and config[\"decoder\"][\"save_run\"]:\n",
    "        torch.save({\n",
    "            \"decoder\": decoder.state_dict(),\n",
    "            \"opter\": decoder.core.opter.state_dict(),\n",
    "            \"history\": history,\n",
    "            \"config\": config,\n",
    "            \"best\": best,\n",
    "        }, os.path.join(config[\"dir\"], \"ckpt\", f\"decoder_{epoch}.pt\"), pickle_module=dill)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### final evaluation + logging + saving\n",
    "print(f\"Best val loss: {best['val_loss']:.4f} at epoch {best['epoch']}\")\n",
    "\n",
    "### save final ckpt\n",
    "if config[\"decoder\"][\"save_run\"]:\n",
    "    torch.save({\n",
    "        \"decoder\": decoder.state_dict(),\n",
    "        \"opter\": decoder.core.opter.state_dict(),\n",
    "        \"history\": history,\n",
    "        \"config\": config,\n",
    "        \"best\": best,\n",
    "    }, os.path.join(config[\"dir\"], f\"decoder.pt\"), pickle_module=dill)\n",
    "\n",
    "### eval on test set w/ current params\n",
    "print(\"Evaluating on test set with current model...\")\n",
    "dls, neuron_coords = get_mouse_v1_data(config=config)\n",
    "test_loss_curr = val(\n",
    "    model=decoder,\n",
    "    dataloader=dls[\"mouse_v1\"][\"test\"],\n",
    "    loss_fn=val_loss_fn,\n",
    "    config=config,\n",
    ")\n",
    "print(f\"  Test loss (current model): {test_loss_curr['total']:.4f}\")\n",
    "\n",
    "### load best model\n",
    "decoder.load_state_dict(best[\"model\"])\n",
    "\n",
    "### eval on test set w/ best params\n",
    "print(\"Evaluating on test set with best model...\")\n",
    "dls, neuron_coords = get_mouse_v1_data(config=config)\n",
    "test_loss_final = val(\n",
    "    model=decoder,\n",
    "    dataloader=dls[\"mouse_v1\"][\"test\"],\n",
    "    loss_fn=val_loss_fn,\n",
    "    config=config,\n",
    ")\n",
    "print(f\"  Test loss (best model): {test_loss_final['total']:.4f}\")\n",
    "\n",
    "\n",
    "### plot reconstructions of the final model\n",
    "decoder.load_state_dict(best[\"model\"])\n",
    "stim_pred_best, recon_history = decoder(\n",
    "    x=resp.to(config[\"device\"]),\n",
    "    data_key=sample_data_key,\n",
    "    neuron_coords=neuron_coords[sample_data_key].to(config[\"device\"]),\n",
    "    pupil_center=pupil_center.to(config[\"device\"]),\n",
    "    additional_core_inp=dict(\n",
    "        resp=resp.to(config[\"device\"]),\n",
    "        stim=stim.to(config[\"device\"]),\n",
    "        data_key=sample_data_key,\n",
    "        n_steps=config[\"decoder\"][\"n_steps\"],\n",
    "        train=False,\n",
    "        # x_hat_history_iters=None,\n",
    "        x_hat_history_iters=list(range(1, config[\"decoder\"][\"n_steps\"] + 1)),\n",
    "    ),\n",
    ")\n",
    "stim_pred_best = stim_pred_best.detach()\n",
    "fig = plot_comparison(\n",
    "    target=crop(stim[:8], config[\"crop_win\"]).cpu(),\n",
    "    pred=crop(stim_pred_best[:8], config[\"crop_win\"]).cpu(),\n",
    "    save_to=os.path.join(config[\"dir\"], \"stim_comparison_best.png\") if config[\"decoder\"][\"save_run\"] else None,\n",
    ")\n",
    "\n",
    "### log\n",
    "if config[\"wandb\"]:\n",
    "    wandb.run.summary[\"best_val_loss\"] = best[\"val_loss\"]\n",
    "    wandb.run.summary[\"best_epoch\"] = best[\"epoch\"]\n",
    "    wandb.run.summary[\"curr_test_loss\"] = test_loss_curr[\"total\"]\n",
    "    wandb.run.summary[\"final_test_loss\"] = test_loss_final[\"total\"]\n",
    "    wandb.run.summary[\"best_reconstruction\"] = fig\n",
    "\n",
    "### save/delete wandb run\n",
    "if config[\"wandb\"]:\n",
    "    if input(\"Delete run with 'd', save with anything else: \") == \"d\":\n",
    "        print(\"Deleting wandb run...\")\n",
    "        api = wandb.Api()\n",
    "        run = api.run(f\"johnny1188/{config['wandb']['project']}/{wdb_run.id}\")\n",
    "        run.delete()\n",
    "    else:\n",
    "        wdb_run.finish()\n",
    "\n",
    "### plot losses\n",
    "plot_losses(\n",
    "    history=history,\n",
    "    save_to=None if not config[\"decoder\"][\"save_run\"] else os.path.join(config[\"dir\"], f\"losses.png\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 2\n",
    "\n",
    "plt.imshow(stim[idx].squeeze().cpu().detach().numpy(), cmap=\"gray\")\n",
    "plt.show()\n",
    "for x_hat in history[\"x_hat_history\"]:\n",
    "    plt.imshow(x_hat[idx].squeeze().cpu().detach().numpy(), cmap=\"gray\")\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.1.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
