{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os.path import join\n",
    "import torch\n",
    "from torchvision.datasets import ImageNet\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import functional as F\n",
    "import torch.nn.functional as tf\n",
    "import torchvision\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from random import random\n",
    "import torch.multiprocessing as mp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "device = os.environ[\"DEVICE\"]\n",
    "utils = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_convnets_processing_utils', )\n",
    "\n",
    "DATA_DIR = os.environ['DATA_PATH']\n",
    "CACHE_DIR = join(DATA_DIR, 'imagenet_inversion')\n",
    "RESNET_SIZE = 224\n",
    "TARGET_CROP = torchvision.transforms.CenterCrop((36, 64))\n",
    "\n",
    "class CachedImageNet(ImageNet):\n",
    "    def __init__(self, root, split, transform=None, feature_extractor=None, version='0.1'):\n",
    "        super().__init__(root=root, split=split, transform=transform)\n",
    "        self.feature_extractor = feature_extractor  # Function to extract features\n",
    "        self.cache_dir = os.path.join(CACHE_DIR, version, split)\n",
    "\n",
    "        # Create cache directory if it doesn't exist\n",
    "        os.makedirs(self.cache_dir, exist_ok=True)\n",
    "        self.resnet50 = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_resnet50', pretrained=True)\n",
    "        self.resnet50.eval().to(device)\n",
    "        self.resnet_layer = self.resnet50.layers[2][0].downsample[0]\n",
    "\n",
    "\n",
    "    def _get_cache_path(self, index):\n",
    "        \"\"\"Get the path for the cached feature.\"\"\"\n",
    "        return os.path.join(self.cache_dir, f'feature_{index}.pt')\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # Load the image and label\n",
    "        img, object_class = super().__getitem__(index)\n",
    "\n",
    "        # Cache file path\n",
    "        cache_path = self._get_cache_path(index)\n",
    "\n",
    "        # Load feature from cache if it exists\n",
    "\n",
    "        img = img.unsqueeze(0)  # Add batch dimension\n",
    "        grayscale_img_rgb = F.rgb_to_grayscale(img, num_output_channels=3).to(device)\n",
    "        features_path = os.path.join(self.cache_dir, f'feature_{index}.pt')\n",
    "\n",
    "        if os.path.exists(cache_path):\n",
    "            saved_features = torch.load(cache_path).to(device)\n",
    "            if random() < 0.01: # check if the cache is correct\n",
    "                features = None\n",
    "                def assign_features(module, input, output):\n",
    "                    nonlocal features\n",
    "                    features = output\n",
    "                hook = self.resnet_layer.register_forward_hook(assign_features)\n",
    "                \n",
    "                with torch.no_grad():\n",
    "                    self.resnet50(grayscale_img_rgb)\n",
    "                hook.remove()\n",
    "                assert features is not None\n",
    "                assert torch.equal(saved_features, features)\n",
    "            features = saved_features\n",
    "\n",
    "        else:\n",
    "            # Compute feature if not cached\n",
    "\n",
    "            features = None\n",
    "            def assign_features(module, input, output):\n",
    "                nonlocal features\n",
    "                features = output\n",
    "            hook = self.resnet_layer.register_forward_hook(assign_features)\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                self.resnet50(grayscale_img_rgb)\n",
    "            hook.remove()\n",
    "            assert features is not None\n",
    "\n",
    "            torch.save(features, cache_path)  # Save to cache\n",
    "        \n",
    "        # center crop\n",
    "        target = TARGET_CROP(F.rgb_to_grayscale(img, num_output_channels=1))\n",
    "        return grayscale_img_rgb, features, target\n",
    "# Image transformations\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# Example feature extractor: compute mean/std per channel\n",
    "\n",
    "def feature_extractor(img):\n",
    "    img_np = np.array(img)\n",
    "    mean = np.mean(img_np, axis=(0, 1))\n",
    "    std = np.std(img_np, axis=(0, 1))\n",
    "    return torch.tensor(np.concatenate([mean, std]))\n",
    "# Dataset path\n",
    "\n",
    "\n",
    "# Set the start method to 'spawn'\n",
    "mp.set_start_method('spawn', force=True)\n",
    "# Initialize CachedImageNet\n",
    "train_dataset = CachedImageNet(\n",
    "    root=join(DATA_DIR, 'imagenet'),\n",
    "    split='val',\n",
    "    transform=train_transforms,\n",
    "    feature_extractor=feature_extractor,\n",
    "    version='0.5'\n",
    ")\n",
    "\n",
    "from torch.utils.data import random_split, DataLoader\n",
    "\n",
    "# Define the split sizes\n",
    "train_size = int(0.8 * len(train_dataset))  # 80% for training\n",
    "test_size = len(train_dataset) - train_size  # 20% for testing\n",
    "print(\"Train size:\", train_size)\n",
    "print(\"Test size:\", test_size)\n",
    "\n",
    "# Split the dataset\n",
    "train_subset, test_subset = random_split(train_dataset, [train_size, test_size])\n",
    "\n",
    "# Create DataLoaders for train and test\n",
    "train_loader = DataLoader(\n",
    "    dataset=train_subset,\n",
    "    batch_size=64,\n",
    "    # shuffle=True,\n",
    "    shuffle=False,\n",
    "    num_workers=0\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    dataset=test_subset,\n",
    "    batch_size=64,\n",
    "    shuffle=False,  # No need to shuffle test data\n",
    "    num_workers=0\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a batch from the DataLoader\n",
    "def show_image(img_tensor):\n",
    "    img = img_tensor.cpu().numpy().transpose((1, 2, 0))  # Convert to HWC\n",
    "    mean = np.array([0.485, 0.456, 0.406])  # ImageNet normalization mean\n",
    "    std = np.array([0.229, 0.224, 0.225])  # ImageNet normalization std\n",
    "    img = std * img + mean  # De-normalize\n",
    "    img = np.clip(img, 0, 1)  # Clip values to [0, 1]\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "data_iter = iter(train_loader)  # Replace `train_loader` with your DataLoader\n",
    "images, features, targets = next(data_iter)\n",
    "show_image(images[2][0, ...])  # Show the first image in the batch\n",
    "show_image(targets[2][0, ...])  # Show the first image in the batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import torch.nn.functional as f2\n",
    "\n",
    "class LogisticRegressor(nn.Module):\n",
    "    def __init__(self, feature_dim, output_dim):\n",
    "        \"\"\"\n",
    "        Logistic Regression Model\n",
    "        :param feature_dim: Flattened input feature size\n",
    "        :param output_dim: Number of outputs (1 for binary classification)\n",
    "        \"\"\"\n",
    "        super(LogisticRegressor, self).__init__()\n",
    "        self.linear = nn.Linear(feature_dim, output_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        logits = self.linear(x)  # Compute raw scores\n",
    "        probs = torch.sigmoid(logits)  # Apply sigmoid for binary classification\n",
    "        return probs\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        \"\"\"\n",
    "        Single-layer MLP for regression.\n",
    "        :param input_dim: Input feature size (flattened)\n",
    "        :param hidden_dim: Number of hidden units\n",
    "        :param output_dim: Number of outputs (target size)\n",
    "        :param alpha: Regularization strength\n",
    "        \"\"\"\n",
    "        super(SingleLayerMLP, self).__init__()\n",
    "        self.hidden1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.act1 = nn.LeakyReLU(.1)\n",
    "        self.hidden2 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.act2 = nn.LeakyReLU(.1)\n",
    "        self.output = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.act2(self.hiddne2(self.act1(self.hidden1(x))))\n",
    "        return self.output(x)\n",
    "\n",
    "# Model parameters\n",
    "feature_shape = (1024, 14, 14)  # Provided feature shape\n",
    "flattened_feature_size = torch.prod(torch.tensor(feature_shape)).item()\n",
    "\n",
    "output_size = 36 * 64  # Flattened target shape (36x64 from TARGET_CROP)\n",
    "# Model parameters\n",
    "hidden_units = 256 # Number of hidden units in the MLP\n",
    "mlp_model = MLP(flattened_feature_size, hidden_units, output_size).to(device)\n",
    "\n",
    "# Loss and optimizer2481825\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(mlp_model.parameters(), lr=0.001)\n",
    "\n",
    "# Training Loop\n",
    "num_epochs = 6 # Number of epochs\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(mlp_model.parameters(), lr=0.001)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    mlp_model.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    # for grayscale_img, features, target in tqdm(train_loader):\n",
    "    for grayscale_img, features, target in train_loader:\n",
    "        features = features.to(device)  # Move to device\n",
    "        target = target.view(target.size(0), -1).to(device)  # Flatten target\n",
    "\n",
    "        # Flatten features\n",
    "        features = features.view(features.size(0), -1)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = mlp_model(features)\n",
    "        loss = criterion(outputs, target)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        # constant_guess = torch.mean(target, dim=(-1, -2), keepdim=True)\n",
    "        constant_guess_loss = criterion(torch.full_like(target, 0), target)\n",
    "        # print(f\"Constant guess loss: {constant_guess_loss.item()}\")\n",
    "        # print(f\"Loss: {loss.item()}\")\n",
    "\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}\")\n",
    "       \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def evaluate_partial_model(model, test_loader, device, percentage=0.1):\n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    criterion = nn.MSELoss()\n",
    "    all_targets = []\n",
    "    all_predictions = []\n",
    "\n",
    "    num_batches = int(len(test_loader) * percentage)  # Calculate the number of batches to process\n",
    "    processed_batches = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for grayscale_img, features, target in tqdm(test_loader):\n",
    "            if processed_batches >= num_batches:\n",
    "                break\n",
    "\n",
    "            features = features.to(device)\n",
    "            target = target.view(target.size(0), -1).to(device)\n",
    "\n",
    "            # Flatten features\n",
    "            features = features.view(features.size(0), -1)\n",
    "\n",
    "            # Predict\n",
    "            predictions = model(features)\n",
    "            loss = criterion(predictions, target)\n",
    "            test_loss += loss.item()\n",
    "\n",
    "            # Store for plotting\n",
    "            all_targets.append(target.cpu())\n",
    "            all_predictions.append(predictions.cpu())\n",
    "\n",
    "            processed_batches += 1\n",
    "\n",
    "    test_loss /= processed_batches\n",
    "    all_targets = torch.cat(all_targets, dim=0)\n",
    "    all_predictions = torch.cat(all_predictions, dim=0)\n",
    "\n",
    "    return test_loss, all_targets, all_predictions\n",
    "\n",
    "# Evaluate on the first 10% of the test dataset\n",
    "test_loss_partial, partial_targets, partial_predictions = evaluate_partial_model(\n",
    "    mlp_model, test_loader, device, percentage=0.1\n",
    ")\n",
    "print(f\"Test Loss (First 10%): {test_loss_partial:.4f}\")\n",
    "\n",
    "# Plot Examples\n",
    "def plot_examples(targets, predictions, num_examples=5):\n",
    "    plt.figure(figsize=(15, num_examples * 3))\n",
    "    for i in range(num_examples):\n",
    "        plt.subplot(num_examples, 2, 2 * i + 1)\n",
    "        plt.imshow(targets[i].reshape(36, 64), cmap='gray')\n",
    "        plt.title(\"Actual Target\")\n",
    "        plt.axis('off')\n",
    "\n",
    "        plt.subplot(num_examples, 2, 2 * i + 2)\n",
    "        plt.imshow(predictions[i].reshape(36, 64), cmap='gray')\n",
    "        plt.title(\"Predicted Target\")\n",
    "        plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Plot Examples\n",
    "num_examples = 5  # Number of examples to visualize\n",
    "plot_examples(partial_targets[:num_examples].cpu().numpy(), partial_predictions[:num_examples].cpu().numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(partial_predictions.min(), partial_predictions.max())\n",
    "print(partial_targets.min(), partial_targets.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
