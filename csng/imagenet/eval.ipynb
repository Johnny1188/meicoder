{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Evaluation\n",
                "In this notebook, we evaluate the performance of the Resnet50 based model in a way, which is directly comparable to the other methods.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "import numpy as np\n",
                "from collections import defaultdict\n",
                "import json\n",
                "import torch\n",
                "import torch.nn as nn\n",
                "\n",
                "from csng.data import get_dataloaders, get_sample_data\n",
                "from csng.losses import FID, get_metrics\n",
                "from csng.utils.mix import seed_all\n",
                "from csng.utils.comparison import plot_reconstructions\n",
                "from csng.utils.data import crop\n",
                "from csng.imagenet.models import ReadIn, UpsampleModel, Decoder"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "### brainreader mouse data\n",
                "\n",
                "MODELS_PATH = os.path.join(os.environ[\"MODELS_PATH\"])\n",
                "READIN_PATH =  os.path.join(MODELS_PATH, 'readin', 'readin_2024-12-16_21-22-07.pt')\n",
                "UPSAMPLE_PATH = os.path.join(MODELS_PATH, 'mlp2497127.pt')\n",
                "\n",
                "cfg = {\n",
                "    \"device\": os.environ[\"DEVICE\"],\n",
                "    \"seed\": 0,\n",
                "    \"data\": {\"mixing_strategy\": \"sequential\"},\n",
                "    \"crop_wins\": dict(),\n",
                "}\n",
                "cfg[\"data\"][\"brainreader_mouse\"] = {\n",
                "    \"device\": cfg[\"device\"],\n",
                "    \"mixing_strategy\": cfg[\"data\"][\"mixing_strategy\"],\n",
                "    \"max_batches\": None,\n",
                "    \"data_dir\": os.path.join(os.environ[\"DATA_PATH\"], \"brainreader\", \"data\"),\n",
                "    \"batch_size\": 256,\n",
                "    \"sessions\": [6],\n",
                "    \"resize_stim_to\": (224, 224),\n",
                "    \"normalize_stim\": False,\n",
                "    \"normalize_resp\": True,\n",
                "    \"div_resp_by_std\": True,\n",
                "    \"clamp_neg_resp\": True,\n",
                "    \"additional_keys\": None,\n",
                "    \"avg_test_resp\": True,\n",
                "}\n",
                "# add crop_wins for brainreader mouse data\n",
                "_dls, _ = get_dataloaders(config=cfg)\n",
                "for data_key, dset in zip(_dls[\"train\"][\"brainreader_mouse\"].data_keys, _dls[\"train\"][\"brainreader_mouse\"].datasets):\n",
                "    cfg[\"crop_wins\"][data_key] = tuple(dset[0].images.shape[-2:])\n",
                "    print(f\"crop_wins[{data_key}]: {cfg['crop_wins'][data_key]}\")\n",
                "    "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [],
            "source": [
                "### evaluation function\n",
                "def eval_decoder(model, dataloaders, loss_fns, crop_wins, calc_fid=False, max_batches=None):\n",
                "    model.eval()\n",
                "\n",
                "    ### for tracking over whole dataset\n",
                "    losses = {data_key: {loss_fn_name: 0 for loss_fn_name in data_key_loss_fns.keys()} for data_key, data_key_loss_fns in loss_fns.items()}\n",
                "    denom_data_keys = {}\n",
                "    if calc_fid:\n",
                "        preds, targets = defaultdict(list), defaultdict(list)\n",
                "\n",
                "    ### run eval\n",
                "    for k, dl in dataloaders.items(): # different data sources (cat_v1, mouse_v1, ...)\n",
                "        for b in dl:\n",
                "            ### combine losses from all data keys\n",
                "            for dp in b:\n",
                "                ### get predictions\n",
                "                stim_pred = model(\n",
                "                    dp[\"resp\"],\n",
                "                    data_key=dp[\"data_key\"],\n",
                "                    neuron_coords=dp[\"neuron_coords\"],\n",
                "                    pupil_center=dp[\"pupil_center\"],\n",
                "                )\n",
                "\n",
                "                ### calc metrics\n",
                "                for loss_fn_name, loss_fn in loss_fns[dp[\"data_key\"]].items():\n",
                "                    losses[dp[\"data_key\"]][loss_fn_name] += loss_fn(stim_pred, dp[\"stim\"], data_key=dp[\"data_key\"], phase=\"val\").item()\n",
                "\n",
                "                ### append for later fid calculation\n",
                "                if calc_fid:\n",
                "                    preds[dp[\"data_key\"]].append(crop(stim_pred, crop_wins[dp[\"data_key\"]]).detach().cpu())\n",
                "                    targets[dp[\"data_key\"]].append(crop(dp[\"stim\"], crop_wins[dp[\"data_key\"]]).cpu())\n",
                "\n",
                "                denom_data_keys[dp[\"data_key\"]] = denom_data_keys[dp[\"data_key\"]] + dp[\"stim\"].shape[0] if dp[\"data_key\"] in denom_data_keys else dp[\"stim\"].shape[0]\n",
                "\n",
                "            if max_batches is not None and b_idx + 1 >= max_batches:\n",
                "                break\n",
                "\n",
                "    ### average losses\n",
                "    losses[\"total\"] = defaultdict(float)\n",
                "    for data_key in losses:\n",
                "        if data_key == \"total\": continue\n",
                "        for loss_name in losses[data_key]:\n",
                "            losses[data_key][loss_name] /= denom_data_keys[data_key]\n",
                "            losses[\"total\"][loss_name] += losses[data_key][loss_name]\n",
                "    losses[\"total\"] = {loss_name: losses[\"total\"][loss_name] / (len(losses.keys()) - 1) for loss_name in losses[\"total\"]}\n",
                "\n",
                "    ### eval fid\n",
                "    if calc_fid:\n",
                "        losses[\"total\"][\"FID\"] = 0\n",
                "        for data_key in preds.keys():\n",
                "            fid = FID(inp_standardized=False, device=\"cpu\")\n",
                "            losses[data_key][\"FID\"] = fid(\n",
                "                pred_imgs=torch.cat(preds[data_key], dim=0),\n",
                "                gt_imgs=torch.cat(targets[data_key], dim=0)\n",
                "            )\n",
                "            losses[\"total\"][\"FID\"] += losses[data_key][\"FID\"]\n",
                "        losses[\"total\"][\"FID\"] /= len(preds.keys())\n",
                "\n",
                "    return losses"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "decoder = Decoder(readin_path=READIN_PATH, upsample_path=UPSAMPLE_PATH).to(cfg[\"device\"], dtype=torch.float32)\n",
                "decoder.eval()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "### eval\n",
                "# prepare data and metrics\n",
                "seed_all(cfg[\"seed\"])\n",
                "dls, _ = get_dataloaders(config=cfg)\n",
                "metrics = {data_key: get_metrics(crop_win=cfg[\"crop_wins\"][data_key], device=cfg[\"device\"]) for data_key in cfg[\"crop_wins\"].keys()}\n",
                "\n",
                "# run evaluation\n",
                "test_losses = eval_decoder(\n",
                "    model=decoder,\n",
                "    dataloaders=dls[\"test\"],\n",
                "    loss_fns=metrics,\n",
                "    crop_wins=cfg[\"crop_wins\"],\n",
                "    calc_fid=True,\n",
                ")[\"total\"]\n",
                "\n",
                "### save results\n",
                "print(json.dumps(test_losses, indent=4))\n",
                "torch.save(test_losses, \"test_losses.pt\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "### get sample reconstructions\n",
                "# sample data\n",
                "seed_all(cfg[\"seed\"])\n",
                "dls, neuron_coords = get_dataloaders(config=cfg)\n",
                "s = get_sample_data(dls=dls, config=cfg, sample_from_tier=\"test\")\n",
                "\n",
                "# get reconstructions\n",
                "stim_pred = decoder(\n",
                "    s[\"b_resp\"].to(cfg[\"device\"]),\n",
                "    neuron_coords=neuron_coords[s[\"b_sample_dataset\"]][s[\"b_sample_data_key\"]],\n",
                "    data_key=s[\"b_sample_data_key\"],\n",
                ").detach().cpu()\n",
                "\n",
                "torch.save(stim_pred, \"stim_pred_best.pt\")\n",
                "\n",
                "# plot reconstructions\n",
                "plot_reconstructions(\n",
                "    runs={\n",
                "        \"Decoder\": {\n",
                "            \"stim_pred_best\": [{s[\"b_sample_data_key\"]: stim_pred}],\n",
                "        }\n",
                "    },\n",
                "    stim=s[\"stim\"],\n",
                "    stim_label=\"Target\",\n",
                "    data_key=s[\"b_sample_data_key\"],\n",
                "    crop_win=cfg[\"crop_wins\"][s[\"b_sample_data_key\"]],\n",
                "    save_to=f\"reconstructions_{s['b_sample_data_key']}.pdf\",\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# print pwd\n",
                "!pwd"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3 (ipykernel)",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.15"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
