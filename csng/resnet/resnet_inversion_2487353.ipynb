{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-09T20:34:05.285133Z",
     "iopub.status.busy": "2024-12-09T20:34:05.284977Z",
     "iopub.status.idle": "2024-12-09T20:34:07.868927Z",
     "shell.execute_reply": "2024-12-09T20:34:07.868169Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from os.path import join\n",
    "import torch\n",
    "from torchvision.datasets import ImageNet\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import functional as F\n",
    "import torch.nn.functional as batch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from random import random\n",
    "import torch.multiprocessing as mp\n",
    "from torch.utils.data import random_split, DataLoader, Subset\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-09T20:34:07.872632Z",
     "iopub.status.busy": "2024-12-09T20:34:07.871758Z",
     "iopub.status.idle": "2024-12-09T20:34:11.816026Z",
     "shell.execute_reply": "2024-12-09T20:34:11.815614Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/vanousek/.cache/torch/hub/NVIDIA_DeepLearningExamples_torchhub\n",
      "/home/vanousek/.cache/torch/hub/NVIDIA_DeepLearningExamples_torchhub/PyTorch/Classification/ConvNets/image_classification/models/common.py:13: UserWarning: pytorch_quantization module not found, quantization will not be available\n",
      "  warnings.warn(\n",
      "/home/vanousek/.cache/torch/hub/NVIDIA_DeepLearningExamples_torchhub/PyTorch/Classification/ConvNets/image_classification/models/efficientnet.py:17: UserWarning: pytorch_quantization module not found, quantization will not be available\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/vanousek/.cache/torch/hub/NVIDIA_DeepLearningExamples_torchhub\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 90\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;66;03m# Initialize CachedImageNet\u001b[39;00m\n\u001b[1;32m     83\u001b[0m train_dataset \u001b[38;5;241m=\u001b[39m CachedImageNet(\n\u001b[1;32m     84\u001b[0m     root\u001b[38;5;241m=\u001b[39mjoin(DATA_DIR, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimagenet\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[1;32m     85\u001b[0m     split\u001b[38;5;241m=\u001b[39mSPLIT,\n\u001b[1;32m     86\u001b[0m     version\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m0.9\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     87\u001b[0m )\n\u001b[0;32m---> 90\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m(\u001b[38;5;28mlen\u001b[39m(train_dataset) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m TRAIN_SIZE \u001b[38;5;241m+\u001b[39m TEST_SIZE)\n\u001b[1;32m     92\u001b[0m \u001b[38;5;66;03m# Define the split sizes\u001b[39;00m\n\u001b[1;32m     93\u001b[0m \n\u001b[1;32m     94\u001b[0m \u001b[38;5;66;03m# Split the dataset within the limit\u001b[39;00m\n\u001b[1;32m     95\u001b[0m train_subset_indices \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mrange\u001b[39m(TRAIN_SIZE))  \u001b[38;5;66;03m# Indices for the training subset\u001b[39;00m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "# Define the image limit\n",
    "BATCH_SIZE = 64\n",
    "TRAIN_SIZE = 20_000 * BATCH_SIZE\n",
    "TEST_SIZE = 20 * BATCH_SIZE\n",
    "LOSS_EVERY = 1\n",
    "EPOCH = 1\n",
    "SPLIT = 'train'\n",
    "WEIGHT_DECAY=1e-2\n",
    "LEARNING_RATE = .0005\n",
    "\n",
    "device = os.environ[\"DEVICE\"]\n",
    "utils = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_convnets_processing_utils', )\n",
    "\n",
    "DATA_DIR = os.environ['DATA_PATH']\n",
    "CACHE_DIR = join(DATA_DIR, 'imagenet_inversion')\n",
    "RESNET_SIZE = 224\n",
    "\n",
    "class CachedImageNet(ImageNet):\n",
    "\n",
    "    def __init__(self, root, split, version='0.1'):\n",
    "        TRANSFORM = transforms.Compose([\n",
    "            transforms.CenterCrop(224),\n",
    "            transforms.ToTensor(),\n",
    "        ])\n",
    "        super().__init__(root=root, split=split, transform=TRANSFORM)\n",
    "        self.cache_dir = os.path.join(CACHE_DIR, version, split)\n",
    "\n",
    "        # Create cache directory if it doesn't exist\n",
    "        os.makedirs(self.cache_dir, exist_ok=True)\n",
    "        self.resnet50 = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_resnet50', pretrained=True)\n",
    "        self.resnet50.eval().to(device)\n",
    "        self.resnet_layer = self.resnet50.layers[2][0].downsample[0]\n",
    "\n",
    "\n",
    "    def _get_cache_path(self, index):\n",
    "        \"\"\"Get the path for the cached feature.\"\"\"\n",
    "        return os.path.join(self.cache_dir, f'feature_{index}.pt')\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # Load the image and label\n",
    "        img, object_class = super().__getitem__(index)\n",
    "\n",
    "        cache_path = self._get_cache_path(index)\n",
    "        features = None\n",
    "        if not os.path.exists(cache_path) or random() < .01:\n",
    "            # Image transformations\n",
    "            IMGNET_NORM = transforms.Compose([\n",
    "                transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "            ])\n",
    "            imgnet_input = F.rgb_to_grayscale(IMGNET_NORM(img), num_output_channels=3).to(device).unsqueeze(0)\n",
    "\n",
    "            def assign_features(module, input, output):\n",
    "                nonlocal features\n",
    "                features = output\n",
    "            hook = self.resnet_layer.register_forward_hook(assign_features)\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                self.resnet50(imgnet_input)\n",
    "            hook.remove()\n",
    "            assert features is not None\n",
    "            features = features.squeeze(0)\n",
    "            if os.path.exists(cache_path):\n",
    "                saved_features = torch.load(cache_path).to(device)\n",
    "                assert torch.equal(features,saved_features)\n",
    "\n",
    "            self.save_atomic(features, cache_path)\n",
    "        else:\n",
    "            features = torch.load(cache_path).to(device)\n",
    "\n",
    "        target = F.rgb_to_grayscale(img, num_output_channels=1)\n",
    "        return features, target\n",
    "    def save_atomic(self, value, name):\n",
    "        tmp_name = name + '.tmp' + str(random())\n",
    "        torch.save(value, tmp_name)\n",
    "        os.replace(tmp_name, name)\n",
    "# Example feature extractor: compute mean/std per channel\n",
    "\n",
    "\n",
    "\n",
    "# Set the start method to 'spawn'\n",
    "mp.set_start_method('spawn', force=True)\n",
    "# Initialize CachedImageNet\n",
    "train_dataset = CachedImageNet(\n",
    "    root=join(DATA_DIR, 'imagenet'),\n",
    "    split=SPLIT,\n",
    "    version='0.9'\n",
    ")\n",
    "\n",
    "\n",
    "assert(len(train_dataset) >= TRAIN_SIZE + TEST_SIZE)\n",
    "\n",
    "# Define the split sizes\n",
    "\n",
    "# Split the dataset within the limit\n",
    "train_subset_indices = list(range(TRAIN_SIZE))  # Indices for the training subset\n",
    "test_subset_indices = list(range(TRAIN_SIZE, TRAIN_SIZE + TEST_SIZE))  # Indices for the test subset\n",
    "\n",
    "# Create the subsets\n",
    "train_subset = Subset(train_dataset, train_subset_indices)\n",
    "test_subset = Subset(train_dataset, test_subset_indices)\n",
    "\n",
    "# Define the batch size\n",
    "\n",
    "# Create DataLoaders for train and test\n",
    "train_loader = DataLoader(\n",
    "    dataset=train_subset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,  # Shuffle can be enabled based on your training needs\n",
    "    num_workers=0\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    dataset=test_subset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,  # No need to shuffle test data\n",
    "    num_workers=0\n",
    ")\n",
    "\n",
    "print(f\"Train loader contains {len(train_loader)} batches.\")\n",
    "print(f\"Test loader contains {len(test_loader)} batches.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-09T20:34:11.819228Z",
     "iopub.status.busy": "2024-12-09T20:34:11.818431Z",
     "iopub.status.idle": "2024-12-09T20:34:11.834607Z",
     "shell.execute_reply": "2024-12-09T20:34:11.833974Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_loader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 9\u001b[0m\n\u001b[1;32m      5\u001b[0m     plt\u001b[38;5;241m.\u001b[39maxis(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moff\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      6\u001b[0m     plt\u001b[38;5;241m.\u001b[39mshow()\n\u001b[0;32m----> 9\u001b[0m data_iter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28miter\u001b[39m(\u001b[43mtrain_loader\u001b[49m)  \u001b[38;5;66;03m# Replace `train_loader` with your DataLoader\u001b[39;00m\n\u001b[1;32m     10\u001b[0m features, targets \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(data_iter)\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(targets\u001b[38;5;241m.\u001b[39mshape)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_loader' is not defined"
     ]
    }
   ],
   "source": [
    "# Get a batch from the DataLoader\n",
    "def show_image(img_tensor):\n",
    "    img = img_tensor.cpu().numpy().transpose((1, 2, 0))  # Convert to HWC\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "data_iter = iter(train_loader)  # Replace `train_loader` with your DataLoader\n",
    "features, targets = next(data_iter)\n",
    "print(targets.shape)\n",
    "show_image(targets[0])  # Show the first image in the batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-09T20:34:11.837484Z",
     "iopub.status.busy": "2024-12-09T20:34:11.836724Z",
     "iopub.status.idle": "2024-12-09T20:34:13.333687Z",
     "shell.execute_reply": "2024-12-09T20:34:13.333204Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total parametrs:  24511329\n"
     ]
    }
   ],
   "source": [
    "class UpsampleModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(UpsampleModel, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.ConvTranspose2d(\n",
    "                in_channels=1024, out_channels=768,\n",
    "                kernel_size=4, stride=2, padding=1\n",
    "            ),\n",
    "            nn.BatchNorm2d(768),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.ConvTranspose2d(\n",
    "                in_channels=768, out_channels=512,\n",
    "                kernel_size=4, stride=2, padding=1\n",
    "            ),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.ConvTranspose2d(\n",
    "                in_channels=512, out_channels=384,\n",
    "                kernel_size=4, stride=2, padding=1\n",
    "            ),\n",
    "            nn.BatchNorm2d(384),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.ConvTranspose2d(\n",
    "                in_channels=384, out_channels=256,\n",
    "                kernel_size=4, stride=2, padding=1\n",
    "            ),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.ConvTranspose2d(256, 128, kernel_size=5, padding=2),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.ConvTranspose2d(128, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.ConvTranspose2d(64, 32, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.ConvTranspose2d(32, 16, kernel_size=1, padding=0),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.ConvTranspose2d(16, 1, kernel_size=1, padding=0)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "model = UpsampleModel()\n",
    "\n",
    "\n",
    "input_tensor = torch.randn(1, 1024, 14, 14)  # Batch size = 1\n",
    "output_tensor = model(input_tensor)\n",
    "assert output_tensor.shape == torch.Size([1,1,224,224])\n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(\"Total parametrs: \", count_parameters(model))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-09T20:34:13.336981Z",
     "iopub.status.busy": "2024-12-09T20:34:13.336180Z",
     "iopub.status.idle": "2024-12-09T20:34:13.340505Z",
     "shell.execute_reply": "2024-12-09T20:34:13.339940Z"
    }
   },
   "outputs": [],
   "source": [
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-09T20:34:13.343349Z",
     "iopub.status.busy": "2024-12-09T20:34:13.342587Z",
     "iopub.status.idle": "2024-12-09T20:34:13.390356Z",
     "shell.execute_reply": "2024-12-09T20:34:13.389841Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_loader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m losses \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[0;32m----> 8\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, (features, target) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[43mtrain_loader\u001b[49m):\n\u001b[1;32m      9\u001b[0m         features \u001b[38;5;241m=\u001b[39m features\u001b[38;5;241m.\u001b[39mto(device)  \u001b[38;5;66;03m# Move to device\u001b[39;00m\n\u001b[1;32m     10\u001b[0m         target \u001b[38;5;241m=\u001b[39m target\u001b[38;5;241m.\u001b[39mto(device)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_loader' is not defined"
     ]
    }
   ],
   "source": [
    "num_epochs = 1\n",
    "model.train()\n",
    "model.to(device)\n",
    "running_loss = 0.0\n",
    "losses = []\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "    for i, (features, target) in enumerate(train_loader):\n",
    "        features = features.to(device)  # Move to device\n",
    "        target = target.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(features)\n",
    "\n",
    "        loss = criterion(outputs, target)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        if i % LOSS_EVERY == LOSS_EVERY-1:\n",
    "            avg_loss = running_loss/LOSS_EVERY\n",
    "            print(avg_loss)\n",
    "            losses.append(avg_loss)\n",
    "            running_loss = 0.0\n",
    "\n",
    "        constant_guess_loss = criterion(torch.full_like(target, 0), target)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-09T20:34:13.393287Z",
     "iopub.status.busy": "2024-12-09T20:34:13.392516Z",
     "iopub.status.idle": "2024-12-09T20:34:13.728604Z",
     "shell.execute_reply": "2024-12-09T20:34:13.728197Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAicAAAGdCAYAAADJ6dNTAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAWLElEQVR4nO3da4ycZRnw8WvpYSu4M1IqLW2XgoaUrgUiZTmZijWk7aqAFiMgNo2BhJooh34gED6UIIFClGDCArEQ0S+CAiXEkJAqx9AiKUKsFE0qxRbaFVtxphQtlN7vB9/uy9LD28WdnWva3y+ZD/PMMzPXc2fT+feZmd22UkoJAIAkDmn2AAAAHyZOAIBUxAkAkIo4AQBSEScAQCriBABIRZwAAKmIEwAglZHNHmCwdu7cGRs3boyOjo5oa2tr9jgAwH4opcTWrVtj4sSJccgh+z430nJxsnHjxujs7Gz2GADAx7Bhw4aYPHnyPvdpuTjp6OiIiP8eXKVSafI0AMD+qNfr0dnZ2f86vi8tFye73sqpVCriBABazP58JMMHYgGAVMQJAJCKOAEAUhEnAEAq4gQASEWcAACpiBMAIBVxAgCk0pQ4+cY3vhGHH354fPOb32zG0wMAiTUlTi6//PL4xS9+0YynBgCSa0qczJo1a79+tz4AcPAZdJw888wzcc4558TEiROjra0tHnnkkd32ufPOO+PYY4+NMWPGxIwZM+LZZ58dilkBgIPAoONk27ZtcdJJJ8Udd9yxx9sfeOCBuPLKK+O6666Ll156KWbOnBk9PT2xfv36jzXg9u3bo16vD7gAAAeuQcdJT09P3HjjjTFv3rw93n7bbbfFJZdcEpdeemlMmzYtbr/99ujs7Iy77rrrYw148803R7Va7b90dnZ+rMcBAFrDkH7m5L333osXX3wxZs+ePWD77NmzY8WKFR/rMa+99tqo1Wr9lw0bNgzFqABAUiOH8sE2b94cH3zwQYwfP37A9vHjx0dfX1//9Tlz5sQf/vCH2LZtW0yePDmWLVsW3d3de3zM9vb2aG9vH8oxAYDEhjROdmlraxtwvZQyYNvjjz/eiKcFAA4AQ/q2zrhx42LEiBEDzpJERLz11lu7nU0BANiTIY2T0aNHx4wZM2L58uUDti9fvjzOPPPMoXwqAOAANei3dd55551Yu3Zt//V169bFyy+/HGPHjo2jjz46Fi1aFPPnz49TTjklzjjjjPjpT38a69evj4ULFw7p4ADAgWnQcbJq1aqYNWtW//VFixZFRMSCBQvivvvuiwsuuCC2bNkSN9xwQ2zatCmmT58ejz32WEyZMmXopgYADlhtpZTS7CEGo16vR7VajVqtFpVKpdnjAAD7YTCv30352zoAAHsjTgCAVMQJAJCKOAEAUhEnAEAq4gQASEWcAACptEyc9Pb2RldX117/ejEAcGDwS9gAgIbzS9gAgJYlTgCAVMQJAJCKOAEAUhEnAEAq4gQASEWcAACpiBMAIBVxAgCkIk4AgFTECQCQijgBAFIRJwBAKuIEAEhFnAAAqbRMnPT29kZXV1d0d3c3exQAoIHaSiml2UMMRr1ej2q1GrVaLSqVSrPHAQD2w2Bev1vmzAkAcHAQJwBAKuIEAEhFnAAAqYgTACAVcQIApCJOAIBUxAkAkIo4AQBSEScAQCriBABIRZwAAKmIEwAgFXECAKQiTgCAVMQJAJCKOAEAUhEnAEAqLRMnvb290dXVFd3d3c0eBQBooLZSSmn2EINRr9ejWq1GrVaLSqXS7HEAgP0wmNfvljlzAgAcHMQJAJCKOAEAUhEnAEAq4gQASEWcAACpiBMAIBVxAgCkIk4AgFTECQCQijgBAFIRJwBAKuIEAEhFnAAAqYgTACAVcQIApCJOAIBUxAkAkIo4AQBSEScAQCotEye9vb3R1dUV3d3dzR4FAGigtlJKafYQg1Gv16NarUatVotKpdLscQCA/TCY1++WOXMCABwcxAkAkIo4AQBSEScAQCriBABIRZwAAKmIEwAgFXECAKQiTgCAVMQJAJCKOAEAUhEnAEAq4gQASEWcAACpiBMAIBVxAgCkIk4AgFTECQCQijgBAFIRJwBAKuIEAEhFnAAAqYgTACAVcQIApCJOAIBUWiZOent7o6urK7q7u5s9CgDQQG2llNLsIQajXq9HtVqNWq0WlUql2eMAAPthMK/fLXPmBAA4OIgTACAVcQIApCJOAIBUxAkAkIo4AQBSEScAQCriBABIRZwAAKmIEwAgFXECAKQiTgCAVMQJAJCKOAEAUhEnAEAq4gQASEWcAACpiBMAIBVxAgCkIk4AgFTECQCQijgBAFIRJwBAKuIEAEhFnAAAqYgTACAVcQIApCJOAIBUxAkAkIo4AQBSaZk46e3tja6uruju7m72KABAA7WVUkqzhxiMer0e1Wo1arVaVCqVZo8DAOyHwbx+t8yZEwDg4CBOAIBUxAkAkIo4AQBSEScAQCriBABIRZwAAKmIEwAgFXECAKQiTgCAVMQJAJCKOAEAUhEnAEAq4gQASEWcAACpiBMAIBVxAgCkIk4AgFTECQCQijgBAFIRJwBAKuIEAEhFnAAAqYgTACAVcQIApCJOAIBUxAkAkIo4AQBSEScAQCriBABIRZwAAKmIEwAgFXECAKQiTgCAVMQJAJCKOAEAUhEnAEAq4gQASEWcAACpiBMAIJWWiZPe3t7o6uqK7u7uZo8CADRQWymlNHuIwajX61GtVqNWq0WlUmn2OADAfhjM63fLnDkBAA4O4gQASEWcAACpiBMAIBVxAgCkIk4AgFTECQCQijgBAFIRJwBAKuIEAEhFnAAAqYgTACAVcQIApCJOAIBUxAkAkIo4AQBSEScAQCriBABIRZwAAKmIEwAgFXECAKQiTgCAVMQJAJCKOAEAUhEnAEAq4gQASEWcAACpiBMAIBVxAgCkIk4AgFTECQCQijgBAFIRJwBAKuIEAEhFnAAAqYgTACAVcQIApCJOAIBUxAkAkIo4AQBSEScAQCriBABIRZwAAKmIEwAgFXECAKQiTgCAVMQJAJCKOAEAUhEnAEAq4gQASEWcAACpiBMAIBVxAgCkIk4AgFTECQCQijgBAFIRJwBAKi0TJ729vdHV1RXd3d3NHgUAaKC2Ukpp9hCDUa/Xo1qtRq1Wi0ql0uxxAID9MJjX75Y5cwIAHBzECQCQijgBAFIRJwBAKuIEAEhFnAAAqYgTACAVcQIApCJOAIBUxAkAkIo4AQBSEScAQCriBABIRZwAAKmIEwAgFXECAKQiTgCAVMQJAJCKOAEAUhEnAEAq4gQASEWcAACpiBMAIBVxAgCkIk4AgFTECQCQijgBAFIRJwBAKuIEAEhFnAAAqYgTACAVcQIApCJOAIBUxAkAkIo4AQBSEScAQCriBABIRZwAAKmIEwAgFXECAKQiTgCAVMQJAJCKOAEAUhEnAEAq4gQASEWcAACpiBMAIBVxAgCkIk4AgFTECQCQijgBAFIRJwBAKuIEAEhFnAAAqYgTACAVcQIApCJOAIBUxAkAkIo4AQBSEScAQCriBABIRZwAAKmIEwAgFXECAKQiTgCAVMQJAJCKOAEAUhEnAEAq4gQASEWcAACpiBMAIBVxAgCkIk4AgFTECQCQijgBAFIRJwBAKuIEAEhFnAAAqYgTACAVcQIApCJOAIBUxAkAkIo4AQBSEScAQCriBABIRZwAAKmIEwAgFXECAKQiTgCAVMQJAJCKOAEAUhEnAEAq4gQASEWcAACpNCVOfvOb38TUqVPjuOOOi3vuuacZIwAASY0c7ifcsWNHLFq0KJ588smoVCpx8sknx7x582Ls2LHDPQoAkNCwnzl54YUX4nOf+1xMmjQpOjo64itf+Uo8/vjjwz0GAJDUoOPkmWeeiXPOOScmTpwYbW1t8cgjj+y2z5133hnHHntsjBkzJmbMmBHPPvts/20bN26MSZMm9V+fPHlyvPnmmx9vegDggDPoONm2bVucdNJJcccdd+zx9gceeCCuvPLKuO666+Kll16KmTNnRk9PT6xfvz4iIkopu92nra1tr8+3ffv2qNfrAy4AwIFr0HHS09MTN954Y8ybN2+Pt992221xySWXxKWXXhrTpk2L22+/PTo7O+Ouu+6KiIhJkyYNOFPyxhtvxFFHHbXX57v55pujWq32Xzo7Owc7MgDQQob0MyfvvfdevPjiizF79uwB22fPnh0rVqyIiIhTTz01/vSnP8Wbb74ZW7dujcceeyzmzJmz18e89tpro1ar9V82bNgwlCMDAMkM6bd1Nm/eHB988EGMHz9+wPbx48dHX1/ff59w5Mj48Y9/HLNmzYqdO3fG1VdfHUccccReH7O9vT3a29uHckwAILGGfJX4o58hKaUM2HbuuefGueee24inBgBa3JC+rTNu3LgYMWJE/1mSXd56663dzqYAAOzJkMbJ6NGjY8aMGbF8+fIB25cvXx5nnnnmUD4VAHCAGvTbOu+8806sXbu2//q6devi5ZdfjrFjx8bRRx8dixYtivnz58cpp5wSZ5xxRvz0pz+N9evXx8KFC4d0cADgwDToOFm1alXMmjWr//qiRYsiImLBggVx3333xQUXXBBbtmyJG264ITZt2hTTp0+Pxx57LKZMmTJ0UwMAB6y2sqffipZYvV6ParUatVotKpVKs8cBAPbDYF6/m/JXiQEA9kacAACpiBMAIBVxAgCkIk4AgFTECQCQijgBAFJpyB/+a4Te3t7o7e2NHTt2RMR/vy8NALSGXa/b+/Pr1Vrul7C98cYb0dnZ2ewxAICPYcOGDTF58uR97tNycbJz587YuHFjdHR0RFtbW7PHabp6vR6dnZ2xYcMGvzG3gazz8LDOw8M6Dw/rPFApJbZu3RoTJ06MQw7Z96dKWuZtnV0OOeSQ/29xHYwqlYof/mFgnYeHdR4e1nl4WOf/p1qt7td+PhALAKQiTgCAVMRJi2tvb4/FixdHe3t7s0c5oFnn4WGdh4d1Hh7W+eNruQ/EAgAHNmdOAIBUxAkAkIo4AQBSEScAQCriJLm333475s+fH9VqNarVasyfPz/+9a9/7fM+pZS4/vrrY+LEifGJT3wivvSlL8Urr7yy1317enqira0tHnnkkaE/gBbRiHX+5z//GT/4wQ9i6tSpceihh8bRRx8dl19+edRqtQYfTR533nlnHHvssTFmzJiYMWNGPPvss/vc/+mnn44ZM2bEmDFj4jOf+Uzcfffdu+3z0EMPRVdXV7S3t0dXV1csW7asUeO3lKFe66VLl8bMmTPj8MMPj8MPPzzOPvvseOGFFxp5CC2hET/Tu9x///3R1tYWX//614d46hZUSG3u3Lll+vTpZcWKFWXFihVl+vTp5Wtf+9o+77NkyZLS0dFRHnroobJ69epywQUXlKOOOqrU6/Xd9r3ttttKT09PiYiybNmyBh1Ffo1Y59WrV5d58+aVRx99tKxdu7b87ne/K8cdd1w5//zzh+OQmu7+++8vo0aNKkuXLi1r1qwpV1xxRTnssMPK3/72tz3u/9prr5VDDz20XHHFFWXNmjVl6dKlZdSoUeXBBx/s32fFihVlxIgR5aabbiqvvvpquemmm8rIkSPL888/P1yHlVIj1vrb3/526e3tLS+99FJ59dVXy3e/+91SrVbLG2+8MVyHlU4j1nmX119/vUyaNKnMnDmznHfeeQ0+kvzESWJr1qwpETHgH96VK1eWiCh//vOf93ifnTt3lgkTJpQlS5b0b/vPf/5TqtVqufvuuwfs+/LLL5fJkyeXTZs2HdRx0uh1/rBf/epXZfTo0eX9998fugNI6tRTTy0LFy4csO34448v11xzzR73v/rqq8vxxx8/YNtll11WTj/99P7r3/rWt8rcuXMH7DNnzpxy4YUXDtHUrakRa/1RO3bsKB0dHeXnP//5/z5wi2rUOu/YsaN84QtfKPfcc09ZsGCBOCmleFsnsZUrV0a1Wo3TTjutf9vpp58e1Wo1VqxYscf7rFu3Lvr6+mL27Nn929rb2+Oss84acJ933303LrroorjjjjtiwoQJjTuIFtDIdf6oWq0WlUolRo5suT9rNSjvvfdevPjiiwPWJyJi9uzZe12flStX7rb/nDlzYtWqVfH+++/vc599rfmBrlFr/VHvvvtuvP/++zF27NihGbzFNHKdb7jhhvj0pz8dl1xyydAP3qLESWJ9fX1x5JFH7rb9yCOPjL6+vr3eJyJi/PjxA7aPHz9+wH2uuuqqOPPMM+O8884bwolbUyPX+cO2bNkSP/zhD+Oyyy77HyfOb/PmzfHBBx8Man36+vr2uP+OHTti8+bN+9xnb495MGjUWn/UNddcE5MmTYqzzz57aAZvMY1a5+eeey7uvffeWLp0aWMGb1HipAmuv/76aGtr2+dl1apVERHR1ta22/1LKXvc/mEfvf3D93n00UfjiSeeiNtvv31oDiipZq/zh9Xr9fjqV78aXV1dsXjx4v/hqFrL/q7Pvvb/6PbBPubBohFrvcutt94av/zlL+Phhx+OMWPGDMG0rWso13nr1q3xne98J5YuXRrjxo0b+mFb2IF9bjmp73//+3HhhRfuc59jjjkm/vjHP8bf//733W77xz/+sVuN77LrLZq+vr446qij+re/9dZb/fd54okn4q9//Wt86lOfGnDf888/P2bOnBlPPfXUII4mr2av8y5bt26NuXPnxic/+clYtmxZjBo1arCH0nLGjRsXI0aM2O1/lHtan10mTJiwx/1HjhwZRxxxxD732dtjHgwatda7/OhHP4qbbropfvvb38aJJ544tMO3kEas8yuvvBKvv/56nHPOOf2379y5MyIiRo4cGX/5y1/is5/97BAfSYto0mdd2A+7Pqj5+9//vn/b888/v18f1Lzlllv6t23fvn3ABzU3bdpUVq9ePeASEeUnP/lJee211xp7UAk1ap1LKaVWq5XTTz+9nHXWWWXbtm2NO4iETj311PK9731vwLZp06bt88OD06ZNG7Bt4cKFu30gtqenZ8A+c+fO9YHYBqx1KaXceuutpVKplJUrVw7twC1qqNf53//+927/Fp933nnly1/+clm9enXZvn17Yw6kBYiT5ObOnVtOPPHEsnLlyrJy5cpywgkn7PYV16lTp5aHH364//qSJUtKtVotDz/8cFm9enW56KKL9vpV4l3iIP62TimNWed6vV5OO+20csIJJ5S1a9eWTZs29V927NgxrMfXDLu+dnnvvfeWNWvWlCuvvLIcdthh5fXXXy+llHLNNdeU+fPn9++/62uXV111VVmzZk259957d/va5XPPPVdGjBhRlixZUl599dWyZMkSXyUujVnrW265pYwePbo8+OCDA352t27dOuzHl0Uj1vmjfFvnv8RJclu2bCkXX3xx6ejoKB0dHeXiiy8ub7/99oB9IqL87Gc/67++c+fOsnjx4jJhwoTS3t5evvjFL5bVq1fv83kO9jhpxDo/+eSTJSL2eFm3bt3wHFiT9fb2lilTppTRo0eXk08+uTz99NP9ty1YsKCcddZZA/Z/6qmnyuc///kyevTocswxx5S77rprt8f89a9/XaZOnVpGjRpVjj/++PLQQw81+jBawlCv9ZQpU/b4s7t48eJhOJq8GvEz/WHi5L/aSvm/n84BAEjAt3UAgFTECQCQijgBAFIRJwBAKuIEAEhFnAAAqYgTACAVcQIApCJOAIBUxAkAkIo4AQBSEScAQCr/B2Dzknp18YpLAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot losses\n",
    "plt.plot(losses)\n",
    "plt.yscale('log')\n",
    "# set maximum y to "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-09T20:34:13.731693Z",
     "iopub.status.busy": "2024-12-09T20:34:13.730911Z",
     "iopub.status.idle": "2024-12-09T20:34:13.757339Z",
     "shell.execute_reply": "2024-12-09T20:34:13.756968Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_loader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 39\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m test_loss, all_targets, all_predictions\n\u001b[1;32m     38\u001b[0m \u001b[38;5;66;03m# Evaluate on the first 10% of the test dataset\u001b[39;00m\n\u001b[0;32m---> 39\u001b[0m test_loss_partial, partial_targets, partial_predictions \u001b[38;5;241m=\u001b[39m evaluate_partial_model(model, \u001b[43mtest_loader\u001b[49m, device)\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTest Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_loss_partial\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mplot_examples\u001b[39m(targets, predictions, num_examples\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m):\n",
      "\u001b[0;31mNameError\u001b[0m: name 'test_loader' is not defined"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def evaluate_partial_model(model, test_loader, device, max_batches=10_000):\n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    all_targets = []\n",
    "    all_predictions = []\n",
    "\n",
    "    num_batches = min(max_batches, len(test_loader)) \n",
    "    processed_batches = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for features, target in tqdm(test_loader):\n",
    "            if processed_batches >= num_batches:\n",
    "                break\n",
    "\n",
    "            features = features.to(device)\n",
    "            target = target.to(device)\n",
    "\n",
    "            # Predict\n",
    "            predictions = model(features)\n",
    "\n",
    "            loss = criterion(predictions, target)\n",
    "            test_loss += loss.item()\n",
    "\n",
    "            # Store for plotting\n",
    "            all_targets.append(target.cpu())\n",
    "            all_predictions.append(predictions.cpu())\n",
    "\n",
    "            processed_batches += 1\n",
    "\n",
    "    test_loss /= processed_batches\n",
    "    all_targets = torch.cat(all_targets, dim=0)\n",
    "    all_predictions = torch.cat(all_predictions, dim=0)\n",
    "\n",
    "    return test_loss, all_targets, all_predictions\n",
    "\n",
    "# Evaluate on the first 10% of the test dataset\n",
    "test_loss_partial, partial_targets, partial_predictions = evaluate_partial_model(model, test_loader, device)\n",
    "print(f\"Test Loss: {test_loss_partial:.4f}\")\n",
    "\n",
    "def plot_examples(targets, predictions, num_examples=5):\n",
    "    plt.figure(figsize=(15, num_examples * 3))\n",
    "    for i in range(num_examples):\n",
    "        # Plot the actual target\n",
    "        plt.subplot(num_examples, 2, 2 * i + 1)\n",
    "        plt.imshow(targets[i].squeeze(), cmap='gray')  # Squeeze to remove extra dimension\n",
    "        plt.title(\"Actual Target\")\n",
    "        plt.axis('off')\n",
    "\n",
    "        # Plot the predicted target\n",
    "        plt.subplot(num_examples, 2, 2 * i + 2)\n",
    "        plt.imshow(predictions[i].squeeze(), cmap='gray')  # Squeeze to remove extra dimension\n",
    "        plt.title(\"Predicted Target\")\n",
    "        plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Plot Examples\n",
    "num_examples = 5  # Number of examples to visualize\n",
    "plot_examples(partial_targets[:num_examples].cpu().numpy(), partial_predictions[:num_examples].cpu().numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-09T20:34:13.760167Z",
     "iopub.status.busy": "2024-12-09T20:34:13.759410Z",
     "iopub.status.idle": "2024-12-09T20:34:13.773480Z",
     "shell.execute_reply": "2024-12-09T20:34:13.773125Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'partial_predictions' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mpartial_predictions\u001b[49m\u001b[38;5;241m.\u001b[39mmin(), partial_predictions\u001b[38;5;241m.\u001b[39mmax())\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(partial_targets\u001b[38;5;241m.\u001b[39mmin(), partial_targets\u001b[38;5;241m.\u001b[39mmax())\n",
      "\u001b[0;31mNameError\u001b[0m: name 'partial_predictions' is not defined"
     ]
    }
   ],
   "source": [
    "print(partial_predictions.min(), partial_predictions.max())\n",
    "print(partial_targets.min(), partial_targets.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-09T20:34:13.776218Z",
     "iopub.status.busy": "2024-12-09T20:34:13.775469Z",
     "iopub.status.idle": "2024-12-09T20:34:13.900225Z",
     "shell.execute_reply": "2024-12-09T20:34:13.899701Z"
    }
   },
   "outputs": [],
   "source": [
    "name_extra = os.environ['SLURM_JOB_ID'] if 'SLURM_JOB_ID' in os.environ else ''\n",
    "torch.save(model, join(os.environ['MODELS_PATH'], \"mlp\" + name_extra + \".pt\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
